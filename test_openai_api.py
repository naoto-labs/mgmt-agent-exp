#!/usr/bin/env python3
"""
OpenAI APIãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Azure OpenAIã®è¨­å®šãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã‹ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import asyncio
import os
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.ai.model_manager import model_manager


async def test_openai_api():
    """OpenAI APIã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ¤– OpenAI APIãƒ†ã‚¹ãƒˆé–‹å§‹")

    try:
        # ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆã‚’å–å¾—
        stats = model_manager.get_model_stats()
        print(f"   âœ… ãƒ—ãƒ©ã‚¤ãƒãƒªãƒ¢ãƒ‡ãƒ«: {stats.get('primary_model')}")
        print(f"   âœ… åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«æ•°: {len(stats.get('models', {}))}")

        # å„ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
        models = stats.get("models", {})
        for model_name, model_info in models.items():
            print(f"   ğŸ“Š {model_name}: {model_info.get('status', 'ä¸æ˜')}")

        # ãƒ¢ãƒ‡ãƒ«ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        print("\nğŸ” ãƒ¢ãƒ‡ãƒ«ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­...")
        health = await model_manager.check_all_models_health()
        print("   âœ… ãƒ¢ãƒ‡ãƒ«ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Œäº†")

        for model_name, is_healthy in health.items():
            status = "âœ… æ­£å¸¸" if is_healthy else "âŒ ç•°å¸¸"
            print(f"      - {model_name}: {status}")

        # ã‚·ãƒ³ãƒ—ãƒ«ãªå¿œç­”ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print("\nğŸ’¬ AIå¿œç­”ç”Ÿæˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
        from src.ai.model_manager import AIMessage

        messages = [
            AIMessage(
                role="user",
                content="ã“ã‚“ã«ã¡ã¯ã€ãƒ†ã‚¹ãƒˆã§ã™ã€‚ã‚ãªãŸã®å½¹å‰²ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
            )
        ]

        response = await model_manager.generate_response(messages, max_tokens=100)

        if response.success:
            print(f"   âœ… AIå¿œç­”ç”ŸæˆæˆåŠŸ")
            print(f"   ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {response.model_used}")
            print(f"   â±ï¸ å¿œç­”æ™‚é–“: {response.response_time:.2f}ç§’")
            print(f"   ğŸ“ ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: {response.tokens_used}")
            print(f"   ğŸ’¬ å¿œç­”å†…å®¹: {response.content}")
        else:
            print(f"   âŒ AIå¿œç­”ç”Ÿæˆå¤±æ•—: {response.error_message}")
            print(f"   ğŸ¤– ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {response.model_used}")

        # Azure OpenAIãŒãƒ—ãƒ©ã‚¤ãƒãƒªã®å ´åˆã®è©³ç´°ãƒ†ã‚¹ãƒˆ
        if stats.get("primary_model") == "azure_openai":
            print("\nğŸ”§ Azure OpenAIè©³ç´°ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")

            # ã‚ˆã‚Šè¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ãƒ†ã‚¹ãƒˆ
            complex_messages = [
                AIMessage(role="system", content="ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
                AIMessage(
                    role="user",
                    content="è‡ªå‹•è²©å£²æ©Ÿã®é‹å–¶ã«ã¤ã„ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ãƒã‚¤ãƒ³ãƒˆã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ï¼š1)åœ¨åº«ç®¡ç†ã€2)é¡§å®¢æº€è¶³åº¦ã€3)ã‚³ã‚¹ãƒˆåŠ¹ç‡ã€‚",
                ),
            ]

            complex_response = await model_manager.generate_response(
                complex_messages, max_tokens=200
            )

            if complex_response.success:
                print("   âœ… è¤‡é›‘ãªã‚¯ã‚¨ãƒªå¿œç­”æˆåŠŸ")
                print(f"   ğŸ’¬ å¿œç­”å†…å®¹: {complex_response.content[:100]}...")
            else:
                print(f"   âŒ è¤‡é›‘ãªã‚¯ã‚¨ãƒªå¿œç­”å¤±æ•—: {complex_response.error_message}")

    except Exception as e:
        print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()

    print("\nğŸ‰ OpenAI APIãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    asyncio.run(test_openai_api())
