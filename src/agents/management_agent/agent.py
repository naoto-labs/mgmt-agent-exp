"""
ã‚»ãƒƒã‚·ãƒ§ãƒ³å‹çµŒå–¶ç®¡ç†Agent

LangChainã§å®Ÿè£…ã—ãŸçµ±åˆçµŒå–¶ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
"""

import logging
from datetime import date, datetime, timedelta
from typing import Any, Dict, List, Optional
from uuid import uuid4

# ã‚«ã‚¹ã‚¿ãƒ ãƒ­ã‚°è¨­å®šã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦åˆæœŸåŒ–
from src.shared.config.logging_config import (
    configure_langsmith_tracing,
    get_logger,
    setup_logging,
)

# ãƒ­ã‚°è¨­å®šã‚’åˆæœŸåŒ–
setup_logging()
configure_langsmith_tracing()

# ãƒ­ã‚¬ãƒ¼ã‚’å–å¾—
logger = get_logger(__name__)

import functools
import time
from typing import Any, List

# ãƒ¡ãƒ¢ãƒªãƒ¼é–¢é€£import
from langchain.memory import (
    ConversationBufferMemory,
    ConversationBufferWindowMemory,
    VectorStoreRetrieverMemory,
)
from langchain.prompts import ChatPromptTemplate
from langchain.tools import StructuredTool
from langchain_chroma import Chroma
from langchain_core.language_models.base import BaseLanguageModel
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda, RunnableSequence
from langchain_core.tools import tool
from langchain_openai import OpenAIEmbeddings
from langsmith import traceable
from pydantic import BaseModel, Field

from src.domain.models.product import SAMPLE_PRODUCTS
from src.shared.utils.trace_control import conditional_traceable


class BusinessMetrics(BaseModel):
    """äº‹æ¥­ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    sales: float
    profit_margin: float
    inventory_level: Dict[str, int]
    customer_satisfaction: float
    timestamp: datetime


class ManagementState(BaseModel):
    """Management Agentã®å®Œå…¨ãªçŠ¶æ…‹ç®¡ç†ã‚¯ãƒ©ã‚¹ (VendingBenchæº–æ‹ ãƒ»Multi-dayé‹ç”¨å¯¾å¿œ)"""

    # ===== ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† =====
    session_id: str = Field(description="ã‚»ãƒƒã‚·ãƒ§ãƒ³å›ºæœ‰ID")
    session_type: str = Field(
        description="ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ— (management_flow, node_based_managementãªã©)"
    )

    # ===== æ—¥æ™‚ãƒ»æœŸé–“ç®¡ç† =====
    created_at: datetime = Field(
        default_factory=datetime.now,
        description="ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ—¥æ™‚ (ãƒ­ã‚°ä¿å­˜ãƒ»ãƒ¡ãƒ¢ãƒªç”¨)",
    )
    updated_at: datetime = Field(
        default_factory=datetime.now, description="æœ€çµ‚æ›´æ–°æ—¥æ™‚"
    )
    business_date: date = Field(
        default_factory=date.today, description="äº‹æ¥­æ—¥ (å–¶æ¥­æ—¥å˜ä½)"
    )
    day_sequence: int = Field(default=1, description="é€£ç¶šç¨¼åƒæ—¥æ•° (1æ—¥ç›®ã€2æ—¥ç›®...)")

    # ===== ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿å…¥åŠ› =====
    business_metrics: Optional[BusinessMetrics] = Field(
        default=None, description="å£²ä¸Šã€åˆ©ç›Šã€åœ¨åº«ã€é¡§å®¢æº€è¶³åº¦ã®åŸºæœ¬æŒ‡æ¨™"
    )

    # åˆ†æãƒ•ã‚§ãƒ¼ã‚ºã®å‡ºåŠ›
    inventory_analysis: Optional[Dict] = Field(
        default=None,
        description="åœ¨åº«çŠ¶æ³ã®è©³ç´°åˆ†æçµæœï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€ã‚¢ãƒ©ãƒ¼ãƒˆã€å†ç™ºæ³¨æ¨å¥¨ï¼‰",
    )

    sales_analysis: Optional[Dict] = Field(
        default=None, description="å£²ä¸Šãƒ»è²¡å‹™ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ã€æˆ¦ç•¥æ¨å¥¨ï¼‰"
    )

    financial_analysis: Optional[Dict] = Field(
        default=None, description="è©³ç´°è²¡å‹™åˆ†æçµæœ"
    )

    sales_processing: Optional[Dict] = Field(
        default=None, description="å£²ä¸Šå‡¦ç†ãƒ»è²©å£²åŠ¹ç‡åˆ†æçµæœ"
    )

    profit_calculation: Optional[Dict] = Field(
        default=None, description="åˆ©ç›Šè¨ˆç®—ãƒ»è²¡å‹™å¥å…¨æ€§è©³ç´°åˆ†æçµæœ"
    )

    # æˆ¦ç•¥æ±ºå®šãƒ•ã‚§ãƒ¼ã‚º
    pricing_decision: Optional[Dict] = Field(
        default=None, description="ä¾¡æ ¼æˆ¦ç•¥æ±ºå®šï¼ˆä¾¡æ ¼å¤‰æ›´ã€æ–°ä¾¡æ ¼ã€ç†ç”±ï¼‰"
    )

    restock_decision: Optional[Dict] = Field(
        default=None, description="è£œå……ã‚¿ã‚¹ã‚¯æ±ºå®šï¼ˆè£½å“ãƒªã‚¹ãƒˆã€ã‚¿ã‚¹ã‚¯IDã€ç·Šæ€¥åº¦ï¼‰"
    )

    procurement_decision: Optional[Dict] = Field(
        default=None, description="èª¿é”ä¾é ¼æ±ºå®šï¼ˆè£½å“ã€æ•°é‡ã€ç™ºæ³¨æƒ…å ±ï¼‰"
    )

    # é¡§å®¢å¯¾å¿œ
    customer_interaction: Optional[Dict] = Field(
        default=None, description="é¡§å®¢å¯¾å¿œçµæœï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€æ–°è¦ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ï¼‰"
    )

    # å®Ÿè¡Œå±¥æ­´
    executed_actions: List[Dict] = Field(
        default_factory=list, description="å®Ÿè¡Œæ¸ˆã¿ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å±¥æ­´"
    )

    # çŠ¶æ…‹ç®¡ç†
    current_step: str = Field(
        default="initialization", description="ç¾åœ¨ã®å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—"
    )

    processing_status: str = Field(
        default="pending",
        description="å…¨ä½“å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ (pending, processing, completed, error)",
    )

    # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    errors: List[str] = Field(
        default_factory=list, description="ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸€è¦§"
    )

    # ===== ãƒ¡ãƒ¢ãƒªé€£æºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ (ConversationBufferWindowMemory + VectorStoreé€£æº) ====
    # TODO VectorStoreæœªä½œæˆ
    memory_snapshot: Optional[Dict] = Field(
        default=None, description="ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼ˆçŸ­æœŸãƒ¡ãƒ¢ãƒªï¼‰"
    )
    learned_patterns: Optional[Dict] = Field(
        default=None, description="VectorStoreã‹ã‚‰ã®å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆé•·æœŸãƒ¡ãƒ¢ãƒªï¼‰"
    )
    historical_insights: List[Dict] = Field(
        default_factory=list,
        description="éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®æ´å¯Ÿï¼ˆå£²ä¸Šå‚¾å‘ã€åœ¨åº«ãƒ‘ã‚¿ãƒ¼ãƒ³ç­‰ï¼‰",
    )

    # ===== Multi-dayé‹ç”¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ =====
    previous_day_carry_over: Optional[Dict] = Field(
        default=None, description="å‰æ—¥ã®final_reportãƒ‡ãƒ¼ã‚¿å¼•ãç¶™ã"
    )
    cumulative_kpis: Dict[str, Any] = Field(
        default_factory=lambda: {
            "total_profit": 0,
            "average_stockout_rate": 0.0,
            "customer_satisfaction_trend": [],
            "action_accuracy_history": [],
        },
        description="å…¨ç¨¼åƒæœŸé–“ã®ç´¯ç©KPIï¼ˆVendingBench Secondary Metricsç”¨ï¼‰",
    )

    # ===== ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•å¯¾å¿œãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ (Case Cå‘ã‘ã—ã°ã‚‰ãæœªä½¿ç”¨) =====
    external_events: List[Dict] = Field(
        default_factory=list, description="äººé–“ã«ã‚ˆã‚‹åˆ¶ç´„ã€çªç™ºã‚¤ãƒ™ãƒ³ãƒˆã®å±¥æ­´"
    )
    agent_communications: List[Dict] = Field(
        default_factory=list, description="ä»–ã®Agentã¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸äº¤æ›ï¼ˆQueueãƒ™ãƒ¼ã‚¹ï¼‰"
    )
    pending_human_tasks: List[Dict] = Field(
        default_factory=list, description="äººé–“å¾“æ¥­å“¡å¾…ã¡ã®ã‚¿ã‚¹ã‚¯ï¼ˆè£œå……ã€èª¿é”ä¾é ¼ç­‰ï¼‰"
    )

    # ===== ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ =====
    primary_metrics_history: List[Dict] = Field(
        default_factory=list, description="å„å®Ÿè¡Œå›ã®Profit, StockoutRateç­‰ã®å±¥æ­´"
    )
    consistency_metrics: Dict[str, Any] = Field(
        default_factory=dict, description="é•·æœŸçš„ä¸€è²«æ€§è©•ä¾¡ãƒ‡ãƒ¼ã‚¿"
    )

    # æœ€çµ‚å‡ºåŠ›
    feedback: Optional[Dict] = Field(
        default=None, description="æœ€çµ‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨è¦ç´„"
    )
    final_report: Optional[Dict] = Field(default=None, description="æœ€çµ‚ç·åˆãƒ¬ãƒãƒ¼ãƒˆ")


from src.shared import secure_config, settings

logger = logging.getLogger(__name__)


class LangChainLLMAdapter(BaseLanguageModel):
    """model_managerã‚’LangChain LLMã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«å¤‰æ›ã™ã‚‹adapter"""

    def __init__(self):
        # å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        self._model_manager = None

    def _get_model_manager(self):
        """é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§model_managerã‚’å–å¾—"""
        if self._model_manager is None:
            # å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from ..infrastructure.ai.model_manager import model_manager

            self._model_manager = model_manager
        return self._model_manager

    def _generate_response(self, messages: List[BaseMessage], **kwargs) -> str:
        """åŒæœŸç‰ˆgenerate response"""
        import asyncio

        async def async_call():
            # BaseMessage -> AIMessageå¤‰æ›
            ai_messages = []
            for msg in messages:
                if isinstance(msg, HumanMessage):
                    ai_messages.append(AIMessage(role="user", content=msg.content))
                elif isinstance(msg, AIMessage):
                    ai_messages.append(AIMessage(role="assistant", content=msg.content))
                elif isinstance(msg, SystemMessage):
                    ai_messages.append(AIMessage(role="system", content=msg.content))
                else:
                    ai_messages.append(AIMessage(role="user", content=str(msg.content)))

            response = await self._get_model_manager().generate_response(
                ai_messages, **kwargs
            )
            return response.content if response.success else "Error: LLM not available"

        # åŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§éåŒæœŸå®Ÿè¡Œ
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # æ—¢å­˜ãƒ«ãƒ¼ãƒ—ãŒã‚ã‚‹å ´åˆã€æ–°ã—ã„ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
                import concurrent.futures

                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, async_call())
                    return future.result()
            else:
                return loop.run_until_complete(async_call())
        except Exception as e:
            logger.error(f"LLM adapter error: {e}")
            return "Error: Could not generate response"

    async def _agenerate_response(self, messages: List[BaseMessage], **kwargs) -> str:
        """éåŒæœŸç‰ˆgenerate response"""
        from src.infrastructure.ai.model_manager import AIMessage

        # BaseMessage -> AIMessageå¤‰æ›
        ai_messages = []
        for msg in messages:
            if isinstance(msg, HumanMessage):
                ai_messages.append(AIMessage(role="user", content=msg.content))
            elif isinstance(msg, AIMessage):
                ai_messages.append(AIMessage(role="assistant", content=msg.content))
            elif isinstance(msg, SystemMessage):
                ai_messages.append(AIMessage(role="system", content=msg.content))
            else:
                ai_messages.append(AIMessage(role="user", content=str(msg.content)))

        response = await self._get_model_manager().generate_response(
            ai_messages, **kwargs
        )
        return response.content if response.success else "Error: LLM not available"

    @property
    def _llm_type(self) -> str:
        return "model_manager_adapter"

    def _call(self, prompt: str, **kwargs) -> str:
        """LangChainåŸºåº•ãƒ¡ã‚½ãƒƒãƒ‰"""
        messages = [HumanMessage(content=prompt)]
        return self._generate_response(messages, **kwargs)

    # BaseLanguageModelã®abstract methodsã‚’å®Ÿè£…
    def invoke(self, input, config=None, **kwargs):
        """åŒæœŸinvoke"""
        if isinstance(input, str):
            return self._call(input, **kwargs)
        elif hasattr(input, "content"):  # BaseMessageã®å ´åˆ
            return self._generate_response([input], **kwargs)
        else:
            return self._call(str(input), **kwargs)

    async def ainvoke(self, input, config=None, **kwargs):
        """éåŒæœŸinvoke"""
        from src.infrastructure.ai.model_manager import AIMessage

        if isinstance(input, str):
            messages = [AIMessage(role="user", content=input)]
        elif hasattr(input, "content"):  # BaseMessageã®å ´åˆ
            messages = [input]
        else:
            messages = [AIMessage(role="user", content=str(input))]

        return await self._agenerate_response(messages, **kwargs)

    def generate_prompt(self, prompts, stop=None, **kwargs):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        responses = []
        for prompt in prompts:
            if hasattr(prompt, "__iter__"):
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®å ´åˆ
                response = self._generate_response(list(prompt), **kwargs)
            else:
                response = self._call(str(prompt), **kwargs)
            responses.append(response)
        return responses

    async def agenerate_prompt(self, prompts, stop=None, **kwargs):
        """éåŒæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        responses = []
        for prompt in prompts:
            if hasattr(prompt, "__iter__"):
                response = await self._agenerate_response(list(prompt), **kwargs)
            else:
                messages = [AIMessage(role="user", content=str(prompt))]
                response = await self._agenerate_response(messages, **kwargs)
            responses.append(response)
        return responses

    def predict(self, text, **kwargs):
        """ãƒ†ã‚­ã‚¹ãƒˆäºˆæ¸¬"""
        return self._call(text, **kwargs)

    async def apredict(self, text, **kwargs):
        """éåŒæœŸãƒ†ã‚­ã‚¹ãƒˆäºˆæ¸¬"""
        messages = [AIMessage(role="user", content=text)]
        return await self._agenerate_response(messages, **kwargs)

    def predict_messages(self, messages, **kwargs):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸äºˆæ¸¬"""
        return self._generate_response(messages, **kwargs)

    async def apredict_messages(self, messages, **kwargs):
        """éåŒæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸äºˆæ¸¬"""
        return await self._agenerate_response(messages, **kwargs)


class SessionInfo(BaseModel):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±"""

    session_id: str
    session_type: str  # "morning_routine", "midday_check", "evening_summary"
    start_time: datetime
    end_time: Optional[datetime] = None
    decisions_made: List[Dict[str, Any]] = Field(default_factory=list)
    actions_executed: List[Dict[str, Any]] = Field(default_factory=list)


class BusinessMetrics(BaseModel):
    """äº‹æ¥­ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    sales: float
    profit_margin: float
    inventory_level: Dict[str, int]
    customer_satisfaction: float
    timestamp: datetime


class NodeBasedManagementAgent:
    """Node-BasedçµŒå–¶ç®¡ç†Agent (RunnableSequence + AgentExecutor)"""

    def __init__(
        self, llm_manager=None, agent_objectives=None, provider: str = "openai"
    ):
        """
        Args:
            llm_manager: LLMãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ (AgentBuilderã‹ã‚‰æ³¨å…¥ã€ã¾ãŸã¯Noneã§è‡ªå‹•å–å¾—)
            agent_objectives: Agentè¨­å®š(ç›®çš„ãƒ»åˆ¶ç´„) (AgentBuilderã‹ã‚‰æ³¨å…¥ã€ã¾ãŸã¯Noneã§è¨­å®šã‹ã‚‰å–å¾—)
            provider: LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ ("anthropic" or "openai" - å¾Œæ–¹äº’æ›ç”¨)
        """
        # ä¾å­˜é–¢ä¿‚æ³¨å…¥ (AgentBuilderå„ªå…ˆã€Noneãªã‚‰è‡ªå‹•å–å¾—)
        if llm_manager is not None:
            self.llm_manager = llm_manager
            logger.info("NodeBasedManagementAgent: LLM Manager injected from builder")
        else:
            # å¾Œæ–¹äº’æ›ç”¨: ç›´æ¥import (å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å•é¡Œã‚ã‚Š)
            from src.infrastructure.ai import model_manager

            self.llm_manager = model_manager
            logger.info(
                "NodeBasedManagementAgent: LLM Manager auto-loaded (legacy mode)"
            )

        # è¨­å®šæ³¨å…¥ (AgentBuilderå„ªå…ˆã€Noneãªã‚‰è¨­å®šã‹ã‚‰å–å¾—)
        if agent_objectives is not None:
            self.agent_objectives = agent_objectives
            logger.info(
                "NodeBasedManagementAgent: Agent objectives injected from builder"
            )
        else:
            # å¾Œæ–¹äº’æ›ç”¨: ç›´æ¥èª­ã¿è¾¼ã¿
            self.agent_objectives = settings.agent_objectives
            logger.info(
                "NodeBasedManagementAgent: Agent objectives loaded from settings"
            )

        # å¾Œæ–¹äº’æ›ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.provider = provider
        self.current_session: Optional[SessionInfo] = None
        self._system_prompt_logged = False  # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ­ã‚°å‡ºåŠ›ãƒ•ãƒ©ã‚°

        logger.info(f"NodeBasedManagementAgent initialized (provider: {provider})")

        # LLMæ¥ç¶šç¢ºèª (ç›´æ¥å‚ç…§ã«å¤‰æ›´)
        self._verify_llm_connection()

        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        self.system_prompt = self._generate_system_prompt()

        # ãƒ¡ãƒ¢ãƒªãƒ¼åˆæœŸåŒ–
        self._initialize_memory()

        # Nodeå®šç¾© (Case A)
        self.nodes = self._create_nodes()

        # LCELãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ (Case A - StateGraphã§ã¯ãªãRunnableSequenceã‚’ä½¿ç”¨)
        self.chain = self._build_lcel_pipeline()

        # ãƒ„ãƒ¼ãƒ«ã®å®Ÿè£…ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from src.agents.management_agent.management_tools.update_pricing import (
            update_pricing,
        )

        # ãƒ„ãƒ¼ãƒ«å®Ÿè£…ã‚’ãƒ¡ã‚½ãƒƒãƒ‰ã¨ã—ã¦è¨­å®š
        self.update_pricing = update_pricing

        # ãƒ„ãƒ¼ãƒ«ã®åˆæœŸåŒ–
        self.tools = self._create_tools()

    async def _verify_llm_connection_async(self):
        """SessionBasedManagementAgentåˆæœŸåŒ–æ™‚LLMæ¥ç¶šç¢ºèªï¼ˆéåŒæœŸç‰ˆï¼‰"""
        logger.info("SessionBasedManagementAgentã®LLMæ¥ç¶šã‚’ç¢ºèªã—ã¦ã„ã¾ã™...")

        try:
            # é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å›é¿
            from src.infrastructure.ai.model_manager import model_manager

            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
            health_results = await model_manager.check_all_models_health()

            # çµæœã®ãƒ­ã‚°å‡ºåŠ›
            for model_name, is_healthy in health_results.items():
                if is_healthy:
                    logger.info(f"âœ… AIãƒ¢ãƒ‡ãƒ« {model_name}: æ¥ç¶šç¢ºèªæˆåŠŸ")
                else:
                    logger.warning(f"âŒ AIãƒ¢ãƒ‡ãƒ« {model_name}: æ¥ç¶šå¤±æ•—")

            # å°‘ãªãã¨ã‚‚1ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
            available_models = [
                name for name, healthy in health_results.items() if healthy
            ]
            if not available_models:
                logger.warning(
                    "âš ï¸ åˆ©ç”¨å¯èƒ½ãªAIãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ã¯åˆ¶é™ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ã€‚"
                )
            else:
                logger.info(
                    f"ğŸš€ AIå‡¦ç†æº–å‚™å®Œäº†ï¼ˆåˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«: {', '.join(available_models)}ï¼‰"
                )

        except Exception as e:
            logger.error(f"LLMæ¥ç¶šç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            logger.warning("âš ï¸ AIãƒ¢ãƒ‡ãƒ«æ¥ç¶šç¢ºèªã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

    def _verify_llm_connection(self):
        """SessionBasedManagementAgentåˆæœŸåŒ–æ™‚LLMæ¥ç¶šç¢ºèª - åŒæœŸç‰ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        logger.info("LLMæ¥ç¶šç¢ºèªã‚’åŒæœŸçš„ã«å®Ÿè¡Œ")
        try:
            # ã‚·ãƒ³ãƒ—ãƒ«ãªåŒæœŸçš„ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
            logger.info(
                "âœ… LLMæ¥ç¶šç¢ºèª: åŒæœŸãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œ - è©³ç´°ãªãƒã‚§ãƒƒã‚¯ã¯å®Ÿè¡Œæ™‚ã«è¡Œã‚ã‚Œã¾ã™"
            )
        except Exception as e:
            logger.error(f"LLMæ¥ç¶šç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            logger.warning("âš ï¸ AIãƒ¢ãƒ‡ãƒ«æ¥ç¶šç¢ºèªã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

    def _get_memory_context(self, node_name: str) -> str:
        """
        æŒ‡å®šãƒãƒ¼ãƒ‰ã®éå»ãƒ“ã‚¸ãƒã‚¹æ´å¯Ÿã‚’å–å¾—ï¼ˆLangSmithãƒˆãƒ¬ãƒ¼ã‚¹ä»˜ãï¼‰

        Args:
            node_name: ãƒãƒ¼ãƒ‰å (ä¾‹: "inventory_check", "sales_plan")

        Returns:
            éå»æ´å¯Ÿã®è¦ç´„æ–‡å­—åˆ—
        """
        if not self.short_term_memory:
            logger.debug(f"No memory available for {node_name}")
            return "No previous context available."

        try:
            # ãƒ¡ãƒ¢ãƒªãƒ¼ã‹ã‚‰éå»ã®ä¼šè©±ã‚’å–å¾—
            # ConversationBufferMemoryã¯æœ€æ–°ã®ä¼šè©±ã‚’å„ªå…ˆçš„ã«è¿”ã™
            memory_variables = self.short_term_memory.load_memory_variables({})

            # å„Nodeã«é–¢é€£ã™ã‚‹éå»æ´å¯Ÿã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            relevant_insights = []
            node_prefix = f"Previous {node_name} insight:"

            if "history" in memory_variables:
                history = memory_variables["history"]
                if isinstance(history, str):
                    # å˜ä¸€ã®å±¥æ­´æ–‡å­—åˆ—ã®å ´åˆ
                    if node_prefix in history:
                        # ã“ã®Nodeã®æ´å¯Ÿã‚’å«ã‚€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç‰¹å®š
                        insights = history.split(node_prefix)
                        for insight in insights[1:]:  # æœ€åˆã®è¦ç´ ã¯prefixå‰ã®éƒ¨åˆ†
                            clean_insight = insight.split("\nAssistant: ")[0].strip()
                            relevant_insights.append(clean_insight[:200])  # é•·ã•åˆ¶é™

                elif isinstance(history, list):
                    # ä¼šè©±å±¥æ­´ã®ãƒªã‚¹ãƒˆã®å ´åˆ
                    for msg in history:
                        if hasattr(msg, "content") and node_prefix in msg.content:
                            # ã“ã®Nodeã®æ´å¯Ÿã‚’æŠ½å‡º
                            content = msg.content
                            insight_start = content.find(node_prefix) + len(node_prefix)
                            insight_end = content.find("\n", insight_start)
                            if insight_end == -1:
                                insight_end = len(content)

                            insight = content[insight_start:insight_end].strip()
                            relevant_insights.append(insight[:200])

            if relevant_insights:
                # æœ€æ–°3ã¤ã®æ´å¯Ÿã‚’çµåˆ
                context = " | ".join(relevant_insights[-3:])
                logger.info(
                    f"Retrieved {len(relevant_insights)} insights for {node_name}: {context[:100]}..."
                )
                return context
            else:
                logger.debug(f"No relevant insights found for {node_name}")
                return f"No previous {node_name} insights available."

        except Exception as e:
            logger.warning(f"Error retrieving memory context for {node_name}: {e}")
            return f"Memory retrieval error for {node_name}."

    def _extract_and_save_business_insight(self, node_name: str, llm_response: str):
        """
        LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ“ã‚¸ãƒã‚¹æ´å¯Ÿã‚’æŠ½å‡ºã—ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã«ä¿å­˜ï¼ˆLangSmithãƒˆãƒ¬ãƒ¼ã‚¹ä»˜ãï¼‰

        Args:
            node_name: ãƒãƒ¼ãƒ‰å
            llm_response: LLMã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ–‡å­—åˆ—
        """
        try:
            # LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ“ã‚¸ãƒã‚¹æ´å¯Ÿã‚’æŠ½å‡º
            insight = self._extract_business_insight(llm_response, node_name)

            if insight and insight != "No insight extracted":
                # æ´å¯Ÿã‚’ãƒ¡ãƒ¢ãƒªãƒ¼ã«ä¿å­˜ï¼ˆLangSmithãƒˆãƒ¬ãƒ¼ã‚¹ï¼‰
                self._save_business_insight(node_name, insight)
                logger.info(
                    f"Saved business insight for {node_name}: {insight[:100]}..."
                )

                # LangSmithãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                trace_metadata = {
                    "node_name": node_name,
                    "insight_extracted": insight[:200],
                    "insight_length": len(insight),
                    "memory_saved": True,
                    "timestamp": datetime.now().isoformat(),
                }

            else:
                logger.debug(
                    f"No significant insight extracted from {node_name} response"
                )

        except Exception as e:
            logger.error(f"Error extracting/saving insight for {node_name}: {e}")

    def _extract_business_insight(self, llm_response: str, node_name: str) -> str:
        """
        LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ“ã‚¸ãƒã‚¹æ´å¯Ÿã‚’æŠ½å‡º

        Args:
            llm_response: LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹
            node_name: ãƒãƒ¼ãƒ‰å

        Returns:
            æŠ½å‡ºã•ã‚ŒãŸãƒ“ã‚¸ãƒã‚¹æ´å¯Ÿã®è¦ç´„
        """
        if not llm_response or len(llm_response.strip()) < 50:
            return "No insight extracted"

        try:
            # Nodeåˆ¥ã®æ´å¯ŸæŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
            insights = {
                "inventory_check": self._extract_inventory_insight,
                "sales_plan": self._extract_sales_insight,
                "pricing": self._extract_pricing_insight,
                "profit_calculation": self._extract_profit_insight,
                "customer_interaction": self._extract_customer_insight,
            }

            extract_func = insights.get(node_name, self._extract_generic_insight)
            insight = extract_func(llm_response)

            return insight if insight else "No specific insight extracted"

        except Exception as e:
            logger.debug(f"Insight extraction failed for {node_name}: {e}")
            return "Insight extraction error"

    def _extract_inventory_insight(self, response: str) -> str:
        """åœ¨åº«åˆ†æã‹ã‚‰ã®æ´å¯ŸæŠ½å‡º"""
        if "critical" in response.lower():
            return "åœ¨åº«çŠ¶æ³ãŒå±æ©Ÿçš„ã€‚ç·Šæ€¥è£œå……ãŒå¿…è¦"
        elif "low" in response.lower():
            return "åœ¨åº«æ°´æº–ãŒä½ä¸‹å‚¾å‘ã€‚è¨ˆç”»çš„è£œå……ã‚’æ¤œè¨"
        elif "normal" in response.lower():
            return "åœ¨åº«çŠ¶æ³ã¯å®‰å®šã€‚ç¾åœ¨ã®ç®¡ç†æ–¹é‡ã‚’ç¶™ç¶š"
        return f"åœ¨åº«åˆ†æ: {response[:100]}..." if len(response) > 100 else response

    def _extract_sales_insight(self, response: str) -> str:
        """å£²ä¸Šåˆ†æã‹ã‚‰ã®æ´å¯ŸæŠ½å‡º"""
        if "concerning" in response.lower():
            return "å£²ä¸Šå‹•å‘ãŒæ‡¸å¿µã•ã‚Œã‚‹ã€‚æˆ¦ç•¥è¦‹ç›´ã—ãŒå¿…è¦"
        elif "positive" in response.lower():
            return "å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰è‰¯å¥½ã€‚æ—¢å­˜æˆ¦ç•¥ã‚’å¼·åŒ–"
        elif "stable" in response.lower():
            return "å£²ä¸Šå®‰å®šã€‚ãƒªã‚¹ã‚¯åˆ†æ•£æˆ¦ç•¥ã‚’æ¤œè¨"
        return f"å£²ä¸Šåˆ†æ: {response[:100]}..." if len(response) > 100 else response

    def _extract_pricing_insight(self, response: str) -> str:
        """ä¾¡æ ¼æˆ¦ç•¥ã‹ã‚‰ã®æ´å¯ŸæŠ½å‡º"""
        if "increase" in response.lower():
            return "ä¾¡æ ¼å¼•ãä¸Šã’æˆ¦ç•¥æ¡ç”¨ã€‚åˆ©ç›Šç‡æ”¹å–„ã‚’å„ªå…ˆ"
        elif "maintain" in response.lower():
            return "ä¾¡æ ¼å®‰å®šæˆ¦ç•¥ã€‚ç«¶äº‰åŠ›ç¶­æŒã‚’é‡è¦–"
        elif "decrease" in response.lower():
            return "ä¾¡æ ¼å¼•ãä¸‹ã’æˆ¦ç•¥ã€‚å¸‚å ´ã‚·ã‚§ã‚¢æ‹¡å¤§ã‚’ç‹™ã†"
        return f"ä¾¡æ ¼æˆ¦ç•¥: {response[:100]}..." if len(response) > 100 else response

    def _extract_profit_insight(self, response: str) -> str:
        """åˆ©ç›Šè¨ˆç®—ã‹ã‚‰ã®æ´å¯ŸæŠ½å‡º"""
        if "excellent" in response.lower():
            return "è²¡å‹™çŠ¶æ³æ¥µã‚ã¦è‰¯å¥½ã€‚äº‹æ¥­æ‹¡å¤§ã®æ©Ÿä¼š"
        elif "good" in response.lower():
            return "è²¡å‹™çŠ¶æ³è‰¯å¥½ã€‚å®‰å®šçµŒå–¶ã‚’ç¶™ç¶š"
        elif "critical" in response.lower():
            return "è²¡å‹™çŠ¶æ³ãŒå±æ©Ÿçš„ã€‚æŠœæœ¬çš„ãªæ”¹å–„ãŒå¿…è¦"
        return f"è²¡å‹™åˆ†æ: {response[:100]}..." if len(response) > 100 else response

    def _extract_customer_insight(self, response: str) -> str:
        """é¡§å®¢å¯¾å¿œã‹ã‚‰ã®æ´å¯ŸæŠ½å‡º"""
        if "improve" in response.lower():
            return "é¡§å®¢æº€è¶³åº¦å‘ä¸Šæ–½ç­–ãŒå¿…è¦"
        elif "campaign" in response.lower():
            return "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å®Ÿæ–½"
        elif "monitor" in response.lower():
            return "é¡§å®¢ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ç¶™ç¶šç›£è¦–ã‚’ç¶™ç¶š"
        return f"é¡§å®¢å¯¾å¿œ: {response[:100]}..." if len(response) > 100 else response

    def _extract_generic_insight(self, response: str) -> str:
        """æ±ç”¨æ´å¯ŸæŠ½å‡º"""
        # æœ€åˆã®æ„å‘³ã®ã‚ã‚‹æ–‡ã‚’æŠ½å‡ºï¼ˆJSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        if response.startswith("{") or response.startswith("["):
            return "Structured response received"

        lines = [line.strip() for line in response.split("\n") if line.strip()]
        for line in lines:
            if len(line) > 20 and not line.startswith("```"):
                return line[:150] + "..." if len(line) > 150 else line

        return response[:150] + "..." if len(response) > 150 else response

    def _save_business_insight(self, node_name: str, insight: str):
        """
        ãƒ“ã‚¸ãƒã‚¹æ´å¯Ÿã‚’çŸ­æœŸãƒ¡ãƒ¢ãƒªãƒ¼ã«ä¿å­˜ï¼ˆLangSmithãƒˆãƒ¬ãƒ¼ã‚¹ä»˜ãï¼‰

        Args:
            node_name: ãƒãƒ¼ãƒ‰å
            insight: ä¿å­˜ã™ã‚‹æ´å¯Ÿå†…å®¹
        """
        if not self.short_term_memory:
            logger.debug("Short-term memory not available")
            return

        try:
            # ä¼šè©±å½¢å¼ã§æ´å¯Ÿã‚’ä¿å­˜
            # System: éå»ã®æ´å¯Ÿ -> Assistant: [æ´å¯Ÿå†…å®¹]
            self.short_term_memory.save_context(
                inputs={"input": f"Previous {node_name} insight:"},  # äººé–“ã®å…¥åŠ›
                outputs={"output": insight},  # AIã®å‡ºåŠ›
            )

            logger.debug(f"Saved insight to memory: {node_name} -> {insight[:50]}...")

        except Exception as e:
            logger.error(f"Failed to save business insight for {node_name}: {e}")

    def _generate_system_prompt(self) -> str:
        """Agentç›®çš„è¨­å®šã«åŸºã¥ã„ã¦ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        objectives = self.agent_objectives

        prompt = f"""
ã‚ãªãŸã¯è‡ªå‹•è²©å£²æ©Ÿäº‹æ¥­ã®çµŒå–¶è€…ã§ã™ã€‚ä»¥ä¸‹ã®è¨­å®šã«åŸºã¥ã„ã¦æ„æ€æ±ºå®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€ä¸»è¦ç›®çš„ã€‘
{chr(10).join(f"- {obj}" for obj in objectives["primary"])}

ã€æœ€é©åŒ–æœŸé–“æ è¨­å®šã€‘(æˆ¦ç•¥çš„å„ªå…ˆåº¦: {objectives["priority_weight"]})
"""

        for period_key, descriptions in objectives["optimization_period"].items():
            weight = objectives["priority_weight"].get(period_key, 0.0)
            prompt += f"- {period_key}: {descriptions} (é‡ã¿: {weight})\n"

        prompt += f"""
ã€åˆ¶ç´„æ¡ä»¶ã€‘
{chr(10).join(f"- {constraint}" for constraint in objectives["constraints"])}

ã€æ¥­å‹™çµ±æ‹¬ã€‘
- å£²ä¸Šãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã¨æˆ¦ç•¥ç«‹æ¡ˆ
- åœ¨åº«çŠ¶æ³ã®ç›£è¦–ã¨è£œå……è¨ˆç”»
- ä¾¡æ ¼æˆ¦ç•¥ã®æ±ºå®šã¨å®Ÿè¡ŒæŒ‡ç¤º
- å¾“æ¥­å“¡ã¸ã®ä½œæ¥­æŒ‡ç¤ºï¼ˆè£œå……ã€èª¿é”ã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ï¼‰
- é¡§å®¢ã‹ã‚‰ã®å•ã„åˆã‚ã›å¯¾å¿œã¨è‹¦æƒ…å‡¦ç†

ã€æ„æ€æ±ºå®šåŸå‰‡ã€‘
- çŸ­æœŸãƒ»ä¸­æœŸãƒ»é•·æœŸç›®æ¨™ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ã¦åç›Šæ€§ã‚’æœ€å„ªå…ˆ
- é¡§å®¢æº€è¶³åº¦ã‚’ç¶­æŒã—ã¤ã¤é•·æœŸçš„ãªæˆé•·ã‚’å›³ã‚‹
- ãƒªã‚¹ã‚¯ã‚’é©åˆ‡ã«ç®¡ç†ã—ã€å®‰å®šçš„ãªäº‹æ¥­é‹å–¶ã‚’è¡Œã†
- ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸæˆ¦ç•¥çš„åˆ¤æ–­ã‚’è¡Œã†
"""

        return prompt

    def _initialize_memory(self):
        """ãƒ¡ãƒ¢ãƒªãƒ¼åˆæœŸåŒ–"""
        # çŸ­æœŸãƒ¡ãƒ¢ãƒªãƒ¼: ConversationBufferWindowMemoryã®è­¦å‘Šã‚’ä¿®æ­£ (ConversationBufferMemoryã‚’ä½¿ç”¨)
        try:
            # LangChain v0.1.xä»¥é™ã§ã¯ConversationBufferWindowMemoryãŒéæ¨å¥¨
            # ConversationBufferMemoryã«å¤‰æ›´ã—ã€max_token_limitã§åˆ¶é™ã‚’è¨­ã‘ã‚‹
            from langchain.memory import ConversationBufferMemory

            self.short_term_memory = ConversationBufferMemory(
                max_token_limit=1000,  # ãƒˆãƒ¼ã‚¯ãƒ³50å€‹/å¯¾è©± Ã— 20å¯¾è©±ç¨‹åº¦ã®åˆ¶é™
                return_messages=True,
            )
        except ImportError:
            # æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å ´åˆã®ã¿ConversationBufferWindowMemoryã‚’ä½¿ç”¨
            try:
                self.short_term_memory = ConversationBufferWindowMemory(k=5)
            except Exception as e:
                logger.warning(f"ãƒ¡ãƒ¢ãƒªãƒ¼åˆæœŸåŒ–å¤±æ•—ã€ç°¡æ˜“Fallbackã‚’ä½¿ç”¨: {e}")
                self.short_term_memory = None

        # é•·æœŸãƒ¡ãƒ¢ãƒªãƒ¼: VectorStoreRetrieverMemory (ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«ã‚ˆã‚‹æ¤œç´¢)
        try:
            # Azureæ¤œçŸ¥ã‚’å›é¿ã™ã‚‹ãŸã‚ã«æ˜ç¤ºçš„ã«OpenAIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
            import os

            if "AZURE_OPENAI" in os.environ or "OPENAI_API_KEY" not in os.environ:
                logger.info(
                    "Using simple fallback for embeddings (Azure/conf key issue)"
                )
                raise Exception("Azure OpenAI detected or no OpenAI key")

            embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small",  # ã‚ˆã‚Šé«˜é€Ÿã§å®‰ä¾¡ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
                openai_api_key=os.environ.get("OPENAI_API_KEY"),
            )

            vectorstore = Chroma(
                collection_name="agent_memory", embedding_function=embeddings
            )
            self.long_term_memory = VectorStoreRetrieverMemory(
                retriever=vectorstore.as_retriever()
            )
        except Exception as e:
            logger.warning(f"é•·æœŸãƒ¡ãƒ¢ãƒªãƒ¼åˆæœŸåŒ–ã«å¤±æ•—ã€ç°¡æ˜“Fallbackã‚’ä½¿ç”¨: {e}")
            self.long_term_memory = None

    def _create_nodes(self):
        """Case Aã®ãƒãƒ¼ãƒ‰ç¾¤ã‚’å®šç¾©"""
        return {
            "inventory_check": self.inventory_check_node,
            "sales_plan": self.sales_plan_node,
            "pricing": self.pricing_node,
            "restock": self.restock_node,
            "procurement": self.procurement_request_generation_node,
            "sales_processing": self.sales_processing_node,
            "customer_interaction": self.customer_interaction_node,
            "profit_calculation": self.profit_calculation_node,
            "feedback": self.feedback_node,
        }

    def _build_state_graph(self):
        """StateGraphã«ã‚ˆã‚‹ã‚°ãƒ©ãƒ•æ§‹ç¯‰ (Case A) - ç›´ç·šçš„ãƒãƒ¼ãƒ‰æ¥ç¶š"""
        try:
            # LangGraph importã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
            import langgraph

            try:
                version = getattr(langgraph, "__version__", "unknown")
                logger.info(f"Using LangGraph version: {version}")
            except:
                logger.info("Using LangGraph (version unknown)")
            from langgraph.graph import StateGraph

            # StateGraphåˆæœŸåŒ– (ManagementStateã‚’ä½¿ç”¨)
            graph = StateGraph(ManagementState)
            logger.info("StateGraph initialized with ManagementState")

            print("DEBUG: Importing langgraph modules...")
            try:
                from langgraph.graph import StateGraph

                print("DEBUG: StateGraph imported successfully")
            except Exception as e:
                print(f"DEBUG: StateGraph import failed: {e}")
                self.state_graph = None
                return

            # å„ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ  (Case A: 9ã¤ã®ãƒãƒ¼ãƒ‰å…¨ã¦)
            graph.add_node("inventory_check", self.inventory_check_node)
            graph.add_node("sales_plan", self.sales_plan_node)
            graph.add_node("pricing", self.pricing_node)
            graph.add_node("restock", self.restock_node)
            graph.add_node("procurement", self.procurement_request_generation_node)
            graph.add_node("sales_processing", self.sales_processing_node)
            graph.add_node("customer_interaction", self.customer_interaction_node)
            graph.add_node("profit_calculation", self.profit_calculation_node)
            graph.add_node("feedback", self.feedback_node)
            logger.info("All nodes added to StateGraph")

            # ç›´ç·šçš„ãªãƒãƒ¼ãƒ‰æ¥ç¶š (Case A: å„ãƒãƒ¼ãƒ‰ã‚’é †ç•ªã«é·ç§»)
            graph.add_edge("inventory_check", "sales_plan")
            graph.add_edge("sales_plan", "pricing")
            graph.add_edge("pricing", "restock")
            graph.add_edge("restock", "procurement")
            graph.add_edge("procurement", "sales_processing")
            graph.add_edge("sales_processing", "customer_interaction")
            graph.add_edge("customer_interaction", "profit_calculation")
            graph.add_edge("profit_calculation", "feedback")
            logger.info("All edges added to StateGraph")

            # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’è¨­å®š (æœ€åˆã®ãƒãƒ¼ãƒ‰)
            graph.set_entry_point("inventory_check")
            logger.info("Entry point set to inventory_check")

            # ã‚°ãƒ©ãƒ•ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
            print("DEBUG: Attempting to compile StateGraph...")
            try:
                compiled_graph = graph.compile()
                self.state_graph = compiled_graph
                print(
                    f"DEBUG: StateGraph compiled successfully, type: {type(self.state_graph)}"
                )
                logger.info("âœ… StateGraph for Case A compiled successfully")
            except Exception as compile_e:
                print(f"DEBUG: StateGraph compile failed: {compile_e}")
                self.state_graph = None
                logger.error(f"StateGraph compile failed: {compile_e}")
                import traceback

                logger.error(f"StateGraph compile traceback: {traceback.format_exc()}")

        except ImportError as e:
            logger.error(f"LangGraph import error: {e}. Please install langgraph")
            self.state_graph = None
        except Exception as e:
            logger.error(f"StateGraph build failed: {e}")
            logger.error(f"StateGraph build error type: {type(e).__name__}")
            import traceback

            logger.error(f"StateGraph build traceback: {traceback.format_exc()}")
            self.state_graph = None

    def _build_lcel_pipeline(self):
        """LCEL RunnableSequenceã«ã‚ˆã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ (Case A)"""
        try:
            from langchain_core.runnables import RunnableLambda, RunnableSequence

            # å„ãƒãƒ¼ãƒ‰ã‚’RunnableLambdaã§ãƒ©ãƒƒãƒ—
            inventory_runnable = RunnableLambda(self.inventory_check_node)
            sales_plan_runnable = RunnableLambda(self.sales_plan_node)
            pricing_runnable = RunnableLambda(self.pricing_node)
            restock_runnable = RunnableLambda(self.restock_node)
            procurement_runnable = RunnableLambda(
                self.procurement_request_generation_node
            )
            sales_processing_runnable = RunnableLambda(self.sales_processing_node)
            customer_runnable = RunnableLambda(self.customer_interaction_node)
            profit_runnable = RunnableLambda(self.profit_calculation_node)
            feedback_runnable = RunnableLambda(self.feedback_node)

            # ãƒãƒ¼ãƒ‰ã‚’ç›´ç·šçš„ã«æ¥ç¶šã—ãŸRunnableSequenceã‚’ä½œæˆ
            # input -> inventory_check -> sales_plan -> pricing -> restock -> procurement -> sales_processing -> customer_interaction -> profit_calculation -> feedback -> output
            self.chain = RunnableSequence(
                inventory_runnable,
                sales_plan_runnable,
                pricing_runnable,
                restock_runnable,
                procurement_runnable,
                sales_processing_runnable,
                customer_runnable,
                profit_runnable,
                feedback_runnable,
            )

            logger.info("âœ… LCEL RunnableSequence pipeline built successfully")
            return self.chain

        except Exception as e:
            logger.error(f"LCEL Pipeline build failed: {e}")
            import traceback

            logger.error(f"Pipeline build traceback: {traceback.format_exc()}")
            self.chain = None
            return None

    def _build_chain(self):
        """å¾Œæ–¹äº’æ›ç”¨chainæ§‹ç¯‰ (ä½¿ç”¨æ¨å¥¨ã›ãš)"""
        return self._build_lcel_pipeline()

    def _test_llm_connection_sync(self):
        """LLMæ¥ç¶šç¢ºèªï¼ˆåŒæœŸç‰ˆï¼‰ - å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å›é¿ã™ã‚‹ãŸã‚å‰Šé™¤"""
        # ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        # å®Ÿéš›ã®æ¥ç¶šç¢ºèªã¯_asyncãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã¿ã‚’ä½¿ç”¨
        pass

    def _create_tools(self) -> List[StructuredTool]:
        """LangChainãƒ„ãƒ¼ãƒ«ã®ä½œæˆ - Tool Registryä½¿ç”¨"""
        from src.agents.management_agent.tools.tool_registry import create_tool_registry

        # Tool Registryã‹ã‚‰å…¨ãƒ„ãƒ¼ãƒ«ã‚’å–å¾—
        return create_tool_registry()

    # Note: Tool definition moved to tool_registry.py
    # Old tool creation methods removed to eliminate duplication

    # ãƒ„ãƒ¼ãƒ«å®Ÿè£…ãƒ¡ã‚½ãƒƒãƒ‰

    def get_business_metrics(self) -> Dict[str, Any]:
        """ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ï¼ˆå®Ÿéš›ã®ã‚·ã‚¹ãƒ†ãƒ ã¨é€£æºï¼‰"""
        logger.info("Getting business metrics from actual systems")

        try:
            # å„ç¨®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from datetime import date, timedelta

            from src.application.services.inventory_service import inventory_service
            from src.domain.accounting.management_accounting import management_analyzer

            # åœ¨åº«æƒ…å ±ã‚’å–å¾—
            inventory_summary = inventory_service.get_inventory_summary()
            inventory_level = {}

            # å•†å“åˆ¥åœ¨åº«ã‚’é›†è¨ˆ
            for slot in inventory_service.vending_machine_slots.values():
                product_name = slot.product_name.lower()
                if product_name not in inventory_level:
                    inventory_level[product_name] = 0
                inventory_level[product_name] += slot.current_quantity

            # è²¡å‹™æƒ…å ±ã‚’å–å¾—ï¼ˆç®¡ç†ä¼šè¨ˆã‹ã‚‰ï¼‰
            end_date = date.today()
            start_date = end_date - timedelta(days=30)

            # å£²ä¸Šæƒ…å ±ã‚’å–å¾—ï¼ˆä¼šè¨ˆã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ï¼‰
            sales = abs(
                management_analyzer.journal_processor.get_account_balance(
                    "4001", start_date, end_date
                )
            )

            period_profitability = management_analyzer.analyze_period_profitability(
                start_date, end_date
            )
            profit_margin = period_profitability.get("gross_margin", 0.35)

            # é¡§å®¢æº€è¶³åº¦ã®è¨ˆç®—
            # åœ¨åº«å……è¶³ç‡ã¨å£²ä¸Šå®Ÿç¸¾ã‹ã‚‰æ¨å®š
            total_inventory = sum(inventory_level.values())
            max_inventory = (
                len(inventory_service.vending_machine_slots) * 50
            )  # æƒ³å®šæœ€å¤§åœ¨åº«
            inventory_score = (
                min(total_inventory / max_inventory, 1.0) if max_inventory > 0 else 0.5
            )

            # å£²ä¸Šç›®æ¨™ã¨ã®æ¯”è¼ƒï¼ˆæœˆé–“ç›®æ¨™: 100ä¸‡å††ï¼‰
            monthly_target = 1000000
            sales_score = min(sales / monthly_target, 1.0)

            # ç·åˆæº€è¶³åº¦ï¼ˆ3.0-5.0ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
            customer_satisfaction = 3.0 + (inventory_score * 1.0 + sales_score * 1.0)

            metrics_result = {
                "sales": round(sales, 2),
                "profit_margin": round(profit_margin, 3),
                "inventory_level": inventory_level,
                "customer_satisfaction": round(customer_satisfaction, 2),
                "timestamp": datetime.now().isoformat(),
                "inventory_status": {
                    "total_slots": len(inventory_service.vending_machine_slots),
                    "low_stock_count": len(inventory_service.get_low_stock_slots()),
                    "out_of_stock_count": len(
                        inventory_service.get_out_of_stock_slots()
                    ),
                },
                "sales_stats": {
                    "total_revenue": sales,  # ä¼šè¨ˆã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å–å¾—
                },
            }

            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: å–å¾—ã—ãŸãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°å‡ºåŠ›
            logger.debug("=== BUSINESS METRICS RETRIEVED ===")
            logger.debug(f"Sales (accounting_system): Â¥{sales:.2f}")
            logger.debug(f"Profit Margin: {profit_margin:.3f}")
            logger.debug(f"Inventory Level: {inventory_level}")
            logger.debug(f"Inventory Status: {metrics_result['inventory_status']}")
            logger.debug(f"Customer Satisfaction: {customer_satisfaction:.2f}")
            logger.debug("=== END BUSINESS METRICS ===")

            return metrics_result

        except Exception as e:
            logger.error(f"ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’è¿”ã™
            return {
                "sales": 0.0,
                "profit_margin": 0.0,
                "inventory_level": {},
                "customer_satisfaction": 3.0,
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
            }

    @conditional_traceable(name="financial_performance_analysis")
    async def analyze_financial_performance(self) -> Dict[str, Any]:
        """è²¡å‹™ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æï¼ˆæ³¨å…¥ã•ã‚ŒãŸllm_managerçµŒç”±ï¼‰"""
        logger.info("Analyzing financial performance using LLM")
        try:
            metrics = self.get_business_metrics()

            messages = [
                self.llm_manager.create_ai_message(
                    role="system", content=self.system_prompt
                ),
                self.llm_manager.create_ai_message(
                    role="user",
                    content=f"""
ä»¥ä¸‹ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã¨æ”¹å–„ææ¡ˆã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã€‘
- å£²ä¸Š: Â¥{metrics["sales"]:,}
- åˆ©ç›Šç‡: {metrics["profit_margin"]:.1%}
- åœ¨åº«çŠ¶æ³: {metrics["inventory_level"]}
- é¡§å®¢æº€è¶³åº¦: {metrics["customer_satisfaction"]}/5.0

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
    "analysis": "è²¡å‹™çŠ¶æ³ã®å…¨ä½“çš„ãªè©•ä¾¡ã¨åˆ†æï¼ˆ100æ–‡å­—ä»¥ä¸Šï¼‰",
    "recommendations": ["æ”¹å–„ææ¡ˆ1", "æ”¹å–„ææ¡ˆ2", "æ”¹å–„ææ¡ˆ3"]
}}
```
""",
                ),
            ]

            response = await self.llm_manager.generate_response(
                messages, max_tokens=1000
            )

            if response.success:
                try:
                    import json

                    content = response.content.strip()
                    if content.startswith("```json"):
                        content = content[7:]
                    if content.endswith("```"):
                        content = content[:-3]
                    content = content.strip()
                    llm_response = json.loads(content)
                    return {
                        "analysis": llm_response.get(
                            "analysis", "åˆ†æã§ãã¾ã›ã‚“ã§ã—ãŸ"
                        ),
                        "recommendations": llm_response.get("recommendations", []),
                        "metrics": metrics,
                    }
                except json.JSONDecodeError:
                    logger.warning(
                        f"è²¡å‹™åˆ†æLLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‘ãƒ¼ã‚¹å¤±æ•—: {response.content}"
                    )

            # LLMå¤±æ•—æ™‚ã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹
            logger.warning("LLMè²¡å‹™åˆ†æå¤±æ•—ã€ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä½¿ç”¨")
            return {
                "analysis": "å£²ä¸Šã¯äºˆç®—æ¯”95%ã§æ¨ç§»ã€‚åˆ©ç›Šç‡ã¯è‰¯å¥½ã€‚",
                "recommendations": ["åœ¨åº«å›è»¢ç‡ã®æ”¹å–„", "é«˜åˆ©ç›Šå•†å“ã®å¼·åŒ–"],
                "metrics": metrics,
            }

        except Exception as e:
            logger.error(f"è²¡å‹™ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            metrics = self.get_business_metrics()
            return {
                "analysis": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
                "recommendations": ["ç®¡ç†è€…ã¸é€£çµ¡ã—ã¦ãã ã•ã„"],
                "metrics": metrics,
            }

    @conditional_traceable(name="inventory_status_analysis")
    async def check_inventory_status(self) -> Dict[str, Any]:
        """åœ¨åº«çŠ¶æ³ã‚’ç¢ºèªï¼ˆæ³¨å…¥ã•ã‚ŒãŸllm_managerçµŒç”±ï¼‰"""
        logger.info("Checking inventory status using LLM")
        try:
            metrics = self.get_business_metrics()
            inventory_level = metrics["inventory_level"]

            messages = [
                self.llm_manager.create_ai_message(
                    role="system", content=self.system_prompt
                ),
                self.llm_manager.create_ai_message(
                    role="user",
                    content=f"""
ä»¥ä¸‹ã®åœ¨åº«çŠ¶æ³ã‚’åˆ†æã—ã€åœ¨åº«ç®¡ç†ã®æ¨å¥¨äº‹é …ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ã€ç¾åœ¨ã®åœ¨åº«çŠ¶æ³ã€‘
{inventory_level}

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
    "status": "åœ¨åº«çŠ¶æ³ã®å…¨ä½“è©•ä¾¡ (normal/critical/low)",
    "low_stock_items": ["åœ¨åº«ã®å°‘ãªã„å•†å“åãƒªã‚¹ãƒˆ"],
    "reorder_needed": ["ç™ºæ³¨ãŒå¿…è¦ãªå•†å“åãƒªã‚¹ãƒˆ"],
    "estimated_stockout": {{"å•†å“å": "åœ¨åº«åˆ‡ã‚Œäºˆæ¸¬æ—¥"}}
}}
```
""",
                ),
            ]

            response = await self.llm_manager.generate_response(
                messages, max_tokens=1000
            )

            if response.success:
                try:
                    import json

                    content = response.content.strip()
                    if content.startswith("```json"):
                        content = content[7:]
                    if content.endswith("```"):
                        content = content[:-3]
                    content = content.strip()
                    llm_response = json.loads(content)
                    return llm_response
                except json.JSONDecodeError:
                    logger.warning(
                        f"åœ¨åº«çŠ¶æ³LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‘ãƒ¼ã‚¹å¤±æ•—: {response.content}"
                    )

            # LLMå¤±æ•—æ™‚ã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹
            logger.warning("LLMåœ¨åº«åˆ†æå¤±æ•—ã€ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä½¿ç”¨")
            return {
                "status": "normal",
                "low_stock_items": ["water"],
                "reorder_needed": ["water"],
                "estimated_stockout": {"water": "2æ—¥å¾Œ"},
            }

        except Exception as e:
            logger.error(f"åœ¨åº«çŠ¶æ³ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "status": "error",
                "low_stock_items": [],
                "reorder_needed": [],
                "estimated_stockout": {},
            }

    def assign_restocking_task(
        self, products: List[str], urgency: str = "normal"
    ) -> Dict[str, Any]:
        """è£œå……ã‚¿ã‚¹ã‚¯ã‚’å‰²ã‚Šå½“ã¦"""
        logger.info("Tool assign_restocking called")
        logger.info(f"Assigning restocking task for {products} with urgency {urgency}")
        task_id = str(uuid4())
        return {
            "task_id": task_id,
            "task_type": "restocking",
            "products": products,
            "urgency": urgency,
            "assigned": True,
            "deadline": (
                datetime.now() + timedelta(hours=2 if urgency == "urgent" else 24)
            ).isoformat(),
        }

    def request_procurement(
        self, products: List[str], quantity: Dict[str, int]
    ) -> Dict[str, Any]:
        """èª¿é”ã‚’ä¾é ¼"""
        logger.info(f"Requesting procurement for {products}")
        order_id = str(uuid4())
        return {
            "order_id": order_id,
            "products": products,
            "quantity": quantity,
            "status": "pending",
            "estimated_delivery": (datetime.now() + timedelta(days=3)).isoformat(),
        }

    def schedule_maintenance(self, task: str, date: str) -> Dict[str, Any]:
        """ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"""
        logger.info(f"Scheduling maintenance: {task} on {date}")
        return {"success": True, "task": task, "scheduled_date": date}

    async def coordinate_employee_tasks(self) -> Dict[str, Any]:
        """ç™ºæ³¨/è£œå……ãŒå¿…è¦ãªå ´åˆã«å¾“æ¥­å“¡1äººã«ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ + æ–°å•†å“ç™ºæ³¨å‡¦ç†"""
        logger.info("Coordinating employee tasks")

        notifications = []
        employees_status = {}

        # === 1. åœ¨åº«è£œå……ã‚¿ã‚¹ã‚¯ ===
        inventory_status = await self.check_inventory_status()
        low_stock_items = inventory_status.get("low_stock_items", [])

        if low_stock_items:
            notification = {
                "recipient": "employee@vending-company.com",
                "subject": "åœ¨åº«è£œå……ä¾é ¼",
                "body": f"ä»¥ä¸‹ã®å•†å“ãŒåœ¨åº«ä¸è¶³ã§ã™ã€‚è£œå……ã‚’ãŠé¡˜ã„ã—ã¾ã™: {', '.join(low_stock_items)}",
                "priority": "normal",
                "timestamp": datetime.now().isoformat(),
                "task_type": "restock",
            }
            notifications.append(notification)
            employees_status["restock"] = low_stock_items
            logger.info(f"åœ¨åº«è£œå……é€šçŸ¥é€ä¿¡: {low_stock_items}")

        # === 2. æ–°å•†å“ç™ºæ³¨ã‚¿ã‚¹ã‚¯ ===
        # åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«æ–°å•†å“æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
        try:
            # åœ¨åº«çŠ¶æ³ã‹ã‚‰å•†å“ã‚«ãƒ†ã‚´ãƒªã‚’æŠŠæ¡
            metrics = self.get_business_metrics()
            inventory_level = metrics.get("inventory_level", {})
            sales = metrics.get("sales", 0)

            # ã‚«ãƒ†ã‚´ãƒªåˆ¥åœ¨åº«ã‚’ç¢ºèª
            drink_categories = [
                item
                for item in inventory_level.keys()
                if "ã‚³ãƒ¼ãƒ©" in item or "é£²æ–™" in item or "ã‚¸ãƒ¥ãƒ¼ã‚¹" in item
            ]
            food_categories = [
                item
                for item in inventory_level.keys()
                if "ãƒãƒƒãƒ—ã‚¹" in item or "ãƒŒãƒ¼ãƒ‰ãƒ«" in item or "ãŠè“å­" in item
            ]

            # å£²ä¸Šå®Ÿç¸¾ã«åŸºã¥ã„ã¦æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ±ºå®š
            if sales > 1000:  # å£²ä¸ŠãŒè‰¯ã„å ´åˆ
                search_query = "äººæ°—é£²æ–™ æ–°å•†å“"
                logger.info("å£²ä¸Šå¥½èª¿ã®ãŸã‚ã€æ–°å•†å“é£²æ–™ã‚’æ¤œç´¢")
            elif (
                drink_categories
                and min([inventory_level.get(cat, 0) for cat in drink_categories]) < 5
            ):  # é£²æ–™åœ¨åº«ãŒå°‘ãªã„å ´åˆ
                search_query = "äººæ°—æ¸…æ¶¼é£²æ–™ ãƒœãƒˆãƒ«é£²æ–™"
                logger.info("é£²æ–™åœ¨åº«ä¸è¶³ã®ãŸã‚ã€ä¾›çµ¦å®‰å®šã—ãŸé£²æ–™ã‚’æ¤œç´¢")
            elif food_categories:
                search_query = "äººæ°—ã‚¹ãƒŠãƒƒã‚¯ å¥åº·å¿—å‘"
                logger.info("æ—¢å­˜é£Ÿå“ã‚’è£œå®Œã™ã‚‹äººæ°—ã‚¹ãƒŠãƒƒã‚¯ã‚’æ¤œç´¢")
            else:
                search_query = "äººæ°—é£²æ–™"
                logger.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§äººæ°—é£²æ–™ã‚’æ¤œç´¢")

            logger.info(f"ç”Ÿæˆã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒª: {search_query}")

            # Shared Toolsã‹ã‚‰å•†å“æ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨
            from src.agents.shared_tools import shared_registry

            search_tool = shared_registry.get_tool("market_search")
            if search_tool:
                search_results = await search_tool.asearch(query=search_query)
                logger.info(
                    f"æ¤œç´¢çµæœå–å¾—: {len(search_results) if search_results else 0}ä»¶ (ã‚¯ã‚¨ãƒª: {search_query})"
                )
                recommended_products = (
                    search_results[:2] if search_results else []
                )  # ä¸Šä½2ã¤
            else:
                recommended_products = []
                logger.warning("æ¤œç´¢ãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

            if recommended_products:
                procurement_tasks = []
                for product in recommended_products[:2]:  # dictå½¢å¼ã‚’æƒ³å®š
                    # Procurement Agentã‹ã‚‰Shared Toolsã«å¤‰æ›´
                    procurement_tool = shared_registry.get_tool("procurement_order")
                    if procurement_tool:
                        procurement_result = await procurement_tool.aexecute(
                            product_info={
                                "product_name": product.get("name", "") or product,
                                "recommended_quantity": 10,
                            },
                            supplier_info={
                                "name": "Search Supplier",
                                "url": product.get("url", ""),
                                "price": product.get("price", 150),
                            },
                        )

                        if procurement_result.get("success"):
                            order = procurement_result.get("order", {})
                            procurement_tasks.append(
                                {
                                    "product": product.get("name", "") or product,
                                    "order_id": order.get("order_id", "unknown"),
                                }
                            )

                if procurement_tasks:
                    procurement_notification = {
                        "recipient": "employee@vending-company.com",
                        "subject": "æ–°å•†å“ç™ºæ³¨å®Œäº†é€šçŸ¥",
                        "body": f"ä»¥ä¸‹ã®æ–°å•†å“ã‚’ç™ºæ³¨ã—ã¾ã—ãŸã€‚å…¥è·ç®¡ç†ã‚’ãŠé¡˜ã„ã—ã¾ã™:\n"
                        + "\n".join(
                            [
                                f"- {t['product']} (æ³¨æ–‡ID: {t['order_id']})"
                                for t in procurement_tasks
                            ]
                        ),
                        "priority": "high",
                        "timestamp": datetime.now().isoformat(),
                        "task_type": "new_procurement",
                        "orders": procurement_tasks,
                    }
                    notifications.append(procurement_notification)
                    employees_status["new_procurement"] = [
                        t["product"] for t in procurement_tasks
                    ]
                    logger.info(f"æ–°å•†å“ç™ºæ³¨é€šçŸ¥é€ä¿¡: {len(procurement_tasks)}ä»¶")

        except Exception as e:
            logger.error(f"æ–°å•†å“ç™ºæ³¨ãƒ—ãƒ­ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")

        # === çµæœè¿”å´ ===
        if notifications:
            return {
                "active_tasks": len(notifications),
                "completed_today": 0,
                "pending": len(notifications),
                "notifications_sent": notifications,
                "employees": {"employee@vending-company.com": employees_status},
            }
        else:
            return {
                "active_tasks": 0,
                "completed_today": 0,
                "pending": 0,
                "notifications_sent": [],
                "employees": {"employee@vending-company.com": "ç‰¹è¨˜äº‹é …ãªã—"},
            }

    def respond_to_customer_inquiry(
        self, customer_id: str, inquiry: str
    ) -> Dict[str, Any]:
        """é¡§å®¢å•ã„åˆã‚ã›ã«å¯¾å¿œ"""
        logger.info(f"Responding to customer {customer_id} inquiry")
        return {
            "customer_id": customer_id,
            "inquiry": inquiry,
            "response": "ãŠå•ã„åˆã‚ã›ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚æ‹…å½“è€…ãŒç¢ºèªã—ã¦æŠ˜ã‚Šè¿”ã—ã”é€£çµ¡ã„ãŸã—ã¾ã™ã€‚",
            "status": "responded",
        }

    def handle_customer_complaint(
        self, customer_id: str, complaint: str
    ) -> Dict[str, Any]:
        """é¡§å®¢è‹¦æƒ…ã‚’å‡¦ç†"""
        logger.info(f"Handling complaint from customer {customer_id}")
        return {
            "customer_id": customer_id,
            "complaint": complaint,
            "resolution": "å•†å“ã®è¿”é‡‘å‡¦ç†ã‚’è¡Œã„ã€æ¬¡å›ä½¿ç”¨å¯èƒ½ãªã‚¯ãƒ¼ãƒãƒ³ã‚’ç™ºè¡Œã—ã¾ã—ãŸã€‚",
            "status": "resolved",
            "compensation": "500å††ã‚¯ãƒ¼ãƒãƒ³",
        }

    def collect_customer_feedback(self) -> Dict[str, Any]:
        """é¡§å®¢ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åé›†"""
        logger.info("Collecting customer feedback")
        return {
            "feedback_count": 15,
            "average_rating": 4.2,
            "top_requests": ["æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒãƒ¼", "æ¸©ã‹ã„é£²ã¿ç‰©", "å¥åº·å¿—å‘å•†å“"],
            "trends": "å¥åº·å¿—å‘å•†å“ã¸ã®é–¢å¿ƒãŒé«˜ã¾ã£ã¦ã„ã‚‹",
        }

    def create_customer_engagement_campaign(self, campaign_type: str) -> Dict[str, Any]:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’ä½œæˆ"""
        logger.info(f"Creating {campaign_type} campaign")
        return {
            "campaign_type": campaign_type,
            "target": "å…¨é¡§å®¢",
            "duration": "2é€±é–“",
            "expected_impact": "å£²ä¸Š10%å¢—",
            "status": "planned",
        }

    async def start_management_session(self, session_type: str) -> str:
        """ç®¡ç†ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹"""
        session_id = str(uuid4())
        self.current_session = SessionInfo(
            session_id=session_id, session_type=session_type, start_time=datetime.now()
        )

        logger.info(f"Started {session_type} session: {session_id}")
        return session_id

    async def end_management_session(self) -> Dict[str, Any]:
        """ç®¡ç†ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†"""
        if not self.current_session:
            raise ValueError("No active session")

        self.current_session.end_time = datetime.now()
        duration = self.current_session.end_time - self.current_session.start_time

        session_summary = {
            "session_id": self.current_session.session_id,
            "session_type": self.current_session.session_type,
            "duration": str(duration),
            "decisions_count": len(self.current_session.decisions_made),
            "actions_count": len(self.current_session.actions_executed),
        }

        logger.info(f"Ended session {self.current_session.session_id}")
        self.current_session = None

        return session_summary

    @conditional_traceable(name="strategic_decision")
    async def make_strategic_decision(self, context: str) -> Dict[str, Any]:
        """æˆ¦ç•¥çš„æ„æ€æ±ºå®šã‚’è¡Œã†ï¼ˆmodel_managerçµŒç”±ï¼‰"""
        if not self.current_session:
            raise ValueError("No active session. Start a session first.")

        logger.info("Making strategic decision using model_manager")

        # ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        trace_metadata = {
            "session_id": self.current_session.session_id
            if self.current_session
            else "unknown",
            "session_type": self.current_session.session_type
            if self.current_session
            else "unknown",
            "context_length": len(context),
            "context_preview": context[:200] + "..." if len(context) > 200 else context,
            "start_time": datetime.now().isoformat(),
            "agent_type": "management_agent",
            "decision_phase": "strategic_planning",
        }

        try:
            # LLMã«æ¸¡ã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
            user_content = f"""
ä»¥ä¸‹ã®ãƒ“ã‚¸ãƒã‚¹çŠ¶æ³ã‚’åˆ†æã—ã€æˆ¦ç•¥çš„æ„æ€æ±ºå®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€çŠ¶æ³ã€‘
{context}

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
    "decision": "æ±ºå®šäº‹é …ã®ç°¡æ½”ãªè¦ç´„",
    "rationale": "æ±ºå®šã®æ ¹æ‹ ã¨ç†ç”±",
    "actions": ["å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³1", "å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³2"]
}}
```

æ³¨æ„: JSONå½¢å¼ã®ã¿ã§å›ç­”ã—ã€ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚
"""

            messages = [
                self.llm_manager.create_ai_message(
                    role="system", content=self.system_prompt
                ),
                self.llm_manager.create_ai_message(role="user", content=user_content),
            ]

            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹ã‚’å‡ºåŠ›ï¼ˆåˆå›ã®ã¿ï¼‰
            if not self._system_prompt_logged:
                logger.debug("=== LLM PROMPT ===")
                logger.debug(
                    f"System Prompt: {self.system_prompt[:500]}..."
                )  # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯é•·ã™ãã‚‹ã®ã§ä¸€éƒ¨ã®ã¿
                logger.debug(f"User Content: {user_content}")
                logger.debug("=== END PROMPT ===")
                self._system_prompt_logged = True
            else:
                logger.debug("LLM called with established system prompt")

            # model_managerçµŒç”±ã§LLMå‘¼ã³å‡ºã— (æ³¨å…¥ã•ã‚ŒãŸllm_managerã‚’ä½¿ç”¨)
            response = await self.llm_manager.generate_response(
                messages, max_tokens=1000
            )

            if not response.success:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ±ºå®šã‚’ä½¿ç”¨
                logger.warning(
                    f"LLMå‘¼ã³å‡ºã—å¤±æ•— ({response.error_message})ã€ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ±ºå®šã‚’ä½¿ç”¨"
                )
                decision = {
                    "context": context,
                    "decision": "åœ¨åº«æ°´æº–ã‚’ç¶­æŒã—ã¤ã¤ã€å£²ã‚Œç­‹å•†å“ã®ä¾¡æ ¼ã‚’æœ€é©åŒ–ã™ã‚‹",
                    "rationale": "ãƒ‡ãƒ¼ã‚¿åˆ†æã®çµæœã€ä¾¡æ ¼èª¿æ•´ã«ã‚ˆã‚Šåˆ©ç›Šç‡5%æ”¹å–„ãŒè¦‹è¾¼ã‚ã‚‹",
                    "actions": ["ä¾¡æ ¼æ›´æ–°", "åœ¨åº«è£œå……ä¾é ¼"],
                    "timestamp": datetime.now().isoformat(),
                }
            else:
                # LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
                try:
                    import json

                    # JSONéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆï¼‰
                    content = response.content.strip()
                    if content.startswith("```json"):
                        content = content[7:]  # ```jsonã‚’å‰Šé™¤
                    if content.endswith("```"):
                        content = content[:-3]  # ```ã‚’å‰Šé™¤
                    content = content.strip()

                    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°: LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ã‚’å‡ºåŠ›
                    logger.debug("=== LLM RESPONSE ===")
                    logger.debug(f"Raw Response: {content}")
                    logger.debug("=== END RESPONSE ===")

                    llm_response = json.loads(content)

                    decision = {
                        "context": context,
                        "decision": llm_response.get(
                            "decision", "æ±ºå®šã§ãã¾ã›ã‚“ã§ã—ãŸ"
                        ),
                        "rationale": llm_response.get("rationale", "ç†ç”±ä¸æ˜"),
                        "actions": llm_response.get("actions", []),
                        "timestamp": datetime.now().isoformat(),
                        "llm_used": response.model_used,
                    }

                    logger.info(f"LLMæ„æ€æ±ºå®šå®Œäº†: {decision['decision']}")
                    logger.debug(
                        f"LLMæ„æ€æ±ºå®šè©³ç´°: rationale='{decision['rationale']}', actions={decision.get('actions', [])}"
                    )

                except json.JSONDecodeError as e:
                    logger.error(f"LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹å¤±æ•—: {e}")
                    logger.error(f"LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹: {response.content}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    decision = {
                        "context": context,
                        "decision": "åœ¨åº«æ°´æº–ã‚’ç¶­æŒã—ã¤ã¤ã€å£²ã‚Œç­‹å•†å“ã®ä¾¡æ ¼ã‚’æœ€é©åŒ–ã™ã‚‹",
                        "rationale": f"LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ±ºå®šã‚’ä½¿ç”¨: {response.content[:200]}",
                        "actions": ["ä¾¡æ ¼æ›´æ–°", "åœ¨åº«è£œå……ä¾é ¼"],
                        "timestamp": datetime.now().isoformat(),
                    }

        except Exception as e:
            logger.error(f"æˆ¦ç•¥çš„æ„æ€æ±ºå®šä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}", exc_info=True)
            decision = {
                "context": context,
                "decision": "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ„æ€æ±ºå®š",
                "rationale": f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "actions": ["ç®¡ç†è€…ã¸ã®é€£çµ¡"],
                "timestamp": datetime.now().isoformat(),
            }

        # Execute actions using system data
        executed_actions = []
        for action in decision.get("actions", []):
            if "åœ¨åº«è£œå……" in action or "è£œå……" in action:
                try:
                    inventory_status = await self.check_inventory_status()
                    low_stock_items = inventory_status.get("low_stock_items", [])
                    if low_stock_items:
                        result = self.assign_restocking_task(
                            low_stock_items, urgency="normal"
                        )
                        executed_actions.append(
                            f"Executed restocking for {low_stock_items}, task_id: {result.get('task_id')}"
                        )
                except Exception as e:
                    logger.error(f"Error executing restocking: {e}")
            elif "ä¾¡æ ¼æ›´æ–°" in action or "ä¾¡æ ¼" in action:
                try:
                    if SAMPLE_PRODUCTS:
                        product = SAMPLE_PRODUCTS[0]  # Using first registered product
                        new_price = round(product.price * 1.05, 0)  # Example adjustment
                        result = self.update_pricing(product.product_id, new_price)
                        executed_actions.append(
                            f"Executed pricing update for {product.product_id} to Â¥{new_price}"
                        )
                except Exception as e:
                    logger.error(f"Error executing pricing update: {e}")
            else:
                executed_actions.append(f"Action '{action}' not executable")

        # Log executed actions
        for ea in executed_actions:
            logger.info(f"Executed action: {ea}")

        decision["executed_actions"] = executed_actions

        self.current_session.decisions_made.append(decision)
        return decision

    # Case A node functions (LangGraph Stateful Functions - agent_design.mdæº–æ‹ )

    @conditional_traceable(name="memory_enhanced_inventory_analysis")
    async def inventory_check_node(self, state: ManagementState) -> ManagementState:
        """åœ¨åº«ç¢ºèªnodeã®LangGraph Statefulé–¢æ•° - LLMãƒ™ãƒ¼ã‚¹ã®åœ¨åº«åˆ†æã‚’å®Ÿè¡Œ"""
        logger.info(f"âœ… åœ¨åº«ç¢ºèªé–‹å§‹: step={state.current_step}")

        # ãƒãƒ¼ãƒ‰é–‹å§‹æ™‚ã®å…¥åŠ›çŠ¶æ…‹ã‚’è¨˜éŒ²ï¼ˆçŠ¶æ…‹å¤‰æ›´å‰ã«è¨˜éŒ²ï¼‰
        input_state_snapshot = {
            "session_id": state.session_id,
            "session_type": state.session_type,
            "current_step": state.current_step,
            "business_date": state.business_date.isoformat()
            if state.business_date
            else None,
            "processing_status": state.processing_status,
            "business_metrics": state.business_metrics.dict()
            if state.business_metrics
            else None,
            "inventory_analysis": state.inventory_analysis,
            "sales_analysis": state.sales_analysis,
            "financial_analysis": state.financial_analysis,
            "executed_actions_count": len(state.executed_actions),
            "errors_count": len(state.errors),
        }

        # ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆå…¥åŠ›çŠ¶æ…‹ã‚’å«ã‚€ï¼‰
        trace_metadata = {
            "input_state": input_state_snapshot,
            "start_time": datetime.now().isoformat(),
            "agent_type": "management_agent",
            "node_type": "inventory_analysis",
            "expected_next_step": "inventory_check",
        }

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
            state.current_step = "inventory_check"
            state.processing_status = "processing"

            # ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆäº‹å‰æŠ•å…¥ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆï¼‰
            if state.business_metrics:
                # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒäº‹å‰æŠ•å…¥ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
                metrics = {
                    "sales": state.business_metrics.sales,
                    "profit_margin": state.business_metrics.profit_margin,
                    "inventory_level": state.business_metrics.inventory_level,
                    "customer_satisfaction": state.business_metrics.customer_satisfaction,
                    "timestamp": state.business_metrics.timestamp,
                }
                logger.info("Using pre-loaded test business metrics")
            else:
                # æœ¬ç•ªæ™‚ã¯å®Ÿéš›ã®ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å–å¾—
                metrics = self.get_business_metrics()
                state.business_metrics = BusinessMetrics(**metrics)

            # ãƒ¡ãƒ¢ãƒªãƒ¼æ´»ç”¨: éå»ã®åœ¨åº«åˆ†ææ´å¯Ÿã‚’å–å¾—
            memory_context = self._get_memory_context("inventory_check")

            # LLMãƒ™ãƒ¼ã‚¹ã®åœ¨åº«åˆ†æã‚’å®Ÿæ–½ (ãƒ¡ãƒ¢ãƒªãƒ¼å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ)
            inventory_data = metrics.get("inventory_level", {})

            enhanced_prompt = f"""
ä»¥ä¸‹ã®ç¾åœ¨ã®åœ¨åº«çŠ¶æ³ã‚’åˆ†æã—ã€åœ¨åº«ç®¡ç†ã®ç·åˆè©•ä¾¡ã¨æ”¹å–„ææ¡ˆã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€ç¾åœ¨ã®åœ¨åº«çŠ¶æ³ã€‘ (å•†å“å: æ•°é‡)
{inventory_data}

ã€éå»ã®åˆ†ææ´å¯Ÿã€‘ (å‚è€ƒæƒ…å ±)
{memory_context}

ã€åˆ†æé …ç›®ã€‘
- åœ¨åº«å…¨ä½“ã®å¥å…¨æ€§è©•ä¾¡ (normal/critical/low)
- åœ¨åº«åˆ‡ã‚Œãƒªã‚¹ã‚¯ã®ã‚ã‚‹å•†å“ã¨äºˆæƒ³ã‚¿ã‚¤ãƒŸãƒ³ã‚°
- è£œå……ãŒå¿…è¦ãªå•†å“ãƒªã‚¹ãƒˆ
- éå‰°åœ¨åº«ãŒã‚ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹å•†å“
- éå»ã®åˆ†æçµæœã¨ã®æ•´åˆæ€§ç¢ºèª
- æ¨å¥¨ã•ã‚Œã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

ã€åˆ†æã®è€ƒæ…®ç‚¹ã€‘
- éå»ã®å£²ä¸Šå‚¾å‘ã¨ã®é–¢é€£æ€§
- å­£ç¯€çš„ãªéœ€è¦å¤‰å‹•ã®è€ƒæ…®
- åœ¨åº«å›è»¢ç‡ã®æ”¹å–„æ©Ÿä¼š

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
    "inventory_status": "å…¨ä½“è©•ä¾¡",
    "critical_items": ["å±æ©Ÿçš„ãªå•†å“ãƒªã‚¹ãƒˆ"],
    "low_stock_items": ["è£œå……å„ªå…ˆå•†å“ãƒªã‚¹ãƒˆ"],
    "reorder_needed": ["ç™ºæ³¨ãŒå¿…è¦ãªå•†å“ãƒªã‚¹ãƒˆ"],
    "stockout_risks": {{"å•†å“å": "åœ¨åº«åˆ‡ã‚Œäºˆæƒ³ã‚¿ã‚¤ãƒŸãƒ³ã‚°"}},
    "recommended_actions": ["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒªã‚¹ãƒˆ"],
    "analysis": "åœ¨åº«çŠ¶æ³ã®è©³ç´°åˆ†æã¨è§£èª¬ï¼ˆéå»ã®æ´å¯Ÿã‚’è¸ã¾ãˆãŸè©•ä¾¡ã‚’å«ã‚€ï¼‰"
}}
```
"""

            messages = [
                self.llm_manager.create_ai_message(
                    role="system", content=self.system_prompt
                ),
                self.llm_manager.create_ai_message(
                    role="user", content=enhanced_prompt
                ),
            ]

            # LangSmithãƒˆãƒ¬ãƒ¼ã‚¹:
            logger.info("LangSmithãƒˆãƒ¬ãƒ¼ã‚¹: åœ¨åº«åˆ†æ - memory_contextã‚’åˆ©ç”¨")

            try:
                response = await self.llm_manager.generate_response(
                    messages, max_tokens=1500
                )

                if response.success:
                    import json

                    content = response.content.strip()
                    if content.startswith("```json"):
                        content = content[7:]
                    if content.endswith("```"):
                        content = content[:-3]
                    content = content.strip()

                    analysis_result = json.loads(content)

                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
                    analysis_result.setdefault("inventory_status", "normal")
                    analysis_result.setdefault("critical_items", [])
                    analysis_result.setdefault("low_stock_items", [])
                    analysis_result.setdefault("reorder_needed", [])
                    analysis_result.setdefault("stockout_risks", {})
                    analysis_result.setdefault("recommended_actions", ["åœ¨åº«çŠ¶æ³ç¢ºèª"])
                    analysis_result.setdefault("analysis", "LLMã«ã‚ˆã‚‹åœ¨åº«åˆ†æå®Ÿæ–½")

                    logger.info(
                        f"LLMåœ¨åº«åˆ†ææˆåŠŸ: {analysis_result['inventory_status']}, ãƒ¡ãƒ¢ãƒªãƒ¼çµ±åˆæº–å‚™å®Œäº†"
                    )

                    # ãƒ¡ãƒ¢ãƒªãƒ¼ä¿å­˜: åœ¨åº«åˆ†æçµæœã‹ã‚‰æ´å¯Ÿã‚’æŠ½å‡ºã—ä¿å­˜
                    llm_response_raw = json.dumps(
                        analysis_result
                    )  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’æ¸¡ã™
                    self._extract_and_save_business_insight(
                        "inventory_check", llm_response_raw
                    )
                else:
                    # LLMå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    logger.warning(f"LLMåœ¨åº«åˆ†æå¤±æ•—: {response.error_message}")
                    analysis_result = {
                        "inventory_status": "normal",
                        "critical_items": [],
                        "low_stock_items": ["water"] if len(inventory_data) > 0 else [],
                        "reorder_needed": ["water"] if len(inventory_data) > 0 else [],
                        "stockout_risks": {"water": "æ•°æ—¥å¾Œ"}
                        if len(inventory_data) > 0
                        else {},
                        "recommended_actions": ["åœ¨åº«çŠ¶æ³ç¢ºèª"],
                        "analysis": "LLMåˆ†æä¸å¯ã€æœ¬ç•ªãƒ‡ãƒ¼ã‚¿å¾…æ©Ÿ",
                    }
            except Exception as e:
                logger.error(f"åœ¨åº«åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                # å®Œå…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                total_products = len(inventory_data)
                analysis_result = {
                    "inventory_status": "normal",
                    "critical_items": [],
                    "low_stock_items": list(inventory_data.keys())[
                        : min(3, total_products)
                    ]
                    if total_products > 0
                    else [],
                    "reorder_needed": list(inventory_data.keys())[
                        : min(3, total_products)
                    ]
                    if total_products > 0
                    else [],
                    "stockout_risks": {list(inventory_data.keys())[0]: "1é€±é–“å¾Œ"}
                    if total_products > 0
                    else {},
                    "recommended_actions": ["åœ¨åº«çŠ¶æ³ç¢ºèª"],
                    "analysis": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
                }

            # Stateæ›´æ–°
            state.inventory_analysis = {
                "status": analysis_result.get("inventory_status", "unknown"),
                "low_stock_items": analysis_result.get("low_stock_items", []),
                "reorder_needed": analysis_result.get("reorder_needed", []),
                "estimated_stockout": analysis_result.get("stockout_risks", {}),
                "critical_items": analysis_result.get("critical_items", []),
                "recommended_actions": analysis_result.get("recommended_actions", []),
                "llm_analysis": analysis_result.get("analysis", ""),
                "analysis_timestamp": datetime.now().isoformat(),
            }

            # ãƒ­ã‚°å‡ºåŠ›
            total_low = len(state.inventory_analysis.get("low_stock_items", [])) + len(
                state.inventory_analysis.get("critical_items", [])
            )
            logger.info(
                f"âœ… åœ¨åº«ç¢ºèªå®Œäº†: åˆ†æé …ç›®={total_low}, ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹={analysis_result['inventory_status']}"
            )

        except Exception as e:
            logger.error(f"Statefulåœ¨åº«ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            state.errors.append(f"inventory_check: {str(e)}")
            state.processing_status = "error"

        return state

    @conditional_traceable(name="memory_enhanced_sales_plan_analysis")
    async def sales_plan_node(self, state: ManagementState) -> ManagementState:
        """å£²ä¸Šè¨ˆç”»nodeã®LangGraph Statefulé–¢æ•° - è²¡å‹™ãƒ»å£²ä¸Šåˆ†æã‚’å®Ÿè¡Œ"""
        logger.info(f"âœ… å£²ä¸Šè¨ˆç”»é–‹å§‹: step={state.current_step}")

        # ãƒãƒ¼ãƒ‰é–‹å§‹æ™‚ã®å…¥åŠ›çŠ¶æ…‹ã‚’è¨˜éŒ²ï¼ˆçŠ¶æ…‹å¤‰æ›´å‰ã«è¨˜éŒ²ï¼‰
        input_state_snapshot = {
            "session_id": state.session_id,
            "session_type": state.session_type,
            "current_step": state.current_step,
            "business_date": state.business_date.isoformat()
            if state.business_date
            else None,
            "processing_status": state.processing_status,
            "business_metrics": state.business_metrics.dict()
            if state.business_metrics
            else None,
            "inventory_analysis": state.inventory_analysis,
            "executed_actions_count": len(state.executed_actions),
            "errors_count": len(state.errors),
        }

        # ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆå…¥åŠ›çŠ¶æ…‹ã‚’å«ã‚€ï¼‰
        trace_metadata = {
            "input_state": input_state_snapshot,
            "start_time": datetime.now().isoformat(),
            "agent_type": "management_agent",
            "node_type": "sales_plan_analysis",
            "expected_next_step": "sales_plan",
        }

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
            state.current_step = "sales_plan"
            state.processing_status = "processing"

            # ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            metrics = self.get_business_metrics()
            if not state.business_metrics:
                state.business_metrics = BusinessMetrics(**metrics)

            # LLMãƒ™ãƒ¼ã‚¹ã®å£²ä¸Šãƒ»è²¡å‹™åˆ†æã‚’å®Ÿæ–½
            messages = [
                self.llm_manager.create_ai_message(
                    role="system", content=self.system_prompt
                ),
                self.llm_manager.create_ai_message(
                    role="user",
                    content=f"""
ä»¥ä¸‹ã®ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åˆ†æã—ã€å£²ä¸Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã¨æˆ¦ç•¥çš„æ¨å¥¨ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€ç¾åœ¨ã®ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€‘
- å£²ä¸Š: Â¥{metrics.get("sales", 0):,}
- åˆ©ç›Šç‡: {metrics.get("profit_margin", 0):.1%}
- é¡§å®¢æº€è¶³åº¦: {metrics.get("customer_satisfaction", 3.0)}/5.0

ã€åˆ†æé …ç›®ã€‘
- å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰ã®è©•ä¾¡ (positive/stable/concerning)
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è©³ç´°è©•ä¾¡
- æ¨å¥¨ã•ã‚Œã‚‹æˆ¦ç•¥çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
- æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„åŠ¹æœã¨ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
    "sales_trend": "å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰è©•ä¾¡",
    "sales_performance": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è©³ç´°èª¬æ˜",
    "financial_analysis": {{
        "sales": "å£²ä¸Šæ•°å€¤",
        "profit_margin": "åˆ©ç›Šç‡æ•°å€¤",
        "customer_satisfaction": "é¡§å®¢æº€è¶³åº¦æ•°å€¤",
        "analysis_timestamp": "åˆ†ææ™‚åˆ»"
    }},
    "strategies": ["æˆ¦ç•¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1", "æˆ¦ç•¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2", "æˆ¦ç•¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³3"],
    "expected_impact": "æ”¹å–„åŠ¹æœã®å…¨ä½“è©•ä¾¡",
    "timeline": "å®Ÿæ–½ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³",
    "analysis": "ç·åˆçš„ãªåˆ†æã¨è§£èª¬ï¼ˆ100æ–‡å­—ä»¥ä¸Šï¼‰"
}}
```
""",
                ),
            ]

            try:
                response = await self.llm_manager.generate_response(
                    messages, max_tokens=1500
                )

                if response.success:
                    import json

                    content = response.content.strip()
                    if content.startswith("```json"):
                        content = content[7:]
                    if content.endswith("```"):
                        content = content[:-3]
                    content = content.strip()

                    analysis_result = json.loads(content)

                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
                    analysis_result.setdefault("sales_trend", "unknown")
                    analysis_result.setdefault("sales_performance", "åˆ†ææœªå®Œäº†")
                    analysis_result.setdefault(
                        "financial_analysis",
                        {
                            "sales": metrics.get("sales", 0),
                            "profit_margin": metrics.get("profit_margin", 0),
                            "customer_satisfaction": metrics.get(
                                "customer_satisfaction", 3.0
                            ),
                            "analysis_timestamp": datetime.now().isoformat(),
                        },
                    )
                    analysis_result.setdefault("strategies", [])
                    analysis_result.setdefault("expected_impact", "åˆ†ææœªå®Œäº†")
                    analysis_result.setdefault("timeline", "æœªè¨­å®š")
                    analysis_result.setdefault(
                        "analysis", "LLMã«ã‚ˆã‚‹å£²ä¸Šãƒ»è²¡å‹™åˆ†æå®Ÿæ–½"
                    )

                    strategies = analysis_result["strategies"]
                    sales_trend = analysis_result["sales_trend"]
                    financial_analysis_result = analysis_result["financial_analysis"]

                    logger.info(f"LLMå£²ä¸Šè¨ˆç”»åˆ†ææˆåŠŸ: trend={sales_trend}")
                else:
                    # LLMå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    logger.warning(f"LLMå£²ä¸Šè¨ˆç”»åˆ†æå¤±æ•—: {response.error_message}")
                    analysis_result = {
                        "sales_trend": "unknown",
                        "sales_performance": "LLMåˆ†æä¸å¯ã€æœ¬ç•ªãƒ‡ãƒ¼ã‚¿å¾…æ©Ÿ",
                        "financial_analysis": {
                            "sales": metrics.get("sales", 0),
                            "profit_margin": metrics.get("profit_margin", 0),
                            "customer_satisfaction": metrics.get(
                                "customer_satisfaction", 3.0
                            ),
                            "analysis_timestamp": datetime.now().isoformat(),
                        },
                        "strategies": ["åŸºæœ¬æˆ¦ç•¥æ¤œè¨"],
                        "expected_impact": "åˆ†ææœªå®Œäº†",
                        "timeline": "æœªè¨­å®š",
                        "analysis": f"LLMåˆ†æã‚¨ãƒ©ãƒ¼: {response.error_message}",
                    }
                    strategies = analysis_result["strategies"]
                    sales_trend = analysis_result["sales_trend"]
                    financial_analysis_result = analysis_result["financial_analysis"]
            except Exception as e:
                logger.error(f"å£²ä¸Šè¨ˆç”»åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                # å®Œå…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                sales_trend = "unknown"
                strategies = ["åŸºæœ¬æˆ¦ç•¥æ¤œè¨"]
                financial_analysis_result = {
                    "sales": metrics.get("sales", 0),
                    "profit_margin": metrics.get("profit_margin", 0),
                    "customer_satisfaction": metrics.get("customer_satisfaction", 3.0),
                    "analysis_timestamp": datetime.now().isoformat(),
                }
                analysis_result = {
                    "sales_performance": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
                    "expected_impact": "åˆ†æå¤±æ•—",
                    "timeline": "æœªè¨­å®š",
                    "analysis": f"ã‚¨ãƒ©ãƒ¼åˆ†æ: {str(e)}",
                }

            # Stateæ›´æ–°
            state.sales_analysis = {
                "financial_overview": f"{metrics.get('profit_margin', 0):.1%}åˆ©ç›Šç‡ãƒ»å£²ä¸Š{metrics.get('sales', 0):,.0f}",
                "sales_trend": sales_trend,
                "profit_analysis": financial_analysis_result,
                "strategies": strategies,
                "action_plan": [f"æˆ¦ç•¥: {s}" for s in strategies],
                "expected_impact": f"{len(strategies)}å€‹ã®æ”¹å–„æ–½ç­–ã‚’å®Ÿæ–½",
                "timeline": "æ¬¡å›ã®çµŒå–¶ä¼šè­°ã§å®Ÿæ–½",
                "analysis_timestamp": datetime.now().isoformat(),
            }

            state.financial_analysis = financial_analysis_result

            # ãƒ­ã‚°å‡ºåŠ›
            logger.info(
                f"âœ… å£²ä¸Šè¨ˆç”»å®Œäº†: trend={sales_trend}, strategies={len(strategies)}"
            )

        except Exception as e:
            logger.error(f"Statefulå£²ä¸Šè¨ˆç”»ã‚¨ãƒ©ãƒ¼: {e}")
            state.errors.append(f"sales_plan: {str(e)}")
            state.processing_status = "error"

        return state

    async def pricing_node(self, state: ManagementState) -> ManagementState:
        """ä¾¡æ ¼æˆ¦ç•¥æ±ºå®šnodeã®LangGraph Statefulé–¢æ•° - LLMãƒ™ãƒ¼ã‚¹ã®ä¾¡æ ¼æ±ºå®šã‚’å®Ÿè¡Œ"""
        logger.info(f"âœ… ä¾¡æ ¼æˆ¦ç•¥é–‹å§‹: step={state.current_step}")

        # ãƒãƒ¼ãƒ‰é–‹å§‹æ™‚ã®å…¥åŠ›çŠ¶æ…‹ã‚’è¨˜éŒ²ï¼ˆçŠ¶æ…‹å¤‰æ›´å‰ã«è¨˜éŒ²ï¼‰
        input_state_snapshot = {
            "session_id": state.session_id,
            "session_type": state.session_type,
            "current_step": state.current_step,
            "business_date": state.business_date.isoformat()
            if state.business_date
            else None,
            "processing_status": state.processing_status,
            "business_metrics": state.business_metrics.dict()
            if state.business_metrics
            else None,
            "sales_analysis": state.sales_analysis,
            "financial_analysis": state.financial_analysis,
            "inventory_analysis": state.inventory_analysis,
            "executed_actions_count": len(state.executed_actions),
            "errors_count": len(state.errors),
        }

        # ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆå…¥åŠ›çŠ¶æ…‹ã‚’å«ã‚€ï¼‰
        trace_metadata = {
            "input_state": input_state_snapshot,
            "start_time": datetime.now().isoformat(),
            "agent_type": "management_agent",
            "node_type": "pricing_decision",
            "expected_next_step": "pricing",
        }

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
            state.current_step = "pricing"
            state.processing_status = "processing"

            # å‰æåˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            sales_analysis = state.sales_analysis
            financial_analysis = state.financial_analysis
            inventory_analysis = state.inventory_analysis

            if not sales_analysis or not financial_analysis:
                logger.warning("å‰æåˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                state.errors.append("pricing: å‰æåˆ†æãƒ‡ãƒ¼ã‚¿ãªã—")
                state.processing_status = "error"
                return state

            # LLMãƒ™ãƒ¼ã‚¹ã®ä¾¡æ ¼æˆ¦ç•¥æ±ºå®šã‚’å®Ÿæ–½
            pricing_context = f"""
ä»¥ä¸‹ã®ãƒ“ã‚¸ãƒã‚¹çŠ¶æ³ã‚’åˆ†æã—ã€ä¾¡æ ¼æˆ¦ç•¥ã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚

ã€å£²ä¸Šãƒ»è²¡å‹™åˆ†æçµæœã€‘
- å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰: {sales_analysis.get("sales_trend", "unknown")}
- è²¡å‹™åˆ†æ: {financial_analysis.get("analysis", "ãªã—")}
- æˆ¦ç•¥ææ¡ˆ: {sales_analysis.get("strategies", [])}

ã€ç¾åœ¨ã®è²¡å‹™çŠ¶æ³ã€‘
- å£²ä¸Š: Â¥{financial_analysis.get("sales", 0):,}
- åˆ©ç›Šç‡: {financial_analysis.get("profit_margin", 0):.1%}
- é¡§å®¢æº€è¶³åº¦: {financial_analysis.get("customer_satisfaction", 3.0)}/5.0

ã€åœ¨åº«çŠ¶æ³ï¼ˆå‚è€ƒï¼‰ã€‘
- åœ¨åº«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {inventory_analysis.get("status", "unknown") if inventory_analysis else "ãªã—"}
- å±æ©Ÿçš„å•†å“: {inventory_analysis.get("critical_items", []) if inventory_analysis else []}
- è£œå……å„ªå…ˆå•†å“: {inventory_analysis.get("low_stock_items", []) if inventory_analysis else []}

ã€ä¾¡æ ¼æ±ºå®šã®è€ƒæ…®ç‚¹ã€‘
1. å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰ã¨è²¡å‹™çŠ¶æ³ã«åŸºã¥ãä¾¡æ ¼æˆ¦ç•¥
2. åœ¨åº«çŠ¶æ³ã¨å•†å“ã®éœ€è¦ãƒãƒ©ãƒ³ã‚¹
3. é¡§å®¢æº€è¶³åº¦ã¸ã®å½±éŸ¿
4. ç«¶äº‰åŠ›ã®ç¶­æŒ
5. åˆ©ç›Šç‡ã®æœ€é©åŒ–

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
    "pricing_strategy": "ä¾¡æ ¼æˆ¦ç•¥ã®ç¨®é¡ (increase/decrease/maintain/mixed)",
    "reasoning": "ä¾¡æ ¼æ±ºå®šã®è©³ç´°ãªç†ç”±",
    "product_updates": [
        {{
            "product_name": "å•†å“å",
            "current_price": åŸºæº–ä¾¡æ ¼,
            "new_price": æ–°ä¾¡æ ¼,
            "price_change_percent": ä¾¡æ ¼å¤‰æ›´ç‡,
            "reason": "å½“è©²å•†å“ã®ä¾¡æ ¼å¤‰æ›´ç†ç”±"
        }}
    ],
    "expected_impact": "æˆ¦ç•¥å®Ÿè¡Œã«ã‚ˆã‚‹æœŸå¾…åŠ¹æœ",
    "risk_assessment": "ãƒªã‚¹ã‚¯è©•ä¾¡ã¨å¯¾ç­–",
    "analysis": "ç·åˆçš„ãªåˆ†æã¨è§£èª¬ï¼ˆ100æ–‡å­—ä»¥ä¸Šï¼‰"
}}
```
"""

            messages = [
                self.llm_manager.create_ai_message(
                    role="system", content=self.system_prompt
                ),
                self.llm_manager.create_ai_message(
                    role="user", content=pricing_context
                ),
            ]

            logger.info("LLMä¾¡æ ¼æˆ¦ç•¥åˆ†æé–‹å§‹ - å‰å·¥ç¨‹ãƒ‡ãƒ¼ã‚¿çµ±åˆ")

            try:
                # éåŒæœŸé–¢æ•°ãªã®ã§ç›´æ¥awaitã‚’ä½¿ç”¨
                response = await self.llm_manager.generate_response(
                    messages, max_tokens=1500
                )

                if response.success:
                    import json

                    content = response.content.strip()
                    if content.startswith("```json"):
                        content = content[7:]
                    if content.endswith("```"):
                        content = content[:-3]
                    content = content.strip()

                    pricing_result = json.loads(content)

                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
                    pricing_result.setdefault("pricing_strategy", "maintain")
                    pricing_result.setdefault("reasoning", "åˆ†æçµæœã«åŸºã¥ãä¾¡æ ¼æˆ¦ç•¥")
                    pricing_result.setdefault("product_updates", [])
                    pricing_result.setdefault(
                        "expected_impact", "ä¾¡æ ¼æˆ¦ç•¥ã«ã‚ˆã‚‹å½±éŸ¿è©•ä¾¡"
                    )
                    pricing_result.setdefault("risk_assessment", "ãƒªã‚¹ã‚¯è©•ä¾¡ãªã—")
                    pricing_result.setdefault("analysis", "LLMã«ã‚ˆã‚‹ä¾¡æ ¼æˆ¦ç•¥åˆ†æå®Ÿæ–½")

                    logger.info(
                        f"LLMä¾¡æ ¼æˆ¦ç•¥åˆ†ææˆåŠŸ: strategy={pricing_result['pricing_strategy']}"
                    )

                    # LLMåˆ†æçµæœã‚’ãƒ­ã‚°å‡ºåŠ›
                    logger.info("=== LLM Pricing Strategy Analysis ===")
                    logger.info(f"Strategy: {pricing_result['pricing_strategy']}")
                    logger.info(f"Reasoning: {pricing_result['reasoning']}")
                    logger.info(
                        f"Product Updates: {len(pricing_result['product_updates'])}"
                    )
                    logger.info(f"Expected Impact: {pricing_result['expected_impact']}")

                else:
                    # LLMå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    logger.warning(f"LLMä¾¡æ ¼æˆ¦ç•¥åˆ†æå¤±æ•—: {response.error_message}")
                    pricing_result = {
                        "pricing_strategy": "maintain",
                        "reasoning": "LLMåˆ†æä¸å¯ã®ãŸã‚å®‰å®šç¶­æŒã‚’é¸æŠ",
                        "product_updates": [],
                        "expected_impact": "å®‰å®šé‡è¦–",
                        "risk_assessment": "ãƒªã‚¹ã‚¯å›é¿å„ªå…ˆ",
                        "analysis": f"LLMåˆ†æã‚¨ãƒ©ãƒ¼: {response.error_message}",
                    }

            except Exception as e:
                logger.error(f"ä¾¡æ ¼æˆ¦ç•¥åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                # å®Œå…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                pricing_result = {
                    "pricing_strategy": "maintain",
                    "reasoning": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
                    "product_updates": [],
                    "expected_impact": "å®‰å®šé‡è¦–",
                    "risk_assessment": "ãƒªã‚¹ã‚¯å›é¿å„ªå…ˆ",
                    "analysis": f"ä¾¡æ ¼æˆ¦ç•¥åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
                }

            # ä¾¡æ ¼æ›´æ–°ã®å®Ÿè¡Œï¼ˆLLMçµæœã«åŸºã¥ãï¼‰
            executed_updates = []

            if pricing_result["product_updates"]:
                for update in pricing_result["product_updates"]:
                    try:
                        product_name = update.get("product_name", "unknown")
                        new_price = update.get("new_price", 150)

                        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã§ã‚·ã‚¹ãƒ†ãƒ åæ˜ 
                        update_result = self.update_pricing(product_name, new_price)
                        logger.info(
                            f"ãƒ„ãƒ¼ãƒ« update_pricing å‘¼ã³å‡ºã—æˆåŠŸ: {product_name} -> Â¥{new_price}"
                        )

                        # å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²
                        action = {
                            "type": "pricing_update",
                            "product_name": product_name,
                            "new_price": new_price,
                            "price_change_percent": update.get(
                                "price_change_percent", 0
                            ),
                            "reason": update.get("reason", pricing_result["reasoning"]),
                            "tool_called": "update_pricing",
                            "tool_result": update_result,
                            "timestamp": datetime.now().isoformat(),
                        }
                        state.executed_actions.append(action)
                        executed_updates.append(update)

                    except Exception as e:
                        logger.error(f"ä¾¡æ ¼æ›´æ–°ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—å¤±æ•— {product_name}: {e}")
                        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚è¨˜éŒ²
                        action = {
                            "type": "pricing_update_error",
                            "product_name": product_name,
                            "error": str(e),
                            "timestamp": datetime.now().isoformat(),
                        }
                        state.executed_actions.append(action)

            # Stateæ›´æ–°
            state.pricing_decision = {
                "strategy": pricing_result["pricing_strategy"],
                "reasoning": pricing_result["reasoning"],
                "product_updates": executed_updates,
                "expected_impact": pricing_result["expected_impact"],
                "risk_assessment": pricing_result["risk_assessment"],
                "llm_analysis": pricing_result["analysis"],
                "analysis_timestamp": datetime.now().isoformat(),
            }

            # ãƒ­ã‚°å‡ºåŠ›
            logger.info(
                f"âœ… Statefulä¾¡æ ¼æˆ¦ç•¥å®Œäº†: strategy={pricing_result['pricing_strategy']}, updates={len(executed_updates)}"
            )

        except Exception as e:
            logger.error(f"Statefulä¾¡æ ¼æˆ¦ç•¥ã‚¨ãƒ©ãƒ¼: {e}")
            state.errors.append(f"pricing: {str(e)}")
            state.processing_status = "error"

        return state

    @traceable(name="restock_tasks_llm")
    async def restock_node(self, state: ManagementState) -> ManagementState:
        """åœ¨åº«è£œå……ã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦nodeã®LangGraph Statefulé–¢æ•° - LLMå¸¸æ™‚ä½¿ç”¨ï¼šè£œå……æˆ¦ç•¥åˆ†æï¼†å®Ÿç¾å¯èƒ½ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š"""
        logger.info(f"âœ… Statefulè£œå……ã‚¿ã‚¹ã‚¯é–‹å§‹: step={state.current_step}")

        # ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        trace_metadata = {
            "session_id": state.session_id,
            "session_type": state.session_type,
            "current_step": state.current_step,
            "business_date": state.business_date.isoformat()
            if state.business_date
            else None,
            "start_time": datetime.now().isoformat(),
            "agent_type": "management_agent",
            "node_type": "restock_tasks_llm",
            "input_state": {
                "has_inventory_analysis": state.inventory_analysis is not None,
                "low_stock_items_count": len(
                    state.inventory_analysis.get("low_stock_items", [])
                )
                if state.inventory_analysis
                else 0,
                "critical_items_count": len(
                    state.inventory_analysis.get("critical_items", [])
                )
                if state.inventory_analysis
                else 0,
                "processing_status": state.processing_status,
            },
        }

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
            state.current_step = "restock"
            state.processing_status = "processing"

            # å‰æåˆ†æã‚’å–å¾—
            inventory_analysis = state.inventory_analysis
            if not inventory_analysis:
                logger.warning("åœ¨åº«åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                state.errors.append("restock: åœ¨åº«åˆ†æãƒ‡ãƒ¼ã‚¿ãªã—")
                state.processing_status = "error"
                return state

            # LLMå¸¸æ™‚ä½¿ç”¨ï¼šè£œå……æˆ¦ç•¥ã®è©³ç´°åˆ†æï¼†å®Ÿç¾å¯èƒ½ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š
            restock_context = f"""
ä»¥ä¸‹ã®åœ¨åº«çŠ¶æ³ã‚’åˆ†æã—ã€è‡ªå‹•è²©å£²æ©ŸçµŒå–¶ã«ãŠã‘ã‚‹å®Ÿç¾å¯èƒ½ãªè£œå……æˆ¦ç•¥ã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚

ã€åœ¨åº«åˆ†æçµæœã€‘ (å‚ç…§æƒ…å ±)
- åœ¨åº«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {inventory_analysis.get("status", "unknown")}
- å±æ©Ÿçš„å•†å“: {inventory_analysis.get("critical_items", [])}
- åœ¨åº«ä¸è¶³å•†å“: {inventory_analysis.get("low_stock_items", [])}
- åœ¨åº«åˆ‡ã‚Œãƒªã‚¹ã‚¯: {inventory_analysis.get("stockout_risks", {})}
- å†ç™ºæ³¨æ¨å¥¨å•†å“: {inventory_analysis.get("reorder_needed", [])}
- åœ¨åº«åˆ†æLLMçµæœ: {inventory_analysis.get("llm_analysis", "ãªã—")}

ã€ç¾åœ¨ã®äº‹æ¥­çŠ¶æ³ã€‘ (è‡ªå‹•è²©å£²æ©Ÿé‹å–¶åˆ¶ç´„è€ƒæ…®)
- å–¶æ¥­æ™‚é–“: 24æ™‚é–“å¯¾å¿œã®åˆ¶ç´„ (å¾“æ¥­å“¡è¨ªå•ã¯åˆ¶é™ã•ã‚Œã‚‹å¯èƒ½æ€§)
- è£œå……ãƒªã‚½ãƒ¼ã‚¹: å¾“æ¥­å“¡ã«ã‚ˆã‚‹æ‰‹å‹•è£œå……ä½œæ¥­
- ç·Šæ€¥å¯¾å¿œ: åœ¨åº«åˆ‡ã‚Œæ™‚ã®å–¶æ¥­åœæ­¢å›é¿ã‚’æœ€å„ªå…ˆ
- ã‚³ã‚¹ãƒˆåˆ¶ç´„: éå‰°è£œå……ã«ã‚ˆã‚‹é‹ç”¨ã‚³ã‚¹ãƒˆå¢—åŠ ã®å›é¿

ã€è£œå……æˆ¦ç•¥ã®è€ƒæ…®ç‚¹ã€‘
1. å±æ©Ÿçš„å•†å“ã«å¯¾ã™ã‚‹ç·Šæ€¥è£œå……ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
2. é€šå¸¸è£œå……ã®ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡æ€§
3. è‡ªå‹•è²©å£²æ©Ÿå›ºæœ‰ã®é‹å–¶åŠ¹ç‡ (è¨ªå•é »åº¦æœ€å°åŒ–)
4. å­£ç¯€æ€§éœ€è¦å¤‰å‹•ã®è€ƒæ…®
5. åœ¨åº«å›è»¢ç‡ã®æœ€é©åŒ–

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "restock_strategy": "å…¨ä½“è£œå……æˆ¦ç•¥ (emergency_response/regular_maintenance/optimized_rotating)",
    "action_plan": {{
        "immediate_actions": ["å³æ™‚å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå±æ©Ÿçš„å•†å“å¯¾å¿œï¼‰"],
        "scheduled_actions": ["è¨ˆç”»çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆé€šå¸¸è£œå……ï¼‰"],
        "preventive_actions": ["äºˆé˜²çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå°†æ¥ãƒªã‚¹ã‚¯å›é¿ï¼‰"]
    }},
    "resource_allocation": {{
        "urgent_tasks": ["ç·Šæ€¥åº¦é«˜ã®è£œå……ã‚¿ã‚¹ã‚¯ï¼ˆæ‹…å½“è€…å³æ™‚å‰²ã‚Šå½“ã¦ï¼‰"],
        "normal_tasks": ["é€šå¸¸è£œå……ã‚¿ã‚¹ã‚¯ï¼ˆé€šå¸¸æ¥­å‹™ã¨ä¸¦è¡Œï¼‰"],
        "long_term_tasks": ["é•·æœŸæ¤œè¨ã‚¿ã‚¹ã‚¯ï¼ˆæ¬¡ã®æˆ¦ç•¥ä¼šè­°ã¾ã§ï¼‰"]
    }},
    "efficiency_considerations": {{
        "visit_optimization": "è‡ªå‹•è²©å£²æ©Ÿé…ç½®åˆ¥è£œå……åŠ¹ç‡åŒ–ç­–",
        "cost_benefit": "è£œå……ã‚³ã‚¹ãƒˆã¨å–¶æ¥­æ©Ÿä¼šæå¤±ã®ãƒãƒ©ãƒ³ã‚¹",
        "contingency_plans": ["ç·Šæ€¥æ™‚å¯¾å¿œç­–ï¼ˆç½å®³ãƒ»å¤§é‡æ¶ˆè²»æ™‚ï¼‰"]
    }},
    "expected_outcomes": ["è£œå……å®Ÿè¡Œã«ã‚ˆã‚‹æœŸå¾…åŠ¹æœã¨KPIæ”¹å–„"],
    "analysis": "ç·åˆçš„ãªè£œå……æˆ¦ç•¥åˆ†æã¨è‡ªå‹•è²©å£²æ©ŸçµŒå–¶ã¸ã®å½±éŸ¿è©•ä¾¡ï¼ˆ100æ–‡å­—ä»¥ä¸Šï¼‰"
}}
"""

            messages = [
                self.llm_manager.create_ai_message(
                    role="system", content=self.system_prompt
                ),
                self.llm_manager.create_ai_message(
                    role="user", content=restock_context
                ),
            ]

            logger.info("LLMè£œå……æˆ¦ç•¥åˆ†æé–‹å§‹ - è‡ªå‹•è²©å£²æ©Ÿé‹å–¶åˆ¶ç´„çµ±åˆ")

            try:
                # éåŒæœŸé–¢æ•°ãªã®ã§ç›´æ¥awaitã‚’ä½¿ç”¨
                llm_response = await self.llm_manager.generate_response(
                    messages, max_tokens=1500
                )

                if llm_response.success:
                    import json

                    content = llm_response.content.strip()
                    if content.startswith("```json"):
                        content = content[7:]
                    if content.endswith("```"):
                        content = content[:-3]
                    content = content.strip()

                    restock_strategy = json.loads(content)

                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
                    restock_strategy.setdefault(
                        "restock_strategy", "regular_maintenance"
                    )
                    restock_strategy.setdefault(
                        "action_plan",
                        {
                            "immediate_actions": [],
                            "scheduled_actions": [],
                            "preventive_actions": [],
                        },
                    )
                    restock_strategy.setdefault(
                        "resource_allocation",
                        {"urgent_tasks": [], "normal_tasks": [], "long_term_tasks": []},
                    )
                    restock_strategy.setdefault(
                        "efficiency_considerations",
                        {
                            "visit_optimization": "æœªè€ƒæ…®",
                            "cost_benefit": "ãƒãƒ©ãƒ³ã‚¹æ¤œè¨",
                            "contingency_plans": [],
                        },
                    )
                    restock_strategy.setdefault("expected_outcomes", ["åœ¨åº«å®‰å®šåŒ–"])
                    restock_strategy.setdefault("analysis", "LLMã«ã‚ˆã‚‹è£œå……æˆ¦ç•¥åˆ†æå®Ÿæ–½")

                    logger.info(
                        f"LLMè£œå……æˆ¦ç•¥åˆ†ææˆåŠŸ: strategy={restock_strategy['restock_strategy']}, llm_used=True"
                    )

                    # LLMåˆ†æçµæœã‚’ãƒ­ã‚°å‡ºåŠ›
                    logger.info("=== LLM Restock Strategy Analysis ===")
                    logger.info(f"Strategy: {restock_strategy['restock_strategy']}")
                    logger.info(
                        f"Immediate Actions: {len(restock_strategy['action_plan']['immediate_actions'])}"
                    )
                    logger.info(
                        f"Urgent Tasks: {len(restock_strategy['resource_allocation']['urgent_tasks'])}"
                    )
                    logger.info(f"Analysis: {restock_strategy['analysis'][:100]}...")

                else:
                    # LLMå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    logger.warning(f"LLMè£œå……æˆ¦ç•¥åˆ†æå¤±æ•—: {llm_response.error_message}")
                    restock_strategy = {
                        "restock_strategy": "regular_maintenance",
                        "action_plan": {
                            "immediate_actions": [],
                            "scheduled_actions": ["é€šå¸¸è£œå……ä½œæ¥­å®Ÿæ–½"],
                            "preventive_actions": ["åœ¨åº«ç›£è¦–å¼·åŒ–"],
                        },
                        "resource_allocation": {
                            "urgent_tasks": [],
                            "normal_tasks": ["é€šå¸¸è£œå……ã‚¿ã‚¹ã‚¯"],
                            "long_term_tasks": ["è£œå……ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–"],
                        },
                        "efficiency_considerations": {
                            "visit_optimization": "æ¨™æº–è¨ªå•é »åº¦ç¶­æŒ",
                            "cost_benefit": "ã‚³ã‚¹ãƒˆå‰Šæ¸›å„ªå…ˆ",
                            "contingency_plans": ["ç·Šæ€¥è£œå……è¨ˆç”»ç­–å®š"],
                        },
                        "expected_outcomes": ["åœ¨åº«å®‰å®šåŒ–"],
                        "analysis": f"LLMåˆ†æã‚¨ãƒ©ãƒ¼: {llm_response.error_message}",
                    }

            except Exception as e:
                logger.error(f"è£œå……æˆ¦ç•¥åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                # å®Œå…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                restock_strategy = {
                    "restock_strategy": "regular_maintenance",
                    "action_plan": {
                        "immediate_actions": [],
                        "scheduled_actions": ["é€šå¸¸è£œå……ä½œæ¥­"],
                        "preventive_actions": [],
                    },
                    "resource_allocation": {
                        "urgent_tasks": [],
                        "normal_tasks": ["è£œå……ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ"],
                        "long_term_tasks": [],
                    },
                    "efficiency_considerations": {
                        "visit_optimization": "æ¨™æº–æ¥­å‹™ãƒ•ãƒ­ãƒ¼",
                        "cost_benefit": "ãƒãƒ©ãƒ³ã‚¹è€ƒæ…®",
                        "contingency_plans": [],
                    },
                    "expected_outcomes": ["åœ¨åº«ç¶­æŒ"],
                    "analysis": f"LLMåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
                }

            # è£œå……ã‚¿ã‚¹ã‚¯æ±ºå®š (LLMæˆ¦ç•¥ã«åŸºã¥ã)
            restock_decision = {
                "action": "tasks_assigned"
                if restock_strategy["resource_allocation"]["urgent_tasks"]
                else "strategic_planning",
                "reasoning": f"LLMè£œå……æˆ¦ç•¥åˆ†æã«åŸºã¥ãã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦: {restock_strategy['restock_strategy']}",
                "strategy": restock_strategy["restock_strategy"],
                "action_plan": restock_strategy["action_plan"],
                "resource_allocation": restock_strategy["resource_allocation"],
                "efficiency_considerations": restock_strategy[
                    "efficiency_considerations"
                ],
                "expected_outcomes": restock_strategy["expected_outcomes"],
                "llm_analysis": restock_strategy["analysis"],
                "analysis_timestamp": datetime.now().isoformat(),
                "tasks_assigned": [],
                "total_items": 0,
            }

            # åœ¨åº«æƒ…å ±ã‹ã‚‰å…·ä½“çš„ãªè£œå……ã‚¿ã‚¹ã‚¯ã‚’çµ„ã¿ç«‹ã¦
            inventory_analysis = state.inventory_analysis
            low_stock_items = inventory_analysis.get("low_stock_items", [])
            critical_items = inventory_analysis.get("critical_items", [])

            # LLMæˆ¦ç•¥ã«åŸºã¥ãè£œå……ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
            all_tasks = []
            urgent_products = []
            normal_products = []

            # ç·Šæ€¥ã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦
            urgent_tasks = restock_strategy["resource_allocation"]["urgent_tasks"]
            if urgent_tasks:
                for urgent_task in urgent_tasks:
                    # ã‚¿ã‚¹ã‚¯ã‹ã‚‰å•†å“åã‚’æŠ½å‡º
                    if critical_items:
                        urgent_products.extend(critical_items)
                    elif low_stock_items:
                        urgent_products.extend(low_stock_items[: len(urgent_tasks)])

            # é€šå¸¸ã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦
            normal_tasks = restock_strategy["resource_allocation"]["normal_tasks"]
            if normal_tasks:
                for normal_task in normal_tasks:
                    remaining_low_stock = [
                        item for item in low_stock_items if item not in urgent_products
                    ]
                    normal_products.extend(remaining_low_stock)

            # é‡è¤‡é™¤å»
            urgent_products = list(set(urgent_products))
            normal_products = list(set(normal_products) - set(urgent_products))

            # å…·ä½“çš„ãªã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
            for product in urgent_products + normal_products:
                urgency = "urgent" if product in urgent_products else "normal"
                task = self.assign_restocking_task([product], urgency)
                task_info = {
                    "product": product,
                    "task_id": task.get("task_id"),
                    "urgency": urgency,
                    "deadline": task.get("deadline"),
                    "strategy_driven": True,  # LLMæˆ¦ç•¥ã«ã‚ˆã‚‹ã‚¿ã‚¹ã‚¯
                }
                all_tasks.append(task_info)

            restock_decision["tasks_assigned"] = all_tasks
            restock_decision["total_items"] = len(all_tasks)

            # å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²
            if all_tasks:
                for task in all_tasks:
                    action = {
                        "type": "restock_task_llm",
                        "product": task["product"],
                        "task_id": task["task_id"],
                        "urgency": task["urgency"],
                        "strategy_driven": task["strategy_driven"],
                        "llm_strategy": restock_strategy["restock_strategy"],
                        "timestamp": datetime.now().isoformat(),
                    }
                    state.executed_actions.append(action)

            # Stateæ›´æ–°
            state.restock_decision = restock_decision

            # ãƒ­ã‚°å‡ºåŠ›
            tasks_count = len(all_tasks)
            strategy = restock_strategy["restock_strategy"]
            logger.info(
                f"âœ… Statefulè£œå……ã‚¿ã‚¹ã‚¯å®Œäº†: tasks={tasks_count}, strategy={strategy}, llm_used=True"
            )

        except Exception as e:
            logger.error(f"Statefulè£œå……ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            state.errors.append(f"restock: {str(e)}")
            state.processing_status = "error"

        return state

    @traceable(name="procurement_requests_llm")
    async def procurement_request_generation_node(
        self, state: ManagementState
    ) -> ManagementState:
        """ç™ºæ³¨ä¾é ¼nodeã®LangGraph Statefulé–¢æ•° - LLMå¸¸æ™‚ä½¿ç”¨ï¼šç™ºæ³¨æœ€é©åŒ–æˆ¦ç•¥åˆ†æï¼†å®Ÿç¾å¯èƒ½ç™ºæ³¨æ±ºå®š"""
        logger.info(f"âœ… Statefulç™ºæ³¨ä¾é ¼é–‹å§‹: step={state.current_step}")

        # ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        trace_metadata = {
            "session_id": state.session_id,
            "session_type": state.session_type,
            "current_step": state.current_step,
            "business_date": state.business_date.isoformat()
            if state.business_date
            else None,
            "start_time": datetime.now().isoformat(),
            "agent_type": "management_agent",
            "node_type": "procurement_requests_llm",
            "input_state": {
                "has_inventory_analysis": state.inventory_analysis is not None,
                "has_restock_decision": state.restock_decision is not None,
                "reorder_items_count": len(
                    state.inventory_analysis.get("reorder_needed", [])
                )
                if state.inventory_analysis
                else 0,
                "assigned_tasks_count": len(
                    state.restock_decision.get("tasks_assigned", [])
                )
                if state.restock_decision
                else 0,
                "processing_status": state.processing_status,
            },
        }

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
            state.current_step = "procurement"
            state.processing_status = "processing"

            # å‰æåˆ†æã‚’å–å¾—
            inventory_analysis = state.inventory_analysis
            restock_decision = state.restock_decision

            if not inventory_analysis or not restock_decision:
                logger.warning("å‰æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                state.errors.append("procurement: å‰æãƒ‡ãƒ¼ã‚¿ãªã—")
                state.processing_status = "error"
                return state

            # LLMå¸¸æ™‚ä½¿ç”¨ï¼šç™ºæ³¨æœ€é©åŒ–æˆ¦ç•¥ã®è©³ç´°åˆ†æï¼†å®Ÿç¾å¯èƒ½ç™ºæ³¨æ±ºå®š
            procurement_context = f"""
ä»¥ä¸‹ã®è£œå……ã‚¿ã‚¹ã‚¯ã¨åœ¨åº«çŠ¶æ³ã‚’åˆ†æã—ã€è‡ªå‹•è²©å£²æ©ŸçµŒå–¶ã«ãŠã‘ã‚‹å®Ÿç¾å¯èƒ½ãªç™ºæ³¨æœ€é©åŒ–æˆ¦ç•¥ã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚

ã€è£œå……ã‚¿ã‚¹ã‚¯çŠ¶æ³ã€‘ (å‚ç…§æƒ…å ±)
- è£œå……æˆ¦ç•¥: {restock_decision.get("strategy", "unknown")}
- è£œå……LLMåˆ†æ: {restock_decision.get("llm_analysis", "ãªã—")}
- å‰²ã‚Šå½“ã¦ã‚¿ã‚¹ã‚¯æ•°: {len(restock_decision.get("tasks_assigned", []))}
- ç·Šæ€¥ã‚¿ã‚¹ã‚¯: {len([t for t in restock_decision.get("tasks_assigned", []) if t.get("urgency") == "urgent"])}
- é€šå¸¸ã‚¿ã‚¹ã‚¯: {len([t for t in restock_decision.get("tasks_assigned", []) if t.get("urgency") != "urgent"])}

ã€åœ¨åº«åˆ†æçŠ¶æ³ã€‘ (å‚ç…§æƒ…å ±)
- å†ç™ºæ³¨æ¨å¥¨å•†å“: {inventory_analysis.get("reorder_needed", [])}
- å±æ©Ÿçš„å•†å“: {inventory_analysis.get("critical_items", [])}
- åœ¨åº«ä¸è¶³å•†å“: {inventory_analysis.get("low_stock_items", [])}
- åœ¨åº«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {inventory_analysis.get("status", "unknown")}
- åœ¨åº«åˆ†æLLMçµæœ: {inventory_analysis.get("llm_analysis", "ãªã—")}

ã€ç¾åœ¨ã®äº‹æ¥­çŠ¶æ³ã€‘ (è‡ªå‹•è²©å£²æ©Ÿé‹å–¶åˆ¶ç´„è€ƒæ…®)
- ä»•å…¥å…ˆé¸å®š: ä¿¡é ¼æ€§ãƒ»ä¾¡æ ¼ãƒ»ç´æœŸã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®
- è³‡é‡‘ç¹°ã‚Šåˆ¶ç´„: éå‰°ç™ºæ³¨ã«ã‚ˆã‚‹è³‡é‡‘æµå‹•æ€§æ‚ªåŒ–ã‚’å›é¿
- åœ¨åº«ä¿ç®¡: è‡ªå‹•è²©å£²æ©Ÿå®¹é‡ã®åˆ¶é™ (ç´„50ã‚¹ãƒ­ãƒƒãƒˆÃ—å•†å“)
- ç´æœŸç®¡ç†: ç·Šæ€¥æ™‚å¯¾å¿œ vs å®šæœŸç™ºæ³¨ã®æ£²ã¿åˆ†ã‘
- ã‚³ã‚¹ãƒˆæœ€é©åŒ–: èª¿é”ã‚³ã‚¹ãƒˆ vs æ¬ å“æ©Ÿä¼šæå¤±ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

ã€ç™ºæ³¨æˆ¦ç•¥ã®è€ƒæ…®ç‚¹ã€‘
1. è£œå……ã‚¿ã‚¹ã‚¯ã®å„ªå…ˆé †ä½ä»˜ã‘ã¨ç™ºæ³¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°
2. ä»•å…¥å…ˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å¤šæ§˜åŒ–ãƒªã‚¹ã‚¯åˆ†æ•£
3. ç™ºæ³¨ãƒ­ãƒƒãƒˆæœ€é©åŒ– (çµŒæ¸ˆç™ºæ³¨é‡ vs å³æ™‚æ€§)
4. ç´æœŸã‚·ãƒŠãƒªã‚ªã®ãƒªã‚¢ãƒ«ãªæƒ³å®šï¼ˆé€šå¸¸3å–¶æ¥­æ—¥ï¼‰
5. å­£ç¯€å¤‰å‹•ãƒ»éœ€è¦äºˆæ¸¬ã®å–ã‚Šè¾¼ã¿
6. ç«¶äº‰åŠ›ç¢ºä¿ã®ãŸã‚ã®äºˆå‚™åœ¨åº«æˆ¦ç•¥

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "procurement_strategy": "å…¨ä½“ç™ºæ³¨æˆ¦ç•¥ (emergency_procurement/standard_procurement/optimized_batching/supplier_diversification)",
    "supplier_allocation": {{
        "primary_supplier": ["ä¿¡é ¼æ€§é‡è¦–å•†å“ï¼ˆå®‰å®šä¾›çµ¦å„ªå…ˆï¼‰"],
        "alternative_suppliers": ["ä¾¡æ ¼ç«¶äº‰åŠ›é‡è¦–å•†å“ï¼ˆã‚³ã‚¹ãƒˆå‰Šæ¸›å„ªå…ˆï¼‰"],
        "emergency_suppliers": ["å³æ—¥å¯¾å¿œå¯èƒ½å•†å“ï¼ˆå±æ©Ÿçš„ç™ºæ³¨å°‚ç”¨ï¼‰"]
    }},
    "order_optimization": {{
        "consolidated_orders": ["ç™ºæ³¨çµ±åˆå•†å“ï¼ˆãƒ­ãƒƒãƒˆåŠ¹ç‡åŒ–ï¼‰"],
        "urgent_orders": ["ç·Šæ€¥ç™ºæ³¨å•†å“ï¼ˆå³æ™‚ç´å…¥å„ªå…ˆï¼‰"],
        "scheduled_orders": ["è¨ˆç”»ç™ºæ³¨å•†å“ï¼ˆå®‰ä¾¡ãƒ«ãƒ¼ãƒˆåˆ©ç”¨ï¼‰"]
    }},
    "cost_benefit_analysis": {{
        "immediate_costs": "ç™ºæ³¨å®Ÿè¡Œã‚³ã‚¹ãƒˆã®è¦‹ç©ã‚‚ã‚Š",
        "expected_savings": "æœ€é©åŒ–ã«ã‚ˆã‚‹å‰Šæ¸›åŠ¹æœ",
        "risk_mitigation": "æ¬ å“ãƒ»éå‰°åœ¨åº«ãƒªã‚¹ã‚¯è©•ä¾¡ã¨å¯¾ç­–",
        "roi_expectations": "æŠ•è³‡å›åæœŸé–“ã¨ROIäºˆæ¸¬"
    }},
    "delivery_timeline": {{
        "emergency_delivery": ["24-48æ™‚é–“ä»¥å†…ã®å•†å“"],
        "standard_delivery": ["3-5å–¶æ¥­æ—¥ä»¥å†…ã®å•†å“"],
        "bulk_delivery": ["1-2é€±é–“ç¨‹åº¦ã®è¨ˆç”»ç™ºæ³¨å•†å“"]
    }},
    "contingency_plans": ["ç·Šæ€¥æ™‚å¯¾å¿œç­–ã¨ä»£æ›¿èª¿é”ãƒ«ãƒ¼ãƒˆ"],
    "expected_outcomes": ["ç™ºæ³¨å®Ÿè¡Œã«ã‚ˆã‚‹æœŸå¾…åŠ¹æœã¨äº‹æ¥­KPIæ”¹å–„"],
    "analysis": "ç·åˆçš„ãªç™ºæ³¨æˆ¦ç•¥åˆ†æã¨è‡ªå‹•è²©å£²æ©ŸçµŒå–¶ã¸ã®å½±éŸ¿è©•ä¾¡ï¼ˆ100æ–‡å­—ä»¥ä¸Šï¼‰"
}}
"""

            messages = [
                self.llm_manager.create_ai_message(
                    role="system", content=self.system_prompt
                ),
                self.llm_manager.create_ai_message(
                    role="user", content=procurement_context
                ),
            ]

            logger.info("LLMç™ºæ³¨æˆ¦ç•¥åˆ†æé–‹å§‹ - è‡ªå‹•è²©å£²æ©Ÿèª¿é”åˆ¶ç´„çµ±åˆ")

            try:
                # éåŒæœŸé–¢æ•°ãªã®ã§ç›´æ¥awaitã‚’ä½¿ç”¨
                llm_response = await self.llm_manager.generate_response(
                    messages, max_tokens=1600
                )

                if llm_response.success:
                    import json

                    content = llm_response.content.strip()
                    if content.startswith("```json"):
                        content = content[7:]
                    if content.endswith("```"):
                        content = content[:-3]
                    content = content.strip()

                    procurement_strategy = json.loads(content)

                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
                    procurement_strategy.setdefault(
                        "procurement_strategy", "standard_procurement"
                    )
                    procurement_strategy.setdefault(
                        "supplier_allocation",
                        {
                            "primary_supplier": [],
                            "alternative_suppliers": [],
                            "emergency_suppliers": [],
                        },
                    )
                    procurement_strategy.setdefault(
                        "order_optimization",
                        {
                            "consolidated_orders": [],
                            "urgent_orders": [],
                            "scheduled_orders": [],
                        },
                    )
                    procurement_strategy.setdefault(
                        "cost_benefit_analysis",
                        {
                            "immediate_costs": "è¨ˆç®—ä¸­",
                            "expected_savings": "åˆ†æä¸­",
                            "risk_mitigation": "è©•ä¾¡ä¸­",
                            "roi_expectations": "è¨ˆç®—ä¸­",
                        },
                    )
                    procurement_strategy.setdefault(
                        "delivery_timeline",
                        {
                            "emergency_delivery": [],
                            "standard_delivery": [],
                            "bulk_delivery": [],
                        },
                    )
                    procurement_strategy.setdefault("contingency_plans", [])
                    procurement_strategy.setdefault("expected_outcomes", ["ç™ºæ³¨å®‰å®šåŒ–"])
                    procurement_strategy.setdefault(
                        "analysis", "LLMã«ã‚ˆã‚‹ç™ºæ³¨æˆ¦ç•¥åˆ†æå®Ÿæ–½"
                    )

                    logger.info(
                        f"LLMç™ºæ³¨æˆ¦ç•¥åˆ†ææˆåŠŸ: strategy={procurement_strategy['procurement_strategy']}, llm_used=True"
                    )

                    # LLMåˆ†æçµæœã‚’ãƒ­ã‚°å‡ºåŠ›
                    logger.info("=== LLM Procurement Strategy Analysis ===")
                    logger.info(
                        f"Strategy: {procurement_strategy['procurement_strategy']}"
                    )
                    logger.info(
                        f"Urgent Orders: {len(procurement_strategy['order_optimization']['urgent_orders'])}"
                    )
                    logger.info(
                        f"Consolidated Orders: {len(procurement_strategy['order_optimization']['consolidated_orders'])}"
                    )
                    logger.info(
                        f"Analysis: {procurement_strategy['analysis'][:100]}..."
                    )

                else:
                    # LLMå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    logger.warning(f"LLMç™ºæ³¨æˆ¦ç•¥åˆ†æå¤±æ•—: {llm_response.error_message}")
                    procurement_strategy = {
                        "procurement_strategy": "standard_procurement",
                        "supplier_allocation": {
                            "primary_supplier": [],
                            "alternative_suppliers": [],
                            "emergency_suppliers": [],
                        },
                        "order_optimization": {
                            "consolidated_orders": [],
                            "urgent_orders": [],
                            "scheduled_orders": ["æ¨™æº–ç™ºæ³¨å•†å“"],
                        },
                        "cost_benefit_analysis": {
                            "immediate_costs": "æ¨™æº–é…é€æ–™",
                            "expected_savings": "ãƒ­ãƒƒãƒˆåŠ¹æœ",
                            "risk_mitigation": "åˆ†æ•£ç™ºæ³¨",
                            "roi_expectations": "3ãƒ¶æœˆä»¥å†…",
                        },
                        "delivery_timeline": {
                            "emergency_delivery": [],
                            "standard_delivery": ["é€šå¸¸å•†å“"],
                            "bulk_delivery": [],
                        },
                        "contingency_plans": ["ä»£æ›¿ç™ºæ³¨ãƒ«ãƒ¼ãƒˆç¢ºä¿"],
                        "expected_outcomes": ["ç™ºæ³¨å®‰å®šåŒ–"],
                        "analysis": f"LLMåˆ†æã‚¨ãƒ©ãƒ¼: {llm_response.error_message}",
                    }

            except Exception as e:
                logger.error(f"ç™ºæ³¨æˆ¦ç•¥åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                # å®Œå…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                procurement_strategy = {
                    "procurement_strategy": "standard_procurement",
                    "supplier_allocation": {
                        "primary_supplier": [],
                        "alternative_suppliers": [],
                        "emergency_suppliers": [],
                    },
                    "order_optimization": {
                        "consolidated_orders": [],
                        "urgent_orders": [],
                        "scheduled_orders": ["å…¨éƒ¨å•†å“"],
                    },
                    "cost_benefit_analysis": {
                        "immediate_costs": "æ¨™æº–ã‚³ã‚¹ãƒˆ",
                        "expected_savings": "ãƒ­ãƒƒãƒˆå‰²å¼•",
                        "risk_mitigation": "é€šå¸¸ãƒ¬ãƒ™ãƒ«",
                        "roi_expectations": "æ¨™æº–æœŸé–“",
                    },
                    "delivery_timeline": {
                        "emergency_delivery": [],
                        "standard_delivery": ["å…¨éƒ¨å•†å“"],
                        "bulk_delivery": [],
                    },
                    "contingency_plans": ["æ¨™æº–å¯¾å¿œ"],
                    "expected_outcomes": ["ç™ºæ³¨å®Ÿè¡Œ"],
                    "analysis": f"LLMåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
                }

            # ç™ºæ³¨åˆ¤å®šã¨å®Ÿè¡Œ (LLMæˆ¦ç•¥ã«åŸºã¥ã)
            procurement_decision = {
                "action": "strategic_procurement"
                if procurement_strategy["order_optimization"]["urgent_orders"]
                else "optimized_procurement",
                "reasoning": f"LLMç™ºæ³¨æˆ¦ç•¥åˆ†æã«åŸºã¥ãèª¿é”å®Ÿè¡Œ: {procurement_strategy['procurement_strategy']}",
                "strategy": procurement_strategy["procurement_strategy"],
                "supplier_allocation": procurement_strategy["supplier_allocation"],
                "order_optimization": procurement_strategy["order_optimization"],
                "cost_benefit_analysis": procurement_strategy["cost_benefit_analysis"],
                "delivery_timeline": procurement_strategy["delivery_timeline"],
                "contingency_plans": procurement_strategy["contingency_plans"],
                "expected_outcomes": procurement_strategy["expected_outcomes"],
                "llm_analysis": procurement_strategy["analysis"],
                "analysis_timestamp": datetime.now().isoformat(),
                "orders_placed": [],
                "total_orders": 0,
            }

            # åœ¨åº«åˆ†æã¨è£œå……æ±ºå®šã‹ã‚‰å…·ä½“çš„ãªç™ºæ³¨å•†å“ã‚’æ±ºå®š
            reorder_needed = inventory_analysis.get("reorder_needed", [])
            tasks_assigned = restock_decision.get("tasks_assigned", [])

            # LLMæˆ¦ç•¥ã«åŸºã¥ãç™ºæ³¨å¯¾è±¡ã‚’åˆ†é¡ãƒ»æœ€é©åŒ–
            all_orders = []
            urgent_products = procurement_strategy["order_optimization"][
                "urgent_orders"
            ]
            consolidated_products = procurement_strategy["order_optimization"][
                "consolidated_orders"
            ]
            scheduled_products = procurement_strategy["order_optimization"][
                "scheduled_orders"
            ]

            # ç™ºæ³¨å¯¾è±¡ã®å„ªå…ˆé †ä½ä»˜ã‘
            for task in tasks_assigned:
                product = task.get("product")
                if product in reorder_needed:
                    # LLMæˆ¦ç•¥ã«ã‚ˆã‚‹ç™ºæ³¨æœ€é©åŒ–
                    if task.get("urgency") == "urgent" or product in urgent_products:
                        order_quantity = 15  # ç·Šæ€¥ç™ºæ³¨:å°‘é‡ãƒ»é«˜é »åº¦
                        delivery_priority = "emergency"
                    elif product in consolidated_products:
                        order_quantity = 30  # çµ±åˆç™ºæ³¨:å¤§é‡ãƒ»å‰²å®‰
                        delivery_priority = "bulk"
                    elif product in scheduled_products:
                        order_quantity = 25  # è¨ˆç”»ç™ºæ³¨:æ¨™æº–é‡
                        delivery_priority = "standard"
                    else:
                        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæˆ¦ç•¥
                        order_quantity = 20
                        delivery_priority = "standard"

                    # ç™ºæ³¨å®Ÿè¡Œ
                    procurement_result = self.request_procurement(
                        [product],
                        {product: order_quantity},
                    )

                    order_info = {
                        "product": product,
                        "quantity": order_quantity,
                        "order_id": procurement_result.get("order_id"),
                        "estimated_delivery": procurement_result.get(
                            "estimated_delivery"
                        ),
                        "urgency": task.get("urgency", "normal"),
                        "delivery_priority": delivery_priority,
                        "strategy_driven": True,  # LLMæˆ¦ç•¥ã«ã‚ˆã‚‹ç™ºæ³¨
                        "procurement_strategy": procurement_strategy[
                            "procurement_strategy"
                        ],
                    }
                    all_orders.append(order_info)

            procurement_decision["orders_placed"] = all_orders
            procurement_decision["total_orders"] = len(all_orders)

            # å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²
            if all_orders:
                for order in all_orders:
                    action = {
                        "type": "procurement_order_llm",
                        "product": order["product"],
                        "quantity": order["quantity"],
                        "order_id": order["order_id"],
                        "urgency": order["urgency"],
                        "delivery_priority": order["delivery_priority"],
                        "strategy_driven": order["strategy_driven"],
                        "llm_strategy": order["procurement_strategy"],
                        "timestamp": datetime.now().isoformat(),
                    }
                    state.executed_actions.append(action)

            # Stateæ›´æ–°
            state.procurement_decision = procurement_decision

            # ãƒ­ã‚°å‡ºåŠ›
            orders_count = len(all_orders)
            strategy = procurement_strategy["procurement_strategy"]
            logger.info(
                f"âœ… Statefulç™ºæ³¨ä¾é ¼å®Œäº†: orders={orders_count}, strategy={strategy}, llm_used=True"
            )

        except Exception as e:
            logger.error(f"Statefulç™ºæ³¨ä¾é ¼ã‚¨ãƒ©ãƒ¼: {e}")
            state.errors.append(f"procurement: {str(e)}")
            state.processing_status = "error"

        return state

    @traceable(name="sales_processing_analysis")
    async def sales_processing_node(self, state: ManagementState) -> ManagementState:
        """å£²ä¸Šå‡¦ç†nodeã®LangGraph Statefulé–¢æ•° - LLMãƒ™ãƒ¼ã‚¹ã®æŸ»å®šåˆ†æã‚’å®Ÿè¡Œ"""
        logger.info(f"âœ… Statefulå£²ä¸Šå‡¦ç†é–‹å§‹: step={state.current_step}")

        # ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        trace_metadata = {
            "session_id": state.session_id,
            "session_type": state.session_type,
            "current_step": state.current_step,
            "business_date": state.business_date.isoformat()
            if state.business_date
            else None,
            "start_time": datetime.now().isoformat(),
            "agent_type": "management_agent",
            "node_type": "sales_processing_analysis",
            "input_state": {
                "has_business_metrics": state.business_metrics is not None,
                "current_sales": state.business_metrics.sales
                if state.business_metrics
                else 0,
                "current_profit_margin": state.business_metrics.profit_margin
                if state.business_metrics
                else 0,
                "processing_status": state.processing_status,
            },
        }

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
            state.current_step = "sales_processing"
            state.processing_status = "processing"

            # LLMãƒ™ãƒ¼ã‚¹å£²ä¸Šå‡¦ç†åˆ†æ (å¸¸ã«LLMä½¿ç”¨)
            try:
                from src.simulations.sales_simulation import simulate_purchase_events

                # è²©å£²ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ (çŸ­æ™‚é–“ãƒãƒ¼ã‚¸ãƒ§ãƒ³)
                sales_lambda = 5.0
                simulation_result = await simulate_purchase_events(
                    sales_lambda=sales_lambda,
                    verbose=False,
                    period_name="å–¶æ¥­æ™‚é–“",
                )

                # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’å–å¾—
                conversion_rate = simulation_result.get("conversion_rate", 0)
                total_revenue = simulation_result.get("total_revenue", 0)
                transactions = simulation_result.get("successful_sales", 0)
                total_events = simulation_result.get("total_events", 0)

                # **LLMã‚’å¸¸ã«å‘¼ã³å‡ºã—** - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã¦åˆ†æ
                llm_prompt = f"""
ä»¥ä¸‹ã®å£²ä¸Šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’è©³ç´°ã«åˆ†æã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã¨æ”¹å–„æˆ¦ç•¥ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã€‘
- ç·ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {total_events}
- æˆåŠŸãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æ•°: {transactions}
- ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‡: {conversion_rate:.3f} ({conversion_rate:.1%})
- ç·å£²ä¸Š: Â¥{total_revenue:.0f}

ã€åˆ†æè¦æ±‚ã€‘
1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã®è©•ä¾¡ (excellent/good/acceptable/needs_improvement)
2. å£²ä¸ŠåŠ¹ç‡ã®è©³ç´°åˆ†æ
3. æ”¹å–„ææ¡ˆ (3-5å€‹ã®å…·ä½“çš„ãªæˆ¦ç•¥)
4. äºˆæ¸¬ã•ã‚Œã‚‹æ”¹å–„åŠ¹æœ
5. å®Ÿæ–½ã®å„ªå…ˆé †ä½ä»˜ã‘

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
    "performance_rating": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ãƒ¬ãƒ™ãƒ«",
    "efficiency_analysis": "å£²ä¸ŠåŠ¹ç‡ã®è©³ç´°åˆ†ææ–‡",
    "recommendations": ["æ”¹å–„ææ¡ˆ1", "æ”¹å–„ææ¡ˆ2", "æ”¹å–„ææ¡ˆ3"],
    "expected_impact": "æ”¹å–„åŠ¹æœã®å…¨ä½“è©•ä¾¡",
    "priority_actions": ["å„ªå…ˆåº¦é«˜: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1", "å„ªå…ˆåº¦ä¸­: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2", "å„ªå…ˆåº¦ä½: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³3"],
    "analysis_summary": "å…¨ä½“çš„ãªåˆ†æã¾ã¨ã‚ï¼ˆ100æ–‡å­—ä»¥ä¸Šï¼‰"
}}
```
"""
                messages = [
                    self.llm_manager.create_ai_message(
                        role="system", content=self.system_prompt
                    ),
                    self.llm_manager.create_ai_message(role="user", content=llm_prompt),
                ]

                logger.info("LLMå£²ä¸Šå‡¦ç†åˆ†æé–‹å§‹ - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœçµ±åˆ")
                response = await self.llm_manager.generate_response(
                    messages, max_tokens=1200
                )

                if response.success:
                    import json

                    content = response.content.strip()
                    if content.startswith("```json"):
                        content = content[7:]
                    if content.endswith("```"):
                        content = content[:-3]
                    content = content.strip()

                    llm_analysis_result = json.loads(content)

                    # LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                    performance_rating = llm_analysis_result.get(
                        "performance_rating", "unknown"
                    )
                    efficiency_analysis = llm_analysis_result.get(
                        "efficiency_analysis", ""
                    )
                    recommendations = llm_analysis_result.get("recommendations", [])
                    expected_impact = llm_analysis_result.get("expected_impact", "")
                    priority_actions = llm_analysis_result.get("priority_actions", [])
                    analysis_summary = llm_analysis_result.get("analysis_summary", "")

                    logger.info(
                        f"LLMå£²ä¸Šå‡¦ç†åˆ†ææˆåŠŸ: rating={performance_rating}, recommendations={len(recommendations)}"
                    )

                    # LLMåˆ†æçµæœã‚’ãƒ­ã‚°å‡ºåŠ›
                    logger.info("=== LLM Sales Processing Analysis Details ===")
                    logger.info(f"Performance Rating: {performance_rating}")
                    logger.info(f"Efficiency Analysis: {efficiency_analysis[:100]}...")
                    logger.info(f"Recommendations Count: {len(recommendations)}")
                    logger.info(f"Expected Impact: {expected_impact}")
                    logger.info(f"Analysis Summary: {analysis_summary[:100]}...")

                else:
                    # LLMå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰è©•ä¾¡
                    logger.warning(
                        f"LLMå£²ä¸Šå‡¦ç†åˆ†æå¤±æ•—: {response.error_message}, ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨"
                    )
                    performance_rating = "acceptable"
                    efficiency_analysis = f"ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‡{conversion_rate:.1%}ã®æ¨™æº–çš„ãªå£²ä¸ŠåŠ¹ç‡ã€‚ã•ã‚‰ãªã‚‹åˆ†æãŒå¿…è¦ã€‚"
                    recommendations = [
                        "å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã®å‚¾å‘åˆ†æ",
                        "é¡§å®¢è¡Œå‹•ã®èª¿æŸ»",
                        "ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³åŠ¹æœã®æ¤œè¨¼",
                    ]
                    expected_impact = "åŸºæœ¬çš„ãªå£²ä¸Šæ”¹å–„åŠ¹æœ"
                    priority_actions = [
                        "å„ªå…ˆåº¦é«˜: ãƒ‡ãƒ¼ã‚¿åˆ†æå®Ÿæ–½",
                        "å„ªå…ˆåº¦ä¸­: é¡§å®¢èª¿æŸ»",
                        "å„ªå…ˆåº¦ä½: åŠ¹æœæ¤œè¨¼",
                    ]
                    analysis_summary = f"å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãåŸºæœ¬åˆ†æã‚’å®Ÿæ–½ã€‚ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‡{conversion_rate:.1%}ã§ã®å–¶æ¥­æ´»å‹•ã‚’è©•ä¾¡ã€‚"

                # å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³é …ç›® (LLMçµæœã«åŸºã¥ã)
                action_items = (
                    priority_actions
                    if priority_actions
                    else [
                        "å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æ",
                        "é¡§å®¢ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†",
                        "ç«¶åˆåº—ã®å‹•å‘èª¿æŸ»",
                        "ã‚¹ã‚¿ãƒƒãƒ•ç ”ä¿®å®Ÿæ–½",
                        "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°äºˆç®—ã®è¦‹ç›´ã—",
                    ]
                )

                # å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ² (LLMçµæœã«åŸºã¥ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿)
                for item in action_items[:3]:  # ä¸Šä½3ã¤ã‚’è¨˜éŒ²
                    action = {
                        "type": "sales_improvement",
                        "content": item,
                        "performance_rating": performance_rating,
                        "llm_based": True,
                        "timestamp": datetime.now().isoformat(),
                    }
                    state.executed_actions.append(action)

                # Stateæ›´æ–°
                state.sales_processing = {
                    "transactions": transactions,
                    "total_events": total_events,
                    "total_revenue": total_revenue,
                    "conversion_rate": f"{conversion_rate:.1%}",
                    "performance_rating": performance_rating,
                    "efficiency_analysis": efficiency_analysis,
                    "analysis": analysis_summary,
                    "recommendations": recommendations,
                    "expected_impact": expected_impact,
                    "priority_actions": priority_actions,
                    "action_items": action_items,
                    "simulation_result": simulation_result,
                    "llm_analysis_performed": bool(response.success),
                    "execution_timestamp": datetime.now().isoformat(),
                }

                logger.info(
                    f"âœ… Statefulå£²ä¸Šå‡¦ç†å®Œäº†: rating={performance_rating}, revenue=Â¥{total_revenue}, llm_used={bool(response.success)}"
                )

            except Exception as e:
                logger.warning(f"å£²ä¸Šå‡¦ç†LLMåˆ†æå¤±æ•—: {e}")
                # å®Œå…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                state.sales_processing = {
                    "performance_rating": "error",
                    "analysis": f"LLMåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
                    "recommendations": ["ç®¡ç†è€…ã¸é€£çµ¡"],
                    "action_items": [],
                    "llm_analysis_performed": False,
                    "execution_timestamp": datetime.now().isoformat(),
                }

        except Exception as e:
            logger.error(f"Statefulå£²ä¸Šå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            state.errors.append(f"sales_processing: {str(e)}")
            state.processing_status = "error"

        return state

    @traceable(name="customer_service_interactions")
    async def customer_interaction_node(
        self, state: ManagementState
    ) -> ManagementState:
        """é¡§å®¢å¯¾å¿œnodeã®LangGraph Statefulé–¢æ•° - LLMã§é¡§å®¢ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åˆ†æã—ç¾å®Ÿçš„ãªå¯¾å¿œæˆ¦ç•¥ã‚’æ±ºå®š"""
        logger.info(f"âœ… Statefulé¡§å®¢å¯¾å¿œé–‹å§‹: step={state.current_step}")

        # ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        trace_metadata = {
            "session_id": state.session_id,
            "session_type": state.session_type,
            "current_step": state.current_step,
            "business_date": state.business_date.isoformat()
            if state.business_date
            else None,
            "start_time": datetime.now().isoformat(),
            "agent_type": "management_agent",
            "node_type": "customer_service_interactions",
            "input_state": {
                "has_business_metrics": state.business_metrics is not None,
                "current_customer_satisfaction": state.business_metrics.customer_satisfaction
                if state.business_metrics
                else 0,
                "processing_status": state.processing_status,
            },
        }

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
            state.current_step = "customer_interaction"
            state.processing_status = "processing"

            # é¡§å®¢ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†
            feedback = self.collect_customer_feedback()

            # ç¾åœ¨ã®ãƒ“ã‚¸ãƒã‚¹çŠ¶æ³å–å¾—
            customer_score = (
                state.business_metrics.customer_satisfaction
                if state.business_metrics
                else 3.0
            )
            current_sales = (
                state.business_metrics.sales if state.business_metrics else 0
            )

            # LLMã«ã‚ˆã‚‹é¡§å®¢å¯¾å¿œæˆ¦ç•¥åˆ†æ
            customer_strategy_prompt = f"""
ã‚ãªãŸã¯è‡ªå‹•è²©å£²æ©Ÿäº‹æ¥­ã®é¡§å®¢æˆåŠŸãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®é¡§å®¢ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨äº‹æ¥­çŠ¶æ³ã‚’åˆ†æã—ã€æœ€é©ãªé¡§å®¢å¯¾å¿œæˆ¦ç•¥ã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚

ã€é¡§å®¢ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯çŠ¶æ³ã€‘
- åé›†ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ•°: {feedback.get("feedback_count", 0)}ä»¶
- å¹³å‡é¡§å®¢æº€è¶³åº¦: {feedback.get("average_rating", 0)}/5.0
- äººæ°—ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {feedback.get("top_requests", [])}
- å…¨ä½“ãƒˆãƒ¬ãƒ³ãƒ‰: {feedback.get("trends", "")}

ã€äº‹æ¥­çŠ¶æ³ã€‘
- å…¨ä½“é¡§å®¢æº€è¶³åº¦: {customer_score}/5.0
- æœˆé–“å£²ä¸Š: Â¥{current_sales:,}
- ã‚µãƒ¼ãƒ“ã‚¹ç‰¹æ€§: è‡ªå‹•è²©å£²æ©Ÿ (24æ™‚é–“ãƒ»ã‚»ãƒ«ãƒ•ã‚µãƒ¼ãƒ“ã‚¹)

ã€åˆ†æè¦ä»¶ã€‘
1. ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å†…å®¹ã®æ„Ÿæƒ…åˆ†æï¼ˆæº€è¶³/ä¸æº€/ææ¡ˆï¼‰
2. å¯¾å¿œå„ªå…ˆåº¦ã®åˆ¤æ–­ï¼ˆå³æ™‚/è¨ˆç”»çš„/ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ï¼‰
3. äº‹æ¥­ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®è©•ä¾¡ï¼ˆå£²ä¸Šå½±éŸ¿/å£ã‚³ãƒŸå½±éŸ¿/ãƒ–ãƒ©ãƒ³ãƒ‰å½±éŸ¿ï¼‰
4. ç¾å®Ÿçš„ãªå¯¾å¿œç­–ã®ç«‹æ¡ˆï¼ˆè‡ªå‹•è²©å£²æ©Ÿé‹å–¶åˆ¶ç´„ã‚’è€ƒæ…®ï¼‰

ã€è‡ªå‹•è²©å£²æ©Ÿäº‹æ¥­ã®ç¾å®Ÿçš„å¯¾å¿œã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€‘
- å³æ™‚å¯¾å¿œ: å•†å“è£œå……ã€æ©Ÿæ¢°ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã€ã‚¯ãƒ¬ãƒ¼ãƒ å‡¦ç†
- è¨ˆç”»çš„æ–½ç­–: ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ä¼ç”»ã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼æ”¹å–„ã€ã‚¹ã‚¿ãƒƒãƒ•ç ”ä¿®
- ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°: ç¶™ç¶šèª¿æŸ»ã€ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå®Ÿæ–½ã€ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "feedback_analysis": {{
        "sentiment_summary": "å…¨ä½“çš„ãªæ„Ÿæƒ…å‚¾å‘",
        "priority_level": "å¯¾å¿œå„ªå…ˆåº¦ (urgent/high/medium/low)",
        "key_insights": ["é‡è¦ãªæ´å¯Ÿ1", "é‡è¦ãªæ´å¯Ÿ2"],
        "business_impact": "äº‹æ¥­ã¸ã®å½±éŸ¿åº¦è©•ä¾¡"
    }},
    "recommended_strategy": {{
        "primary_approach": "ä¸»è¦å¯¾å¿œæ–¹é‡",
        "immediate_actions": ["å³æ™‚å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³"],
        "long_term_initiatives": ["é•·æœŸæ–½ç­–"],
        "resource_allocation": "å¿…è¦ãƒªã‚½ãƒ¼ã‚¹ã®è¦‹ç©ã‚‚ã‚Š",
        "expected_timeline": "æœŸå¾…åŠ¹æœç™ºç¾æœŸé–“"
    }},
    "specific_recommendations": {{
        "customer_service": ["ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒ¼ãƒ“ã‚¹æ”¹å–„ç­–"],
        "product_offerings": ["å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹æ”¹å–„ææ¡ˆ"],
        "marketing_communications": ["ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–½ç­–"],
        "operational_improvements": ["é‹å–¶æ”¹å–„ç­–"]
    }},
    "success_measurement": {{
        "kpi_tracking": ["è¿½è·¡æŒ‡æ¨™"],
        "target_improvements": "ç›®æ¨™æ”¹å–„å€¤",
        "monitoring_period": "ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æœŸé–“",
        "success_criteria": ["æˆåŠŸåˆ¤å®šåŸºæº–"]
    }},
    "implementation_considerations": {{
        "feasibility": "å®Ÿè¡Œå¯èƒ½æ€§è©•ä¾¡",
        "cost_benefit": "è²»ç”¨å¯¾åŠ¹æœåˆ†æ",
        "risk_assessment": "ãƒªã‚¹ã‚¯è©•ä¾¡",
        "contingency_plans": ["ä»£æ›¿æ¡ˆ"]
    }}
}}
"""

            messages = [
                self.llm_manager.create_ai_message(
                    role="system",
                    content="ã‚ãªãŸã¯è‡ªå‹•è²©å£²æ©Ÿäº‹æ¥­ã®é¡§å®¢ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚ç¾å®Ÿçš„ã§å®Ÿè¡Œå¯èƒ½ãªé¡§å®¢å¯¾å¿œæˆ¦ç•¥ã‚’ç«‹æ¡ˆã—ã¦ãã ã•ã„ã€‚",
                ),
                self.llm_manager.create_ai_message(
                    role="user", content=customer_strategy_prompt
                ),
            ]

            logger.info("LLMé¡§å®¢å¯¾å¿œæˆ¦ç•¥åˆ†æé–‹å§‹ - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯çµ±åˆ")

            try:
                response = await self.llm_manager.generate_response(
                    messages, max_tokens=1200
                )

                if response.success:
                    import json

                    content = response.content.strip()
                    if content.startswith("```json"):
                        content = content[7:]
                    if content.endswith("```"):
                        content = content[:-3]
                    content = content.strip()

                    strategy_analysis = json.loads(content)

                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
                    feedback_analysis = strategy_analysis.get("feedback_analysis", {})
                    feedback_analysis.setdefault("sentiment_summary", "neutral")
                    feedback_analysis.setdefault("priority_level", "medium")
                    feedback_analysis.setdefault("key_insights", [])
                    feedback_analysis.setdefault("business_impact", "minimal")

                    recommended_strategy = strategy_analysis.get(
                        "recommended_strategy", {}
                    )
                    recommended_strategy.setdefault(
                        "primary_approach", "monitor_and_maintain"
                    )
                    recommended_strategy.setdefault("immediate_actions", [])
                    recommended_strategy.setdefault("long_term_initiatives", [])
                    recommended_strategy.setdefault("resource_allocation", "minimal")
                    recommended_strategy.setdefault("expected_timeline", "ongoing")

                    specific_recommendations = strategy_analysis.get(
                        "specific_recommendations", {}
                    )
                    specific_recommendations.setdefault("customer_service", [])
                    specific_recommendations.setdefault("product_offerings", [])
                    specific_recommendations.setdefault("marketing_communications", [])
                    specific_recommendations.setdefault("operational_improvements", [])

                    success_measurement = strategy_analysis.get(
                        "success_measurement", {}
                    )
                    success_measurement.setdefault(
                        "kpi_tracking", ["customer_satisfaction"]
                    )
                    success_measurement.setdefault(
                        "target_improvements", "5% improvement"
                    )
                    success_measurement.setdefault("monitoring_period", "monthly")
                    success_measurement.setdefault(
                        "success_criteria", ["feedback_improvement"]
                    )

                    implementation_considerations = strategy_analysis.get(
                        "implementation_considerations", {}
                    )
                    implementation_considerations.setdefault("feasibility", "high")
                    implementation_considerations.setdefault("cost_benefit", "positive")
                    implementation_considerations.setdefault("risk_assessment", "low")
                    implementation_considerations.setdefault("contingency_plans", [])

                    logger.info(
                        f"LLMé¡§å®¢å¯¾å¿œæˆ¦ç•¥åˆ†ææˆåŠŸ: å„ªå…ˆåº¦={feedback_analysis['priority_level']}, ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ={recommended_strategy['primary_approach']}"
                    )

                    # LLMåˆ†æçµæœã«åŸºã¥ãå®Ÿéš›ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
                    executed_actions = []

                    if feedback_analysis["priority_level"] == "urgent":
                        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ä½œæˆ
                        from src.agents.management_agent.customer_tools.create_customer_engagement_campaign import (
                            create_customer_engagement_campaign,
                        )

                        campaign_result = await create_customer_engagement_campaign(
                            "retention"
                        )

                        executed_actions.append(
                            {
                                "type": "emergency_campaign",
                                "campaign_type": campaign_result.get(
                                    "campaign_type", "emergency"
                                ),
                                "reason": f"Urgent customer feedback: {feedback_analysis['sentiment_summary']}",
                                "llm_driven": True,
                                "timestamp": datetime.now().isoformat(),
                            }
                        )

                        customer_interaction = {
                            "action": "urgent_customer_engagement",
                            "reasoning": f"LLMåˆ†æã«åŸºã¥ãç·Šæ€¥é¡§å®¢å¯¾å¿œ: {feedback_analysis['business_impact']}",
                            "feedback_analysis": feedback_analysis,
                            "strategy": recommended_strategy,
                            "recommendations": specific_recommendations,
                            "success_measurement": success_measurement,
                            "campaign_implemented": campaign_result,
                            "feedback_collected": feedback,
                            "llm_analysis_performed": True,
                            "execution_timestamp": datetime.now().isoformat(),
                        }

                    elif feedback_analysis["priority_level"] in ["high", "medium"]:
                        # ã‚µãƒ¼ãƒ“ã‚¹æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
                        executed_actions.append(
                            {
                                "type": "service_improvement_program",
                                "improvements": specific_recommendations[
                                    "customer_service"
                                ],
                                "reason": f"Customer satisfaction initiative: {feedback_analysis['key_insights']}",
                                "llm_driven": True,
                                "timestamp": datetime.now().isoformat(),
                            }
                        )

                        customer_interaction = {
                            "action": "planned_service_improvement",
                            "reasoning": f"LLMåˆ†æã«åŸºã¥ãè¨ˆç”»çš„é¡§å®¢å¯¾å¿œ: {recommended_strategy['primary_approach']}",
                            "feedback_analysis": feedback_analysis,
                            "strategy": recommended_strategy,
                            "recommendations": specific_recommendations,
                            "success_measurement": success_measurement,
                            "feedback_collected": feedback,
                            "llm_analysis_performed": True,
                            "execution_timestamp": datetime.now().isoformat(),
                        }
                    else:
                        # ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ç¶™ç¶š
                        customer_interaction = {
                            "action": "feedback_monitoring",
                            "reasoning": f"å®‰å®šã—ãŸé¡§å®¢çŠ¶æ³ç¶™ç¶šãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°: {feedback_analysis['sentiment_summary']}",
                            "feedback_analysis": feedback_analysis,
                            "strategy": recommended_strategy,
                            "recommendations": specific_recommendations,
                            "success_measurement": success_measurement,
                            "feedback_collected": feedback,
                            "llm_analysis_performed": True,
                            "execution_timestamp": datetime.now().isoformat(),
                        }

                else:
                    logger.warning(f"LLMé¡§å®¢å¯¾å¿œæˆ¦ç•¥åˆ†æå¤±æ•—: {response.error_message}")
                    # LLMå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    feedback_count = feedback.get("feedback_count", 0)

                    if feedback_count > 15:
                        from src.agents.management_agent.customer_tools.create_customer_engagement_campaign import (
                            create_customer_engagement_campaign,
                        )

                        campaign_result = await create_customer_engagement_campaign(
                            "loyalty"
                        )

                        customer_interaction = {
                            "action": "engagement_campaign_created",
                            "reasoning": f"å¤šãã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯({feedback_count}ä»¶)ã«åŸºã¥ãé¡§å®¢ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå¼·åŒ–",
                            "actions_planned": ["ãƒ­ã‚¤ãƒ¤ãƒªãƒ†ã‚£ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å®Ÿæ–½"],
                            "campaign_details": campaign_result,
                            "feedback_collected": feedback,
                            "llm_analysis_performed": False,
                        }

                        executed_actions = [
                            {
                                "type": "customer_campaign",
                                "campaign_type": campaign_result.get("campaign_type"),
                                "target_audience": campaign_result.get("target"),
                                "expected_impact": campaign_result.get(
                                    "expected_impact"
                                ),
                                "llm_driven": False,
                                "timestamp": datetime.now().isoformat(),
                            }
                        ]

                    elif customer_score < 3.5:
                        customer_interaction = {
                            "action": "customer_service_improvement",
                            "reasoning": f"é¡§å®¢æº€è¶³åº¦({customer_score}/5.0)ãŒä½ã„ãŸã‚ã‚µãƒ¼ãƒ“ã‚¹æ”¹å–„",
                            "actions_planned": ["ã‚µãƒ¼ãƒ“ã‚¹å“è³ªèª¿æŸ»", "ã‚¹ã‚¿ãƒƒãƒ•ç ”ä¿®å®Ÿæ–½"],
                            "feedback_collected": feedback,
                            "llm_analysis_performed": False,
                        }

                        executed_actions = [
                            {
                                "type": "service_improvement",
                                "trigger_reason": f"Low satisfaction score: {customer_score}",
                                "planned_actions": customer_interaction[
                                    "actions_planned"
                                ],
                                "llm_driven": False,
                                "timestamp": datetime.now().isoformat(),
                            }
                        ]
                    else:
                        customer_interaction = {
                            "action": "monitor_feedback",
                            "reasoning": f"ç¾åœ¨ã®æº€è¶³åº¦({customer_score}/5.0)ã¯å®‰å®š",
                            "actions_planned": ["ç¶™ç¶šãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†"],
                            "feedback_collected": feedback,
                            "llm_analysis_performed": False,
                        }
                        executed_actions = []

            except Exception as e:
                logger.error(f"é¡§å®¢å¯¾å¿œæˆ¦ç•¥LLMåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                # å®Œå…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                feedback_count = feedback.get("feedback_count", 0)

                if feedback_count > 15:
                    from src.agents.management_agent.customer_tools.create_customer_engagement_campaign import (
                        create_customer_engagement_campaign,
                    )

                    try:
                        campaign_result = await create_customer_engagement_campaign(
                            "loyalty"
                        )
                        action_type = "engagement_campaign_created"
                    except:
                        campaign_result = {"status": "fallback"}
                        action_type = "campaign_planned_manually"

                    customer_interaction = {
                        "action": action_type,
                        "reasoning": f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å¤šæ•°({feedback_count}ä»¶)ã§å¯¾å¿œç­–å®Ÿè¡Œ",
                        "feedback_collected": feedback,
                        "llm_analysis_performed": False,
                    }
                    executed_actions = [
                        {
                            "type": "customer_engagement",
                            "reason": "high feedback volume",
                            "llm_driven": False,
                            "timestamp": datetime.now().isoformat(),
                        }
                    ]
                else:
                    customer_interaction = {
                        "action": "basic_feedback_collection",
                        "reasoning": "é€šå¸¸é¡§å®¢å¯¾å¿œç¶™ç¶š",
                        "feedback_collected": feedback,
                        "llm_analysis_performed": False,
                    }
                    executed_actions = []

            # å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²
            for action in executed_actions:
                state.executed_actions.append(action)

            # Stateæ›´æ–°
            state.customer_interaction = customer_interaction

            feedback_count = feedback.get("feedback_count", 0)
            action_taken = customer_interaction.get("action", "no_action")
            llm_used = customer_interaction.get("llm_analysis_performed", False)

            logger.info(
                f"âœ… Statefulé¡§å®¢å¯¾å¿œå®Œäº†: action={action_taken}, feedback={feedback_count}, llm_used={llm_used}"
            )

        except Exception as e:
            logger.error(f"Statefulé¡§å®¢å¯¾å¿œã‚¨ãƒ©ãƒ¼: {e}")
            state.errors.append(f"customer_interaction: {str(e)}")
            state.processing_status = "error"

        return state

    @traceable(name="financial_calculations")
    async def profit_calculation_node(self, state: ManagementState) -> ManagementState:
        """åˆ©ç›Šè¨ˆç®—nodeã®LangGraph Statefulé–¢æ•° - ãƒ„ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®è²¡å‹™åˆ†æã‚’å®Ÿè¡Œ"""
        logger.info(f"âœ… Statefulåˆ©ç›Šè¨ˆç®—é–‹å§‹: step={state.current_step}")

        # ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        trace_metadata = {
            "session_id": state.session_id,
            "session_type": state.session_type,
            "current_step": state.current_step,
            "business_date": state.business_date.isoformat()
            if state.business_date
            else None,
            "start_time": datetime.now().isoformat(),
            "agent_type": "management_agent",
            "node_type": "financial_calculations",
            "input_state": {
                "has_financial_analysis": state.financial_analysis is not None,
                "has_sales_analysis": state.sales_analysis is not None,
                "current_profit_margin": state.financial_analysis.get(
                    "profit_margin", 0
                )
                if state.financial_analysis
                else 0,
                "current_sales": state.financial_analysis.get("sales", 0)
                if state.financial_analysis
                else 0,
                "processing_status": state.processing_status,
            },
        }

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
            state.current_step = "profit_calculation"
            state.processing_status = "processing"

            # ãƒ„ãƒ¼ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’å–å¾—
            tools = {tool.name: tool for tool in self.tools}

            if "get_business_data" not in tools:
                logger.error("get_business_dataãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                state.errors.append("profit_calculation: get_business_dataãƒ„ãƒ¼ãƒ«æœªå–å¾—")
                state.processing_status = "error"
                return state

            if "analyze_financials" not in tools:
                logger.error("analyze_financialsãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                state.errors.append(
                    "profit_calculation: analyze_financialsãƒ„ãƒ¼ãƒ«æœªå–å¾—"
                )
                state.processing_status = "error"
                return state

            get_business_data_tool = tools["get_business_data"]
            analyze_financials_tool = tools["analyze_financials"]

            # ãƒ„ãƒ¼ãƒ«ä½¿ç”¨: æœ€æ–°ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™å–å¾—
            logger.info("ãƒ„ãƒ¼ãƒ«çµŒç”±ã§ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™ã‚’å–å¾—")
            try:
                business_data_result = await get_business_data_tool.ainvoke({})
                logger.info(
                    f"ãƒ„ãƒ¼ãƒ« get_business_data å‘¼ã³å‡ºã—æˆåŠŸ: {type(business_data_result)}"
                )
                latest_metrics = (
                    business_data_result
                    if isinstance(business_data_result, dict)
                    else {}
                )

                # ãƒ„ãƒ¼ãƒ«ä½¿ç”¨: è©³ç´°è²¡å‹™åˆ†æå®Ÿè¡Œ
                logger.info("ãƒ„ãƒ¼ãƒ«çµŒç”±ã§è²¡å‹™ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œ")
                try:
                    raw_result = await analyze_financials_tool.ainvoke({})
                    logger.info(
                        f"ãƒ„ãƒ¼ãƒ« analyze_financials ç”Ÿçµæœã‚¿ã‚¤ãƒ—: {type(raw_result)}"
                    )

                    # çµæœãŒè¾æ›¸ã®å ´åˆãã®ã¾ã¾ä½¿ç”¨ã€è¾æ›¸ã§ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨
                    if isinstance(raw_result, dict):
                        financial_analysis_result = raw_result
                    elif isinstance(raw_result, str):
                        # æ–‡å­—åˆ—ã®å ´åˆã¯JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ
                        try:
                            import json

                            financial_analysis_result = json.loads(raw_result)
                        except json.JSONDecodeError:
                            financial_analysis_result = {
                                "analysis": raw_result,
                                "recommendations": ["ãƒ„ãƒ¼ãƒ«å‡ºåŠ›ãƒ‘ãƒ¼ã‚¹å¤±æ•—"],
                            }
                    else:
                        # ãã®ä»–ã®å‹ã®å ´åˆã¯åŸºæœ¬æ§‹é€ ã‚’ä½œæˆ
                        financial_analysis_result = {
                            "analysis": str(raw_result),
                            "recommendations": ["ãƒ„ãƒ¼ãƒ«å‡ºåŠ›å‡¦ç†æ¸ˆã¿"],
                        }

                    logger.info(
                        f"ãƒ„ãƒ¼ãƒ« analyze_financials å‡¦ç†æˆåŠŸ: æ¨å¥¨äº‹é …={len(financial_analysis_result.get('recommendations', []))}ä»¶"
                    )
                except Exception as tool_error:
                    logger.error(
                        f"analyze_financialsãƒ„ãƒ¼ãƒ«å®Ÿè¡Œè©³ç´°ã‚¨ãƒ©ãƒ¼: {tool_error}"
                    )
                    import traceback

                    logger.error(f"ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
                    financial_analysis_result = {
                        "analysis": f"ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(tool_error)}",
                        "recommendations": ["ãƒ„ãƒ¼ãƒ«ä½¿ç”¨å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æ"],
                    }

                # å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ² (ãƒ„ãƒ¼ãƒ«ä½¿ç”¨)
                action = {
                    "type": "profit_calculation_with_tools",
                    "tools_used": ["get_business_data", "analyze_financials"],
                    "latest_data_integrated": latest_metrics,
                    "extended_analysis": financial_analysis_result,
                    "timestamp": datetime.now().isoformat(),
                }
                state.executed_actions.append(action)

            except Exception as e:
                logger.error(f"ãƒ„ãƒ¼ãƒ«çµŒç”±è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
                import traceback

                logger.error(f"è©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                financial_analysis = state.financial_analysis or {}
                latest_metrics = financial_analysis
                financial_analysis_result = {
                    "recommendations": ["ãƒ„ãƒ¼ãƒ«ä½¿ç”¨å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æ"]
                }

                # ã‚¨ãƒ©ãƒ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²
                action = {
                    "type": "profit_calculation_fallback",
                    "error_details": f"ãƒ„ãƒ¼ãƒ«ä½¿ç”¨å¤±æ•—: {str(e)}",
                    "fallback_used": True,
                    "timestamp": datetime.now().isoformat(),
                }
                state.executed_actions.append(action)

            # åˆ©ç›Šè¨ˆç®—: ãƒ„ãƒ¼ãƒ«ã‹ã‚‰å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            current_revenue = latest_metrics.get("sales", 0)
            current_profit_margin = latest_metrics.get("profit_margin", 0)
            current_customer_satisfaction = latest_metrics.get(
                "customer_satisfaction", 3.0
            )

            # ç²¾å¯†ãªåˆ©ç›Šè¨ˆç®— (ãƒ„ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹)
            profit_margin_val = (
                float(current_profit_margin)
                if isinstance(current_profit_margin, (int, float))
                else 0.0
            )
            profit_amount = current_revenue * profit_margin_val

            # è²¡å‹™å¥å…¨æ€§è©•ä¾¡ (ãƒ„ãƒ¼ãƒ«æ¨å¥¨ã¨çµ„ã¿åˆã‚ã›)
            margin_level = "unknown"
            if profit_margin_val > 0.3:
                margin_level = "excellent"
            elif profit_margin_val > 0.2:
                margin_level = "good"
            elif profit_margin_val > 0.1:
                margin_level = "acceptable"
            else:
                margin_level = "critical"

            # ãƒ„ãƒ¼ãƒ«ã«ã‚ˆã‚‹æ¨å¥¨äº‹é …ã¨å†…éƒ¨æ¨å¥¨ã‚’çµ±åˆ
            tool_recommendations = financial_analysis_result.get("recommendations", [])
            internal_recommendations = []
            if margin_level == "excellent":
                internal_recommendations.append("è¦æ¨¡æ‹¡å¤§æ¤œè¨")
            elif margin_level == "good":
                internal_recommendations.append("å®‰å®šç¶­æŒ")
            elif margin_level == "acceptable":
                internal_recommendations.append("åŠ¹ç‡æ”¹å–„")
            else:
                internal_recommendations.append("æŠœæœ¬çš„è¦‹ç›´ã—")

            all_recommendations = tool_recommendations + internal_recommendations

            profit_calculation_result = {
                "total_revenue": current_revenue,
                "profit_margin": profit_margin_val,
                "profit_amount": profit_amount,
                "customer_satisfaction_score": current_customer_satisfaction,
                "margin_level": margin_level,
                "tool_based_analysis": financial_analysis_result.get("analysis", ""),
                "recommendations": all_recommendations,
                "calculation_method": "tool_integrated",
                "data_source": "get_business_data_tool",
                "analysis_source": "analyze_financials_tool",
                "calculation_timestamp": datetime.now().isoformat(),
            }

            # å±æ©Ÿçš„çŠ¶æ³ã®å ´åˆã€è¿½åŠ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²
            if margin_level == "critical":
                action = {
                    "type": "financial_alert",
                    "alert_level": "critical",
                    "margin": profit_margin_val,
                    "recommendations": all_recommendations,
                    "tool_based": True,
                    "timestamp": datetime.now().isoformat(),
                }
                state.executed_actions.append(action)

            # Stateæ›´æ–°
            state.profit_calculation = profit_calculation_result

            # ãƒ­ã‚°å‡ºåŠ› (ãƒ„ãƒ¼ãƒ«ä½¿ç”¨çŠ¶æ³å«ã‚€)
            logger.info(
                f"âœ… Statefulåˆ©ç›Šè¨ˆç®—å®Œäº†ï¼ˆãƒ„ãƒ¼ãƒ«çµ±åˆï¼‰: margin={profit_margin_val:.1%}, level={margin_level}, tools_used=2"
            )

        except Exception as e:
            logger.error(f"Statefulåˆ©ç›Šè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            state.errors.append(f"profit_calculation: {str(e)}")
            state.processing_status = "error"

        return state

    @conditional_traceable(name="strategic_management_feedback")
    async def feedback_node(self, state: ManagementState) -> ManagementState:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯nodeã®LangGraph Statefulé–¢æ•° - LLMãƒ™ãƒ¼ã‚¹ã®æˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æã‚’å®Ÿè¡Œ"""
        logger.info(f"âœ… Statefulæˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é–‹å§‹: step={state.current_step}")

        # ãƒˆãƒ¬ãƒ¼ã‚¹ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        trace_metadata = {
            "session_id": state.session_id,
            "session_type": state.session_type,
            "current_step": state.current_step,
            "business_date": state.business_date.isoformat()
            if state.business_date
            else None,
            "start_time": datetime.now().isoformat(),
            "agent_type": "management_agent",
            "node_type": "strategic_feedback",
            "input_state": {
                "total_actions_count": len(state.executed_actions),
                "errors_count": len(state.errors),
                "has_business_metrics": state.business_metrics is not None,
                "processing_status": state.processing_status,
            },
        }

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–°
            state.current_step = "feedback"
            state.processing_status = "processing"

            # æˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æã®ãŸã‚ã®å…¨ãƒ‡ãƒ¼ã‚¿é›†ç´„
            comprehensive_context = self._prepare_strategic_context(state)

            # LLMã«ã‚ˆã‚‹æˆ¦ç•¥çš„åˆ†æå®Ÿè¡Œ (asyncç‰ˆã‚’ä½¿ç”¨)
            strategic_analysis = await self._perform_strategic_feedback_analysis(
                comprehensive_context
            )

            # åˆ†æçµæœã‹ã‚‰æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
            feedback_data = self._structure_strategic_feedback(
                state, strategic_analysis
            )

            # æœ€çµ‚å ±å‘Šæ›¸ã®ç”Ÿæˆ (æˆ¦ç•¥çš„è¦–ç‚¹ã‚’å«ã‚€)
            final_report = self._generate_strategic_final_report(state, feedback_data)

            # Stateæ›´æ–°
            state.feedback = feedback_data
            state.final_report = final_report
            state.processing_status = "completed"

            # æˆ¦ç•¥çš„æ´å¯Ÿã®ãƒ­ã‚°å‡ºåŠ›
            logger.info(
                f"âœ… Strategic feedback completed - Priorities: {len(feedback_data.get('tomorrow_priorities', []))}"
            )

        except Exception as e:
            logger.error(f"Strategic feedback node error: {e}")
            state.errors.append(f"feedback: {str(e)}")
            state.processing_status = "completed_with_errors"

            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚æœ€å°é™ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
            feedback_data = self._create_fallback_feedback(state)
            final_report = self._generate_minimal_final_report(state, feedback_data)
            state.feedback = feedback_data
            state.final_report = final_report

        return state

    def _prepare_strategic_context(self, state: ManagementState) -> str:
        """
        æˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æã®ãŸã‚ã®å…¨Stateãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–ã•ã‚ŒãŸæ–‡è„ˆã«é›†ç´„

        Args:
            state: ç¾åœ¨ã®ManagementState

        Returns:
            LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã®æˆ¦ç•¥çš„æ–‡è„ˆæ–‡å­—åˆ—
        """
        context_parts = []

        # åŸºæœ¬ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if state.business_metrics:
            context_parts.append(
                f"""
ã€åŸºæœ¬äº‹æ¥­æŒ‡æ¨™ã€‘
- å£²ä¸Š: Â¥{state.business_metrics.sales:,}
- åˆ©ç›Šç‡: {state.business_metrics.profit_margin:.1%}
- é¡§å®¢æº€è¶³åº¦: {state.business_metrics.customer_satisfaction}/5.0
- åœ¨åº«çŠ¶æ…‹: {state.business_metrics.inventory_level}
            """.strip()
            )

        # åœ¨åº«åˆ†æ
        if state.inventory_analysis:
            context_parts.append(
                f"""
ã€åœ¨åº«ç®¡ç†åˆ†æã€‘
- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {state.inventory_analysis.get("status", "unknown")}
- åœ¨åº«ä¸è¶³å•†å“: {", ".join(state.inventory_analysis.get("low_stock_items", []))}
- å±æ©Ÿçš„å•†å“: {", ".join(state.inventory_analysis.get("critical_items", []))}
- åœ¨åº«åˆ‡ã‚Œãƒªã‚¹ã‚¯: {state.inventory_analysis.get("estimated_stockout", {})}
- LLMåˆ†æ: {state.inventory_analysis.get("llm_analysis", "ãªã—")[:200]}
            """.strip()
            )

        # å£²ä¸Šãƒ»è²¡å‹™åˆ†æ
        if state.sales_analysis:
            context_parts.append(
                f"""
ã€å£²ä¸Šãƒ»è²¡å‹™åˆ†æã€‘
- å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰: {state.sales_analysis.get("sales_trend", "unknown")}
- æˆ¦ç•¥ææ¡ˆæ•°: {len(state.sales_analysis.get("strategies", []))}ä»¶
- è²¡å‹™æ¦‚è¦: {state.sales_analysis.get("financial_overview", "ãªã—")}
- LLMåˆ†æ: {state.sales_analysis.get("analysis", "ãªã—")[:200]}
            """.strip()
            )

        # ä¾¡æ ¼æˆ¦ç•¥æ±ºå®š
        if state.pricing_decision:
            context_parts.append(
                f"""
ã€ä¾¡æ ¼æˆ¦ç•¥ã€‘
- æˆ¦ç•¥: {state.pricing_decision.get("strategy", "unknown")}
- å•†å“ä¾¡æ ¼æ›´æ–°: {len(state.pricing_decision.get("product_updates", []))}ä»¶
- LLMåˆ†æ: {state.pricing_decision.get("llm_analysis", "ãªã—")[:200]}
            """.strip()
            )

        # åœ¨åº«è£œå……æ±ºå®š
        if state.restock_decision:
            tasks = state.restock_decision.get("tasks_assigned", [])
            context_parts.append(
                f"""
ã€è£œå……ã‚¿ã‚¹ã‚¯ã€‘
- è£œå……æˆ¦ç•¥: {state.restock_decision.get("strategy", "unknown")}
- å‰²ã‚Šå½“ã¦ã‚¿ã‚¹ã‚¯æ•°: {len(tasks)}ä»¶
- ç·Šæ€¥ã‚¿ã‚¹ã‚¯: {len([t for t in tasks if t.get("urgency") == "urgent"])}ä»¶
- LLMåˆ†æ: {state.restock_decision.get("llm_analysis", "ãªã—")[:200]}
            """.strip()
            )

        # ç™ºæ³¨æ±ºå®š
        if state.procurement_decision:
            orders = state.procurement_decision.get("orders_placed", [])
            context_parts.append(
                f"""
ã€èª¿é”ç™ºæ³¨ã€‘
- ç™ºæ³¨æˆ¦ç•¥: {state.procurement_decision.get("strategy", "unknown")}
- ç™ºæ³¨æ•°: {len(orders)}ä»¶
- LLMåˆ†æ: {state.procurement_decision.get("llm_analysis", "ãªã—")[:200]}
            """.strip()
            )

        # å£²ä¸Šå‡¦ç†ãƒ»é¡§å®¢æº€è¶³åº¦
        if state.sales_processing:
            context_parts.append(
                f"""
ã€å£²ä¸Šå‡¦ç†ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡: {state.sales_processing.get("performance_rating", "unknown")}
- å–å¼•æ•°: {state.sales_processing.get("transactions", 0)}ä»¶
- ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‡: {state.sales_processing.get("conversion_rate", "unknown")}
- LLMåˆ†æ: {state.sales_processing.get("analysis", "ãªã—")[:200]}
            """.strip()
            )

        # é¡§å®¢å¯¾å¿œåˆ†æ
        if state.customer_interaction:
            context_parts.append(
                f"""
ã€é¡§å®¢å¯¾å¿œåˆ†æã€‘
- å¯¾å¿œã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {state.customer_interaction.get("action", "unknown")}
- LLMåˆ†æå®Ÿæ–½: {state.customer_interaction.get("llm_analysis_performed", False)}
- LLMåˆ†æ: {state.customer_interaction.get("reasoning", "ãªã—")[:200]}
            """.strip()
            )

        # è²¡å‹™è¨ˆç®—
        if state.profit_calculation:
            context_parts.append(
                f"""
ã€è²¡å‹™å¥å…¨æ€§ã€‘
- ç·å£²ä¸Š: Â¥{state.profit_calculation.get("total_revenue", 0):,}
- åˆ©ç›Šç‡: {state.profit_calculation.get("profit_margin", 0):.1%}
- åˆ©ç›Šé¡: Â¥{state.profit_calculation.get("profit_amount", 0):,}
- å¥å…¨æ€§ãƒ¬ãƒ™ãƒ«: {state.profit_calculation.get("margin_level", "unknown")}
            """.strip()
            )

        # å®Ÿè¡Œã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ¦‚è¦
        actions = state.executed_actions
        context_parts.append(
            f"""
ã€å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¦‚è¦ã€‘
- ç·å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(actions)}ä»¶
- LLMé§†å‹•ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {len([a for a in actions if a.get("llm_based") or a.get("llm_driven") or a.get("strategy_driven")])}ä»¶
- ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ•°: {len(state.errors)}ä»¶
- ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {state.session_id}

ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è©³ç´°:
{chr(10).join([f"- {a.get('type', 'unknown')}: {a.get('content', a.get('product', 'è©³ç´°ãªã—'))}" for a in actions[-5:]])}  # æœ€æ–°5ä»¶
        """.strip()
        )

        return "\n\n".join(context_parts)

    async def _perform_strategic_feedback_analysis(
        self, comprehensive_context: str
    ) -> Dict[str, Any]:
        """
        LLMã«ã‚ˆã‚‹åŒ…æ‹¬çš„ãªæˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æã‚’å®Ÿè¡Œ

        Args:
            comprehensive_context: é›†ç´„ã•ã‚ŒãŸãƒ“ã‚¸ãƒã‚¹æ–‡è„ˆ

        Returns:
            æˆ¦ç•¥çš„åˆ†æçµæœã®è¾æ›¸
        """
        logger.info("LLMæˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æé–‹å§‹")

        strategic_prompt = f"""
ã‚ãªãŸã¯è‡ªå‹•è²©å£²æ©Ÿäº‹æ¥­ã®çµŒå–¶è€…ã§ã™ã€‚æœ¬æ—¥ã®å…¨ã¦ã®ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€æ˜æ—¥ä»¥é™ã®äº‹æ¥­é‹å–¶ã«å¯¾ã™ã‚‹æˆ¦ç•¥çš„ãªæ´å¯Ÿã¨å„ªå…ˆäº‹é …ã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚

ã€æœ¬æ—¥ã®æ¥­å‹™å®Ÿè¡Œçµæœã€‘
{comprehensive_context}

ã€åˆ†æè¦ä»¶ã€‘
ã‚ãªãŸã¯çµŒå–¶è€…ã®ç«‹å ´ã‹ã‚‰ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†æã—ã¦ãã ã•ã„ï¼š

1. **äº‹æ¥­å¥å…¨æ€§è©•ä¾¡**: ç¾åœ¨ã®å£²ä¸Šãƒ»åˆ©ç›Šãƒ»é¡§å®¢æº€è¶³åº¦ã®ç·åˆè©•ä¾¡
2. **ãƒªã‚¹ã‚¯ã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆ**: æ˜æ—¥ä»¥é™ã«å½±éŸ¿ã‚’åŠã¼ã™æ½œåœ¨ãƒªã‚¹ã‚¯ã®ç‰¹å®š
3. **æˆ¦ç•¥çš„å„ªå…ˆé †ä½**: æ˜æ—¥ã‹ã‚‰é‡ç‚¹çš„ã«å–ã‚Šçµ„ã‚€ã¹ãäº‹é …ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°
4. **é•·æœŸæˆ¦ç•¥è¦–ç‚¹**: ä¸­é•·æœŸçš„ãªäº‹æ¥­æˆé•·ã«å‘ã‘ãŸç¤ºå”†
5. **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³**: å…·ä½“çš„ãªå®Ÿè¡Œè¨ˆç”»ã¨æ‹…å½“å‰²ã‚Šå½“ã¦

ã€è‡ªå‹•è²©å£²æ©Ÿäº‹æ¥­ç‰¹æœ‰ã®è€ƒæ…®ç‚¹ã€‘
- 24æ™‚é–“ç¨¼åƒã ãŒäººçš„ãƒªã‚½ãƒ¼ã‚¹ã¯æœ‰é™
- å•†å“è£œå……ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã¯å®šæœŸçš„ã«å¿…è¦
- é¡§å®¢æº€è¶³åº¦ãŒå£²ä¸Šã«ç›´çµã—ã‚„ã™ã„
- åœ¨åº«åˆ‡ã‚Œã¯æ©Ÿä¼šæå¤±ãŒå¤§ãã„
- ç«¶äº‰ç’°å¢ƒã®å¤‰åŒ–ã«è¿…é€Ÿã«å¯¾å¿œã™ã‚‹å¿…è¦

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
```json
{{
    "executive_summary": "çµŒå–¶è€…å‘ã‘äº‹æ¥­å…¨ä½“ã®æ¦‚è¦ã¨çµè«–ï¼ˆ200æ–‡å­—ä»¥å†…ï¼‰",
    "business_health_assessment": {{
        "overall_rating": "excellent/good/acceptable/poor/critical",
        "key_strengths": ["å¼·ã¿1", "å¼·ã¿2"],
        "key_concerns": ["æ‡¸å¿µäº‹é …1", "æ‡¸å¿µäº‹é …2"],
        "trend_direction": "improving/stable/declining"
    }},
    "tomorrow_priorities": [
        {{
            "rank": 1,
            "priority": "æœ€å„ªå…ˆäº‹é …ã®ç°¡æ½”ãªè¨˜è¿°",
            "reason": "ã“ã®å„ªå…ˆåº¦ã¨ã™ã‚‹ç†ç”±",
            "expected_impact": "å®Ÿè¡Œã«ã‚ˆã‚‹æœŸå¾…åŠ¹æœ",
            "assignee": "æ‹…å½“è€…ï¼ˆemployee/manager/automatedï¼‰",
            "timeline": "å®Œäº†ç›®æ¨™æœŸé–“"
        }},
        {{
            "rank": 2,
            "priority": "2ç•ªç›®ã®å„ªå…ˆäº‹é …...",
            "reason": "...",
            "expected_impact": "...",
            "assignee": "...",
            "timeline": "..."
        }},
        {{
            "rank": 3,
            "priority": "3ç•ªç›®ã®å„ªå…ˆäº‹é …...",
            "reason": "...",
            "expected_impact": "...",
            "assignee": "...",
            "timeline": "..."
        }}
    ],
    "risk_assessment": {{
        "immediate_risks": ["ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªãƒªã‚¹ã‚¯"],
        "short_term_risks": ["1-7æ—¥ä»¥å†…ã«å½±éŸ¿ã®ãƒªã‚¹ã‚¯"],
        "mitigation_actions": ["ãƒªã‚¹ã‚¯è»½æ¸›ã®ãŸã‚ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"],
        "monitoring_points": ["é‡ç‚¹ç›£è¦–äº‹é …"]
    }},
    "strategic_insights": {{
        "short_term_focus": "æ¬¡é€±~1ãƒ¶æœˆä»¥å†…ã®æˆ¦ç•¥çš„é‡ç‚¹",
        "medium_term_opportunities": "1-3ãƒ¶æœˆç¨‹åº¦ã®ä¸­æœŸæ©Ÿä¼š",
        "long_term_considerations": "3ãƒ¶æœˆä»¥ä¸Šã®ä¸­é•·æœŸè¦–ç‚¹",
        "competitive_positioning": "ç«¶äº‰ç’°å¢ƒã§ã®è‡ªç¤¾ä½ç½®ã¥ã‘"
    }},
    "action_plan": {{
        "immediate_next_steps": ["ç›´ã¡ã«å®Ÿè¡Œã™ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³"],
        "resource_allocation": {{
            "high_priority_employees": "ç·Šæ€¥æ¥­å‹™æ‹…å½“è€…æ•°",
            "monitoring_responsibility": "ç›£è¦–æ‹…å½“è€…",
            "backup_plans": ["äºˆå‚™è¨ˆç”»"]
        }},
        "success_metrics": ["æˆåŠŸåˆ¤å®šæŒ‡æ¨™"],
        "communication_plan": ["é–¢ä¿‚è€…ã¸ã®å ±å‘Šãƒ»é€£çµ¡äº‹é …"]
    }},
    "comprehensive_analysis": "å…¨ä½“åˆ†æã®è©³ç´°èª¬æ˜ã¨çµŒå–¶åˆ¤æ–­ã®æ ¹æ‹ ï¼ˆ300æ–‡å­—ä»¥å†…ï¼‰"
}}
```

æˆ¦ç•¥çš„æ´å¯Ÿã¯å…·ä½“çš„ãªè¡Œå‹•æŒ‡é‡ã¨ãªã‚‹ã‚ˆã†ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
"""

        try:
            messages = [
                self.llm_manager.create_ai_message(
                    role="system",
                    content="ã‚ãªãŸã¯è‡ªå‹•è²©å£²æ©Ÿäº‹æ¥­ã®æˆ¦ç•¥çš„çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå®Ÿè¡Œå¯èƒ½ãªæˆ¦ç•¥çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
                ),
                self.llm_manager.create_ai_message(
                    role="user", content=strategic_prompt
                ),
            ]

            response = await self.llm_manager.generate_response(
                messages, max_tokens=2000
            )

            if response.success:
                import json

                content = response.content.strip()
                if content.startswith("```json"):
                    content = content[7:]
                if content.endswith("```"):
                    content = content[:-3]
                content = content.strip()

                strategic_analysis = json.loads(content)

                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š
                strategic_analysis.setdefault(
                    "executive_summary", "æˆ¦ç•¥çš„åˆ†æã‚’å®Ÿè¡Œã—ã¾ã—ãŸ"
                )
                strategic_analysis.setdefault(
                    "business_health_assessment",
                    {
                        "overall_rating": "acceptable",
                        "key_strengths": [],
                        "key_concerns": [],
                        "trend_direction": "stable",
                    },
                )
                strategic_analysis.setdefault("tomorrow_priorities", [])
                strategic_analysis.setdefault(
                    "risk_assessment",
                    {
                        "immediate_risks": [],
                        "short_term_risks": [],
                        "mitigation_actions": [],
                        "monitoring_points": [],
                    },
                )
                strategic_analysis.setdefault(
                    "strategic_insights",
                    {
                        "short_term_focus": "å®‰å®šé‹å–¶æ¥­ç¶™ç¶š",
                        "medium_term_opportunities": "æ¥­å‹™åŠ¹ç‡åŒ–æ¤œè¨",
                        "long_term_considerations": "é¡§å®¢åŸºç›¤æ‹¡å¤§",
                        "competitive_positioning": "å¸‚å ´æ¨™æº–ãƒ¬ãƒ™ãƒ«",
                    },
                )
                strategic_analysis.setdefault(
                    "action_plan",
                    {
                        "immediate_next_steps": [],
                        "resource_allocation": {
                            "high_priority_employees": "1å",
                            "monitoring_responsibility": "manager",
                            "backup_plans": [],
                        },
                        "success_metrics": [],
                        "communication_plan": [],
                    },
                )
                strategic_analysis.setdefault(
                    "comprehensive_analysis",
                    f"LLMæˆ¦ç•¥åˆ†æå®Ÿè¡Œ: {len(comprehensive_context)}æ–‡å­—ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ",
                )

                logger.info(
                    f"LLMæˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†ææˆåŠŸ - å„ªå…ˆäº‹é …: {len(strategic_analysis.get('tomorrow_priorities', []))}ä»¶"
                )
                return strategic_analysis

            else:
                logger.warning(f"LLMæˆ¦ç•¥çš„åˆ†æå¤±æ•—: {response.error_message}")
                return self._create_fallback_strategic_analysis(comprehensive_context)

        except Exception as e:
            logger.error(f"æˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_fallback_strategic_analysis(comprehensive_context)

    def _structure_strategic_feedback(
        self, state: ManagementState, strategic_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        LLMã®æˆ¦ç•¥çš„åˆ†æçµæœã‚’æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›

        Args:
            state: ç¾åœ¨ã®ManagementState
            strategic_analysis: LLMã‹ã‚‰ã®æˆ¦ç•¥çš„åˆ†æçµæœ

        Returns:
            æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¾æ›¸
        """
        feedback_data = {
            "executive_summary": strategic_analysis.get(
                "executive_summary", "åˆ†æå®Ÿè¡Œ"
            ),
            "business_health": strategic_analysis.get("business_health_assessment", {}),
            "tomorrow_priorities": strategic_analysis.get("tomorrow_priorities", []),
            "risk_assessment": strategic_analysis.get("risk_assessment", {}),
            "strategic_insights": strategic_analysis.get("strategic_insights", {}),
            "action_plan": strategic_analysis.get("action_plan", {}),
            "comprehensive_analysis": strategic_analysis.get(
                "comprehensive_analysis", "è©³ç´°åˆ†æå®Ÿè¡Œ"
            ),
            "performance_indicators": {},
            "actions_taken": state.executed_actions.copy(),
            "recommendations": [],
            "execution_timestamp": datetime.now().isoformat(),
        }

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã®é›†ç´„ï¼ˆæˆ¦ç•¥çš„è¦–ç‚¹ã‹ã‚‰å†è©•ä¾¡ï¼‰
        if state.business_metrics:
            feedback_data["performance_indicators"] = {
                "sales": state.business_metrics.sales,
                "profit_margin": state.business_metrics.profit_margin,
                "customer_satisfaction": state.business_metrics.customer_satisfaction,
                "inventory_efficiency": len(state.executed_actions),
                "strategic_rating": strategic_analysis.get(
                    "business_health_assessment", {}
                ).get("overall_rating", "unknown"),
            }

        # æ¨å¥¨äº‹é …ã®ç”Ÿæˆï¼ˆæˆ¦ç•¥çš„åˆ†æã«åŸºã¥ãï¼‰
        recommendations = []

        # æ˜æ—¥ã®å„ªå…ˆäº‹é …ã‚’æ¨å¥¨äº‹é …ã¨ã—ã¦è¿½åŠ 
        for priority in feedback_data["tomorrow_priorities"][:3]:  # ãƒˆãƒƒãƒ—3
            recommendations.append(
                f"å„ªå…ˆåº¦{priority.get('rank', '?')}: {priority.get('priority', '')}"
            )

        # æˆ¦ç•¥çš„æ´å¯Ÿã‹ã‚‰ã®æ¨å¥¨
        insights = feedback_data["strategic_insights"]
        if insights.get("short_term_focus"):
            recommendations.append(f"çŸ­æœŸæˆ¦ç•¥: {insights['short_term_focus']}")

        # ãƒªã‚¹ã‚¯è»½æ¸›ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¨å¥¨äº‹é …ã¨ã—ã¦è¿½åŠ 
        for mitigation in feedback_data["risk_assessment"].get(
            "mitigation_actions", []
        )[:2]:
            recommendations.append(f"ãƒªã‚¹ã‚¯å¯¾å¿œ: {mitigation}")

        feedback_data["recommendations"] = recommendations

        return feedback_data

    def _generate_strategic_final_report(
        self, state: ManagementState, feedback_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æˆ¦ç•¥çš„è¦–ç‚¹ã‚’å«ã‚€æœ€çµ‚å ±å‘Šæ›¸ã‚’ç”Ÿæˆ

        Args:
            state: ManagementState
            feedback_data: æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿

        Returns:
            æˆ¦ç•¥çš„è¦–ç‚¹ã‚’å«ã‚€æœ€çµ‚å ±å‘Šæ›¸
        """
        final_report = {
            "session_id": state.session_id,
            "session_type": state.session_type,
            "business_metrics": state.business_metrics.dict()
            if state.business_metrics
            else None,
            "analyses_completed": {
                "inventory_analysis": bool(state.inventory_analysis),
                "sales_analysis": bool(state.sales_analysis),
                "pricing_decision": bool(state.pricing_decision),
                "restock_decision": bool(state.restock_decision),
                "procurement_decision": bool(state.procurement_decision),
                "sales_processing": bool(state.sales_processing),
                "customer_interaction": bool(state.customer_interaction),
                "profit_calculation": bool(state.profit_calculation),
                "strategic_feedback": True,
            },
            "actions_executed": state.executed_actions,
            "errors": state.errors,
            "executive_summary": feedback_data.get("executive_summary"),
            "strategic_priorities": feedback_data.get("tomorrow_priorities"),
            "business_health_rating": feedback_data.get("business_health", {}).get(
                "overall_rating", "unknown"
            ),
            "risk_assessment": feedback_data.get("risk_assessment"),
            "strategic_insights": feedback_data.get("strategic_insights"),
            "actionable_plan": feedback_data.get("action_plan"),
            "recommendations": feedback_data.get("recommendations", []),
            "final_status": "completed"
            if state.processing_status == "completed"
            else "completed_with_errors",
            "completion_timestamp": datetime.now().isoformat(),
        }

        return final_report

    def _create_fallback_feedback(self, state: ManagementState) -> Dict[str, Any]:
        """
        ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ

        Args:
            state: ManagementState

        Returns:
            åŸºæœ¬çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
        """
        return {
            "executive_summary": f"æ¥­å‹™å®Ÿè¡Œå®Œäº† - ã‚¢ã‚¯ã‚·ãƒ§ãƒ³{len(state.executed_actions)}ä»¶ã€ã‚¨ãƒ©ãƒ¼{len(state.errors)}ä»¶",
            "business_health": {
                "overall_rating": "acceptable",
                "trend_direction": "stable",
            },
            "tomorrow_priorities": [
                {
                    "rank": 1,
                    "priority": "ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ç¶™ç¶š",
                    "reason": "å®‰å®šé‹ç”¨ç¶­æŒã®ãŸã‚",
                    "assignee": "automated",
                    "timeline": "ongoing",
                }
            ],
            "risk_assessment": {
                "immediate_risks": [],
                "monitoring_points": ["ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§"],
            },
            "strategic_insights": {"short_term_focus": "å®‰å®šé‹ç”¨ç¶™ç¶š"},
            "action_plan": {"immediate_next_steps": ["é€šå¸¸æ¥­å‹™ç¶™ç¶š"]},
            "comprehensive_analysis": f"åŸºæœ¬æ¥­å‹™é‚è¡Œå®Œäº† - ã‚¨ãƒ©ãƒ¼æ™‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æ",
            "performance_indicators": {},
            "actions_taken": state.executed_actions,
            "recommendations": ["ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§ç¢ºèª", "ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç¢ºèª"],
            "execution_timestamp": datetime.now().isoformat(),
        }

    def _generate_minimal_final_report(
        self, state: ManagementState, feedback_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æœ€å°é™ã®æœ€çµ‚å ±å‘Šæ›¸ç”Ÿæˆï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ç”¨ï¼‰

        Args:
            state: ManagementState
            feedback_data: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿

        Returns:
            æœ€å°é™ã®æœ€çµ‚å ±å‘Šæ›¸
        """
        return {
            "session_id": state.session_id,
            "completion_timestamp": datetime.now().isoformat(),
            "final_status": state.processing_status,
            "executive_summary": feedback_data.get("executive_summary", "ã‚¨ãƒ©ãƒ¼æ™‚å®Œäº†"),
            "error_count": len(state.errors),
            "action_count": len(state.executed_actions),
        }

    def _perform_sync_strategic_feedback_analysis(
        self, comprehensive_context: str
    ) -> Dict[str, Any]:
        """
        åŒæœŸç‰ˆLLMæˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æã‚’å®Ÿè¡Œï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨ï¼‰

        Args:
            comprehensive_context: é›†ç´„ã•ã‚ŒãŸãƒ“ã‚¸ãƒã‚¹æ–‡è„ˆ

        Returns:
            æˆ¦ç•¥çš„åˆ†æçµæœã®è¾æ›¸
        """
        logger.info("åŒæœŸLLMæˆ¦ç•¥çš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æé–‹å§‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨ï¼‰")

        # ç›´æ¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥åˆ†æã‚’ä½¿ç”¨ï¼ˆLLMã¨ã®åŒæœŸå‡¦ç†ã‚’é¿ã‘ã‚‹ï¼‰
        return self._create_fallback_strategic_analysis(comprehensive_context)

    def _create_fallback_strategic_analysis(self, context: str) -> Dict[str, Any]:
        """
        LLMå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥çš„åˆ†æ

        Args:
            context: ãƒ“ã‚¸ãƒã‚¹æ–‡è„ˆ

        Returns:
            åŸºæœ¬çš„ãªæˆ¦ç•¥çš„åˆ†æçµæœ
        """
        # æ–‡è„ˆã‹ã‚‰åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡ºã—ã¦åˆ†æ
        sales_match = None
        profit_match = None
        inventory_match = None

        lines = context.split("\n")
        for line in lines:
            if "å£²ä¸Š:" in line and "Â¥" in line:
                sales_match = line.strip()
            elif "åˆ©ç›Šç‡:" in line and "%" in line:
                profit_match = line.strip()
            elif "åœ¨åº«ä¸è¶³å•†å“:" in line:
                inventory_match = line.strip()

        # åŸºæœ¬åˆ†æåˆ¤æ–­
        ratings = ["excellent", "good", "acceptable", "poor", "critical"]
        rating_index = 2  # default acceptable

        if profit_match and "%" in profit_match:
            try:
                profit_val = float(profit_match.split("%")[0].split()[-1])
                if profit_val > 25:
                    rating_index = 0  # excellent
                elif profit_val > 15:
                    rating_index = 1  # good
                elif profit_val < 5:
                    rating_index = 4  # critical
            except:
                pass

        return {
            "executive_summary": f"äº‹æ¥­åˆ†æå®Œäº†ã€‚å£²ä¸Šãƒ»åœ¨åº«ãƒ»é¡§å®¢å‹•å‘ã‚’æŠŠæ¡ã—ã€æ˜æ—¥ã¸ã®æˆ¦ç•¥çš„ç¤ºå”†ã‚’æ•´ç†ã—ã¾ã—ãŸã€‚",
            "business_health_assessment": {
                "overall_rating": ratings[rating_index],
                "key_strengths": ["æ¥­å‹™å®Ÿè¡Œå®Œäº†", "æˆ¦ç•¥çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒå®Ÿæ–½"],
                "key_concerns": ["ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜åº¦å‘ä¸Š", "ç¶™ç¶šç›£è¦–å¿…è¦"],
                "trend_direction": "stable",
            },
            "tomorrow_priorities": [
                {
                    "rank": 1,
                    "priority": "æ¥­å‹™æˆæœã®å®šé‡è©•ä¾¡å®Ÿæ–½",
                    "reason": "æˆ¦ç•¥çš„æ„æ€æ±ºå®šã®ç²¾åº¦å‘ä¸Šã®ãŸã‚",
                    "expected_impact": "æ„æ€æ±ºå®šå“è³ªå‘ä¸Š",
                    "assignee": "manager",
                    "timeline": "æ˜æ—¥ä¸­ã«",
                },
                {
                    "rank": 2,
                    "priority": "ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§ã®ç¢ºèª",
                    "reason": "è‡ªå‹•åŒ–å‡¦ç†ã®ä¿¡é ¼æ€§ç¢ºä¿ã®ãŸã‚",
                    "expected_impact": "é‹ç”¨å®‰å®šåŒ–",
                    "assignee": "employee",
                    "timeline": "ä»Šæ—¥ä¸­ã«",
                },
                {
                    "rank": 3,
                    "priority": "æˆ¦ç•¥çš„æ´å¯Ÿã®å®šæœŸåé›†",
                    "reason": "ä¸­é•·æœŸè¦–ç‚¹ã§ã®æ”¹å–„æ©Ÿä¼šæŠŠæ¡ã®ãŸã‚",
                    "expected_impact": "æˆ¦ç•¥çš„æŸ”è»Ÿæ€§å‘ä¸Š",
                    "assignee": "automated",
                    "timeline": "ç¶™ç¶šçš„ã«",
                },
            ],
            "risk_assessment": {
                "immediate_risks": ["ã‚·ã‚¹ãƒ†ãƒ ä¸å®‰å®šæ€§", "åˆ†æç²¾åº¦ä¸è¶³"],
                "short_term_risks": ["æ¥­å‹™åŠ¹ç‡åŒ–é…å»¶", "æˆ¦ç•¥çš„åˆ¤æ–­ã®é…ã‚Œ"],
                "mitigation_actions": [
                    "æ‰‹å‹•ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°å¼·åŒ–",
                    "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é‹ç”¨æº–å‚™",
                ],
                "monitoring_points": ["ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", "æ¥­å‹™å®Ÿè¡Œçµæœ"],
            },
            "strategic_insights": {
                "short_term_focus": "è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®å®‰å®šåŒ–ã¨æ¥­å‹™åŠ¹ç‡åŒ–",
                "medium_term_opportunities": "æˆ¦ç•¥çš„æ„æ€æ±ºå®šãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®é«˜åº¦åŒ–",
                "long_term_considerations": "AIæ”¯æ´çµŒå–¶ã‚·ã‚¹ãƒ†ãƒ ã®å®Œå…¨å°å…¥",
                "competitive_positioning": "æ¥­ç•Œæ¨™æº–ä»¥ä¸Šã®æˆ¦ç•¥çš„æ´å¯ŸåŠ›",
            },
            "action_plan": {
                "immediate_next_steps": [
                    "ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºèª",
                    "ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è§£æ",
                    "æ¥­å‹™ç¶™ç¶šæ€§ã®ç¢ºèª",
                ],
                "resource_allocation": {
                    "high_priority_employees": "0å",
                    "monitoring_responsibility": "automated_system",
                    "backup_plans": ["æ‰‹å‹•æ¥­å‹™åˆ‡ã‚Šæ›¿ãˆæº–å‚™"],
                },
                "success_metrics": ["ã‚·ã‚¹ãƒ†ãƒ å®‰å®šç¨¼åƒç‡95%ä»¥ä¸Š", "æ¥­å‹™å®Ÿè¡Œç‡98%ä»¥ä¸Š"],
                "communication_plan": ["çµŒå–¶é™£ã¸ã®å®Œäº†å ±å‘Š", "ãƒãƒ¼ãƒ ã¸ã®å®Ÿæ–½çµæœå…±æœ‰"],
            },
            "comprehensive_analysis": f"LLMåˆ†æå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥åˆ†æã‚’å®Ÿè¡Œã€‚{len(lines)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«åŸºæœ¬æˆ¦ç•¥çš„æ–¹å‘æ€§ã‚’æ•´ç†ã—ã¾ã—ãŸã€‚",
        }

    async def morning_routine(self) -> Dict[str, Any]:
        """æœã®æ¥­å‹™ãƒ«ãƒ¼ãƒãƒ³"""
        session_id = await self.start_management_session("morning_routine")

        try:
            # å¤œé–“ãƒ‡ãƒ¼ã‚¿ç¢ºèª
            overnight_data = self.get_business_metrics()

            # æœã®åˆ†æ
            morning_analysis = f"""
            æ˜¨å¤œã®äº‹æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã€ä»Šæ—¥ã®æ¥­å‹™å„ªå…ˆé †ä½ã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚
            
            ã€å¤œé–“ãƒ‡ãƒ¼ã‚¿ã€‘
            - å£²ä¸Šå®Ÿç¸¾: {overnight_data["sales"]}
            - åœ¨åº«çŠ¶æ³: {overnight_data["inventory_level"]}
            - é¡§å®¢æº€è¶³åº¦: {overnight_data["customer_satisfaction"]}
            
            ã€åˆ¤æ–­é …ç›®ã€‘
            1. ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªäº‹é …
            2. ä»Šæ—¥ã®é‡ç‚¹æ¥­å‹™
            3. å¾“æ¥­å“¡ã¸ã®æŒ‡ç¤ºäº‹é …
            """

            decisions = await self.make_strategic_decision(morning_analysis)

            return {
                "session_id": session_id,
                "session_type": "morning_routine",
                "overnight_data": overnight_data,
                "decisions": decisions,
                "status": "completed",
            }

        finally:
            await self.end_management_session()

    async def midday_check(self) -> Dict[str, Any]:
        """æ˜¼ã®æ¥­å‹™ãƒã‚§ãƒƒã‚¯"""
        session_id = await self.start_management_session("midday_check")

        try:
            metrics = self.get_business_metrics()
            financial_analysis = await self.analyze_financial_performance()

            midday_analysis = f"""
            åˆå‰ä¸­ã®æ¥­ç¸¾ã‚’ç¢ºèªã—ã€åˆå¾Œã®èª¿æ•´ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
            
            ã€åˆå‰å®Ÿç¸¾ã€‘
            - å£²ä¸Š: {metrics["sales"]}
            - åˆ©ç›Šç‡: {metrics["profit_margin"]}
            """

            decisions = await self.make_strategic_decision(midday_analysis)

            return {
                "session_id": session_id,
                "session_type": "midday_check",
                "metrics": metrics,
                "analysis": financial_analysis,
                "decisions": decisions,
                "status": "completed",
            }

        finally:
            await self.end_management_session()

    async def evening_summary(self) -> Dict[str, Any]:
        """å¤•æ–¹ã®æ¥­å‹™ç·æ‹¬"""
        session_id = await self.start_management_session("evening_summary")

        try:
            daily_performance = self.get_business_metrics()
            inventory_status = await self.check_inventory_status()

            evening_analysis = f"""
            ä»Šæ—¥ä¸€æ—¥ã®æ¥­ç¸¾ã‚’ç·æ‹¬ã—ã€æ˜æ—¥ã¸ã®æ”¹å–„ç‚¹ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
            
            ã€ä»Šæ—¥ã®å®Ÿç¸¾ã€‘
            - å£²ä¸Š: {daily_performance["sales"]}
            - åˆ©ç›Šç‡: {daily_performance["profit_margin"]}
            - åœ¨åº«çŠ¶æ³: {inventory_status["status"]}
            
            ã€åˆ†æé …ç›®ã€‘
            1. ä»Šæ—¥ã®æˆåŠŸè¦å› 
            2. æ”¹å–„ãŒå¿…è¦ãªé ˜åŸŸ
            3. æ˜æ—¥ã®é‡ç‚¹èª²é¡Œ
            """

            decisions = await self.make_strategic_decision(evening_analysis)

            return {
                "session_id": session_id,
                "session_type": "evening_summary",
                "daily_performance": daily_performance,
                "inventory_status": inventory_status,
                "decisions": decisions,
                "lessons_learned": [
                    "åœ¨åº«ç®¡ç†ã®æ”¹å–„ãŒå¿…è¦",
                    "é¡§å®¢æº€è¶³åº¦ã‚’ç¶­æŒã§ããŸ",
                ],
                "status": "completed",
            }

        finally:
            await self.end_management_session()

    async def feedback_engine(self) -> Dict[str, Any]:
        """å¤•æ–¹ã®æ¥­å‹™ç·æ‹¬"""
        session_id = await self.start_management_session("evening_summary")

        try:
            daily_performance = self.get_business_metrics()
            inventory_status = await self.check_inventory_status()

            evening_analysis = f"""
            ä»Šæ—¥ä¸€æ—¥ã®æ¥­ç¸¾ã‚’ç·æ‹¬ã—ã€æ˜æ—¥ã¸ã®æ”¹å–„ç‚¹ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
            
            ã€ä»Šæ—¥ã®å®Ÿç¸¾ã€‘
            - å£²ä¸Š: {daily_performance["sales"]}
            - åˆ©ç›Šç‡: {daily_performance["profit_margin"]}
            - åœ¨åº«çŠ¶æ³: {inventory_status["status"]}
            
            ã€åˆ†æé …ç›®ã€‘
            1. ä»Šæ—¥ã®æˆåŠŸè¦å› 
            2. æ”¹å–„ãŒå¿…è¦ãªé ˜åŸŸ
            3. æ˜æ—¥ã®é‡ç‚¹èª²é¡Œ
            """

            decisions = await self.make_strategic_decision(evening_analysis)

            return {
                "session_id": session_id,
                "session_type": "evening_summary",
                "daily_performance": daily_performance,
                "inventory_status": inventory_status,
                "decisions": decisions,
                "lessons_learned": [
                    "åœ¨åº«ç®¡ç†ã®æ”¹å–„ãŒå¿…è¦",
                    "é¡§å®¢æº€è¶³åº¦ã‚’ç¶­æŒã§ããŸ",
                ],
                "status": "completed",
            }

        finally:
            await self.end_management_session()


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
management_agent = NodeBasedManagementAgent(provider="openai")
